# qwen-max

{% hint style="info" %}
This documentation is valid for the following list of our models:

* `qwen-max`
* `qwen-max-2025-01-25`
{% endhint %}

## Model Overview

A large-scale Mixture-of-Experts (MoE) language model developed by Alibaba Cloud. It excels in language understanding, generation, and task performance across a variety of modalities. Mixture-of-Experts (MoE) Architecture: Uses 64 specialized "expert" networks, activating only relevant ones per task for efficient processing. Extensive Multilingual Support: Supports 29 languages, including Chinese, English, and Arabic. Long-Context Optimization: Supports 32K context windows with 8K generation. High Stability: Demonstrates high stability in maintaining prompt instructions, with no erroneous replies during extensive testing.

## How to Make a Call

{% stepper %}
{% step %}
### Setup You Canâ€™t Skip&#x20;

:black\_small\_square:  [**Create an Account**](https://aimlapi.com/app/sign-up): Visit the AI/ML API website and create an account (if you donâ€™t have one yet).\
:black\_small\_square:  [**Generate an API Key**](https://aimlapi.com/app/keys): After logging in, navigate to your account dashboard and generate your API key. Ensure that key is enabled on UI.
{% endstep %}

{% step %}
### Copy the code example

At the bottom of this page, you'll find [a code example](qwen-max.md#code-example-python) that shows how to structure the request. Choose the code snippet in your preferred programming language and copy it into your development environment.
{% endstep %}

{% step %}
### Modify the code example

:black\_small\_square:  Replace `<YOUR_AIMLAPI_KEY>` with your actual AI/ML API key from your account.\
:black\_small\_square:  Insert your question or request into the `content` fieldâ€”this is what the model will respond to.
{% endstep %}

{% step %}
### <sup><sub><mark style="background-color:yellow;">(Optional)<mark style="background-color:yellow;"><sub></sup> Adjust other optional parameters if needed

Only `model` and `messages` are required parameters for this model (and weâ€™ve already filled them in for you in the example), but you can include optional parameters if needed to adjust the modelâ€™s behavior. Below, you can find the corresponding [API schema](qwen-max.md#api-schema), which lists all available parameters along with notes on how to use them.
{% endstep %}

{% step %}
### Run your modified code

Run your modified code in your development environment. Response time depends on various factors, but for simple prompts it rarely exceeds a few seconds.
{% endstep %}
{% endstepper %}

{% hint style="success" %}
If you need a more detailed walkthrough for setting up your development environment and making a request step by step â€” feel free to use our [Quickstart guide](../../../quickstart/setting-up.md).
{% endhint %}

## API Schema

{% openapi src="qwen-max.json" path="/v1/chat/completions" method="post" %}
[qwen-max.json](qwen-max.json)
{% endopenapi %}

## Code Example (Python)

{% code overflow="wrap" %}
```python
import requests

response = requests.post(
    "https://api.aimlapi.com/v1/chat/completions",
    headers={
        "Content-Type":"application/json", 

        # Insert your AIML API Key instead of <YOUR_AIMLAPI_KEY>:
        "Authorization":"Bearer <YOUR_AIMLAPI_KEY>",
        "Content-Type":"application/json"
    },
    json={
        "model":"qwen-max",
        "messages":[
            {
                "role":"user",

                # Insert your question for the model here, instead of Hello:
                "content":"Hello"
            }
        ]
    }
)

data = response.json()
print(data)
```
{% endcode %}

<details>

<summary>Response</summary>

{% code overflow="wrap" %}
```json5
{'id': 'chatcmpl-7470584d-ce5c-95c2-9a79-e9618bca74a6', 'system_fingerprint': None, 'object': 'chat.completion', 'choices': [{'index': 0, 'finish_reason': 'stop', 'logprobs': None, 'message': {'role': 'assistant', 'content': 'Hello! How can I assist you today? ðŸ˜Š'}}], 'created': 1744143818, 'model': 'qwen-max', 'usage': {'prompt_tokens': 30, 'completion_tokens': 148, 'total_tokens': 178, 'prompt_tokens_details': {'cached_tokens': 0}}}
```
{% endcode %}

</details>
