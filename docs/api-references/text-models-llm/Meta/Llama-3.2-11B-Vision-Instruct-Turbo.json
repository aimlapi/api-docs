{"paths":{"/v1/chat/completions":{"post":{"operationId":"ChatCompletionsControllerV1_completeChat_v1","summary":"Generate a conversational response using a language model.","description":"Creates a chat completion using a language model, allowing interactive conversation by predicting the next response based on the given chat history. This is useful for AI-driven dialogue systems and virtual assistants.","parameters":[],"requestBody":{"required":true,"content":{"application/json":{"schema":{"type":"object","properties":{"model":{"enum":["meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo"]},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"type":"string"},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string"},"name":{"type":"string"}},"required":["role"],"additionalProperties":false}]}},"max_tokens":{"type":"number","minimum":1,"default":512},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"n":{"type":"integer","minimum":1},"seed":{"type":"integer","minimum":1},"top_p":{"type":"number","minimum":0.01,"maximum":1},"top_k":{"type":"number"},"temperature":{"type":"number"},"repetition_penalty":{"type":"number","nullable":true},"logprobs":{"type":"boolean","nullable":true},"echo":{"type":"boolean"},"min_p":{"type":"number","minimum":0,"maximum":1},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true}},"required":["description","name"]}},"required":["type","function"]}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"]},"json_schema":{"type":"object","properties":{"name":{"type":"string"},"schema":{"type":"object","additionalProperties":{"nullable":true}},"strict":{"type":"boolean"},"description":{"type":"string"}},"required":["name"],"additionalProperties":false}},"required":["type","json_schema"],"additionalProperties":false}]}},"required":["model","messages"]}}}},"responses":{"201":{"description":""}},"tags":["Chat Completions"],"security":[{"access-token":[]}]}}},"openapi":"3.0.0","info":{"title":"AI/ML Gateway","description":"","version":"1.0","contact":{}},"tags":[],"servers":[{"url":"https://api.aimlapi.com"}],"components":{"securitySchemes":{"access-token":{"scheme":"bearer","bearerFormat":"<YOUR_AIMLAPI_KEY>","type":"http","in":"header","description":"Bearer key"}},"schemas":{"LlmAssistant.v1.CreateAssistantDTO":{"type":"object","properties":{"model":{"type":"string","enum":["gpt-4o","gpt-4o-2024-08-06","gpt-4o-2024-05-13","gpt-4o-mini","gpt-4o-mini-2024-07-18","chatgpt-4o-latest","gpt-4-turbo","gpt-4-turbo-2024-04-09","gpt-4","gpt-4-0125-preview","gpt-4-1106-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125","gpt-3.5-turbo-1106","o1-preview","o1-preview-2024-09-12","o1-mini","o1-mini-2024-09-12","o3-mini","gpt-4.5-preview","gpt-4o-audio-preview","gpt-4o-mini-audio-preview","gpt-4o-search-preview","gpt-4o-mini-search-preview"],"description":"ID of the model to use"},"description":{"type":"string","nullable":true,"description":"The description of the assistant. The maximum length is 512 characters"},"instructions":{"type":"string","nullable":true,"description":"The system instructions that the assistant uses. The maximum length is 256,000 characters"},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"name":{"type":"string","nullable":true,"description":"The name of the assistant. The maximum length is 256 characters"},"reasoning_effort":{"type":"string","nullable":true,"enum":["low","medium","high"],"description":"Constrains effort on reasoning for reasoning models"},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}],"description":"Specifies the format that the model must output"},"temperature":{"type":"number","nullable":true,"minimum":0,"maximum":2,"description":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."},"tools":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]},"description":"A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. "},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1,"description":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both."}},"required":["model"]},"LlmAssistant.v1.CreateAssistantResponseDTO":{"type":"object","properties":{"model":{"type":"string","description":"ID of the model to use."},"description":{"type":"string","nullable":true,"description":"The description of the assistant. The maximum length is 512 characters"},"instructions":{"type":"string","nullable":true,"description":"The system instructions that the assistant uses. The maximum length is 256,000 characters"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"name":{"type":"string","nullable":true,"description":"The name of the assistant. The maximum length is 256 characters"},"reasoning_effort":{"type":"string","nullable":true,"enum":["low","medium","high"],"description":"Constrains effort on reasoning for reasoning models"},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}],"description":"Specifies the format that the model must output"},"temperature":{"type":"number","nullable":true,"minimum":0,"maximum":2,"description":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."},"tools":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]},"description":"A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. "},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1,"description":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the assistant was created"},"object":{"type":"string","enum":["assistant"],"description":"The object type"}},"required":["model","id","created_at","object"]},"LlmAssistant.v1.GetAssistantsDTO":{"type":"object","properties":{"limit":{"type":"integer","minimum":1,"maximum":100,"description":"A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20."},"order":{"type":"string","enum":["asc","desc"],"description":"Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order."},"before":{"type":"string","description":"A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list."},"after":{"type":"string","description":"A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list."}},"additionalProperties":false},"LlmAssistant.v1.GetAssistantsResponseDTO":{"type":"object","properties":{"object":{"type":"string","enum":["list"]},"data":{"type":"array","items":{"type":"object","properties":{"model":{"type":"string","description":"ID of the model to use."},"description":{"type":"string","nullable":true,"description":"The description of the assistant. The maximum length is 512 characters"},"instructions":{"type":"string","nullable":true,"description":"The system instructions that the assistant uses. The maximum length is 256,000 characters"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"name":{"type":"string","nullable":true,"description":"The name of the assistant. The maximum length is 256 characters"},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the assistant was created"},"object":{"type":"string","enum":["assistant"],"description":"The object type"}},"required":["model","id","created_at","object"]}}},"required":["object","data"]},"LlmAssistant.v1.GetAssistantResponseDTO":{"type":"object","properties":{"model":{"type":"string","description":"ID of the model to use."},"description":{"type":"string","nullable":true,"description":"The description of the assistant. The maximum length is 512 characters"},"instructions":{"type":"string","nullable":true,"description":"The system instructions that the assistant uses. The maximum length is 256,000 characters"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"name":{"type":"string","nullable":true,"description":"The name of the assistant. The maximum length is 256 characters"},"reasoning_effort":{"type":"string","nullable":true,"enum":["low","medium","high"],"description":"Constrains effort on reasoning for reasoning models"},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}],"description":"Specifies the format that the model must output"},"temperature":{"type":"number","nullable":true,"minimum":0,"maximum":2,"description":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."},"tools":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]},"description":"A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. "},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1,"description":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the assistant was created"},"object":{"type":"string","enum":["assistant"],"description":"The object type"}},"required":["model","id","created_at","object"]},"LlmAssistant.v1.UpdateAssistantDTO":{"allOf":[{"$ref":"#/components/schemas/LlmAssistant.v1.CreateAssistantDTO"},{"type":"object","properties":{}}]},"LlmAssistant.v1.UpdateAssistantResponseDTO":{"type":"object","properties":{"model":{"type":"string","description":"ID of the model to use."},"description":{"type":"string","nullable":true,"description":"The description of the assistant. The maximum length is 512 characters"},"instructions":{"type":"string","nullable":true,"description":"The system instructions that the assistant uses. The maximum length is 256,000 characters"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"name":{"type":"string","nullable":true,"description":"The name of the assistant. The maximum length is 256 characters"},"reasoning_effort":{"type":"string","nullable":true,"enum":["low","medium","high"],"description":"Constrains effort on reasoning for reasoning models"},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}],"description":"Specifies the format that the model must output"},"temperature":{"type":"number","nullable":true,"minimum":0,"maximum":2,"description":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."},"tools":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]},"description":"A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. "},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1,"description":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the assistant was created"},"object":{"type":"string","enum":["assistant"],"description":"The object type"}},"required":["model","id","created_at","object"]},"LlmAssistant.v1.DeleteAssistantResponseDTO":{"type":"object","properties":{"id":{"type":"string"},"object":{"type":"string","enum":["assistant.deleted"]},"deleted":{"type":"boolean"}},"required":["id","object","deleted"]},"LlmThread.v1.GetThreadResponseDTO":{"type":"object","properties":{"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the thread was created"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"object":{"type":"string","enum":["thread"],"description":"The object type"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this thread. There can be a maximum of 1 vector store attached to the thread."}}}},"description":"A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."}},"required":["id","created_at","object","tool_resources"]},"LlmThread.v1.CreateThreadDTO":{"type":"object","properties":{"messages":{"type":"array","items":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string","description":"The text contents of the message"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"string","description":"Text content to be sent to the model"},"type":{"type":"string","enum":["text"]}},"required":["text","type"]}]},"description":"An array of content parts with a defined type, each can be of type text or images can be passed with image_url or image_file"}]},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}},"required":["role","content"]},"description":"A list of messages to start the thread with"},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"tool_resources":{"type":"object","properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."}},"additionalProperties":false},"LlmThread.v1.CreateThreadResponseDTO":{"type":"object","properties":{"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the thread was created"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"object":{"type":"string","enum":["thread"],"description":"The object type"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this thread. There can be a maximum of 1 vector store attached to the thread."}}}},"description":"A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."}},"required":["id","created_at","object","tool_resources"]},"LlmThread.v1.UpdateThreadDTO":{"type":"object","properties":{"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"tool_resources":{"type":"object","properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"nullable":true},"description":"The vector store attached to this thread. There can be a maximum of 1 vector store attached to the thread."}}}},"required":["code_interpreter","file_search"],"description":"A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."}},"additionalProperties":false},"LlmThread.v1.UpdateThreadResponseDTO":{"type":"object","properties":{"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the thread was created"},"metadata":{"nullable":true,"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"object":{"type":"string","enum":["thread"],"description":"The object type"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this thread. There can be a maximum of 1 vector store attached to the thread."}}}},"description":"A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."}},"required":["id","created_at","object","tool_resources"]},"LlmThread.v1.DeleteThreadResponseDTO":{"type":"object","properties":{"id":{"type":"string"},"object":{"type":"string","enum":["thread.deleted"]},"deleted":{"type":"boolean"}},"required":["id","object","deleted"]},"LlmThreadMessage.v1.GetThreadMessagesDTO":{"type":"object","properties":{"limit":{"type":"integer","minimum":1,"maximum":100,"description":"A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20."},"order":{"type":"string","enum":["asc","desc"],"description":"Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order."},"before":{"type":"string","description":"A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list."},"after":{"type":"string","description":"A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list."},"run_id":{"type":"string","description":"Filter messages by the run ID that generated them"}},"additionalProperties":false},"LlmThreadMessage.v1.GetThreadMessagesResponseDTO":{"type":"object","properties":{"object":{"type":"string","enum":["list"]},"data":{"type":"array","items":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"object","properties":{"annotations":{"type":"array","items":{"anyOf":[{"type":"object","properties":{"end_index":{"type":"integer"},"file_citation":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the specific File the citation is from."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced"},"type":{"type":"string","enum":["file_citation"]}},"required":["end_index","file_citation","start_index","text","type"]},{"type":"object","properties":{"end_index":{"type":"integer"},"file_path":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file that was generated."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced."},"type":{"type":"string","enum":["file_path"]}},"required":["end_index","file_path","start_index","text","type"]}]}},"value":{"type":"string"}},"required":["annotations","value"]},"type":{"type":"string","enum":["text"]}},"required":["text","type"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}],"description":"The content of the message in array of text and/or images"},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"object":{"type":"string","enum":["thread.message"],"description":"The object type"},"status":{"type":"string","enum":["completed","incomplete","in_progress"],"description":"The status of the message"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the message was created."},"completed_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was completed"},"incomplete_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was marked as incomplete"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string","description":"The reason the message is incomplete"}},"required":["reason"],"description":"On an incomplete message, details about why the message is incomplete"},"assistant_id":{"type":"string","nullable":true,"description":"If applicable, the ID of the assistant that authored this message."},"thread_id":{"type":"string","description":"The thread ID that this message belongs to"},"run_id":{"type":"string","nullable":true,"description":"The ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints."}},"required":["role","content","id","object","status","created_at","completed_at","incomplete_at","incomplete_details","assistant_id","thread_id","run_id"]}},"first_id":{"type":"string"},"last_id":{"type":"string"},"has_more":{"type":"boolean"}},"required":["object","data","first_id","last_id","has_more"]},"LlmThreadMessage.v1.CreateThreadMessageDTO":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string","description":"The text contents of the message"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"string","description":"Text content to be sent to the model"},"type":{"type":"string","enum":["text"]}},"required":["text","type"]}]},"description":"An array of content parts with a defined type, each can be of type text or images can be passed with image_url or image_file"}]},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}},"required":["role","content"],"additionalProperties":false},"LlmThreadMessage.v1.CreateThreadMessageResponseDTO":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"object","properties":{"annotations":{"type":"array","items":{"anyOf":[{"type":"object","properties":{"end_index":{"type":"integer"},"file_citation":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the specific File the citation is from."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced"},"type":{"type":"string","enum":["file_citation"]}},"required":["end_index","file_citation","start_index","text","type"]},{"type":"object","properties":{"end_index":{"type":"integer"},"file_path":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file that was generated."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced."},"type":{"type":"string","enum":["file_path"]}},"required":["end_index","file_path","start_index","text","type"]}]}},"value":{"type":"string"}},"required":["annotations","value"]},"type":{"type":"string","enum":["text"]}},"required":["text","type"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}],"description":"The content of the message in array of text and/or images"},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"object":{"type":"string","enum":["thread.message"],"description":"The object type"},"status":{"type":"string","enum":["completed","incomplete","in_progress"],"description":"The status of the message"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the message was created."},"completed_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was completed"},"incomplete_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was marked as incomplete"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string","description":"The reason the message is incomplete"}},"required":["reason"],"description":"On an incomplete message, details about why the message is incomplete"},"assistant_id":{"type":"string","nullable":true,"description":"If applicable, the ID of the assistant that authored this message."},"thread_id":{"type":"string","description":"The thread ID that this message belongs to"},"run_id":{"type":"string","nullable":true,"description":"The ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints."}},"required":["role","content","id","object","status","created_at","completed_at","incomplete_at","incomplete_details","assistant_id","thread_id","run_id"]},"LlmThreadMessage.v1.GetThreadMessageResponseDTO":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"object","properties":{"annotations":{"type":"array","items":{"anyOf":[{"type":"object","properties":{"end_index":{"type":"integer"},"file_citation":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the specific File the citation is from."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced"},"type":{"type":"string","enum":["file_citation"]}},"required":["end_index","file_citation","start_index","text","type"]},{"type":"object","properties":{"end_index":{"type":"integer"},"file_path":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file that was generated."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced."},"type":{"type":"string","enum":["file_path"]}},"required":["end_index","file_path","start_index","text","type"]}]}},"value":{"type":"string"}},"required":["annotations","value"]},"type":{"type":"string","enum":["text"]}},"required":["text","type"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}],"description":"The content of the message in array of text and/or images"},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"object":{"type":"string","enum":["thread.message"],"description":"The object type"},"status":{"type":"string","enum":["completed","incomplete","in_progress"],"description":"The status of the message"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the message was created."},"completed_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was completed"},"incomplete_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was marked as incomplete"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string","description":"The reason the message is incomplete"}},"required":["reason"],"description":"On an incomplete message, details about why the message is incomplete"},"assistant_id":{"type":"string","nullable":true,"description":"If applicable, the ID of the assistant that authored this message."},"thread_id":{"type":"string","description":"The thread ID that this message belongs to"},"run_id":{"type":"string","nullable":true,"description":"The ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints."}},"required":["role","content","id","object","status","created_at","completed_at","incomplete_at","incomplete_details","assistant_id","thread_id","run_id"]},"LlmThreadMessage.v1.UpdateThreadMessageDTO":{"type":"object","properties":{"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}},"required":["metadata"],"additionalProperties":false},"LlmThreadMessage.v1.UpdateThreadMessageResponseDTO":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"object","properties":{"annotations":{"type":"array","items":{"anyOf":[{"type":"object","properties":{"end_index":{"type":"integer"},"file_citation":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the specific File the citation is from."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced"},"type":{"type":"string","enum":["file_citation"]}},"required":["end_index","file_citation","start_index","text","type"]},{"type":"object","properties":{"end_index":{"type":"integer"},"file_path":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file that was generated."}},"required":["file_id"]},"start_index":{"type":"integer"},"text":{"type":"string","description":"The text in the message content that needs to be replaced."},"type":{"type":"string","enum":["file_path"]}},"required":["end_index","file_path","start_index","text","type"]}]}},"value":{"type":"string"}},"required":["annotations","value"]},"type":{"type":"string","enum":["text"]}},"required":["text","type"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}],"description":"The content of the message in array of text and/or images"},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"id":{"type":"string","description":"The identifier, which can be referenced in API endpoints"},"object":{"type":"string","enum":["thread.message"],"description":"The object type"},"status":{"type":"string","enum":["completed","incomplete","in_progress"],"description":"The status of the message"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the message was created."},"completed_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was completed"},"incomplete_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the message was marked as incomplete"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string","description":"The reason the message is incomplete"}},"required":["reason"],"description":"On an incomplete message, details about why the message is incomplete"},"assistant_id":{"type":"string","nullable":true,"description":"If applicable, the ID of the assistant that authored this message."},"thread_id":{"type":"string","description":"The thread ID that this message belongs to"},"run_id":{"type":"string","nullable":true,"description":"The ID of the run associated with the creation of this message. Value is null when messages are created manually using the create message or create thread endpoints."}},"required":["role","content","id","object","status","created_at","completed_at","incomplete_at","incomplete_details","assistant_id","thread_id","run_id"]},"LlmThreadMessage.v1.DeleteThreadMessageResponseDTO":{"type":"object","properties":{"id":{"type":"string"},"object":{"type":"string","enum":["thread.message.deleted"]},"deleted":{"type":"boolean"}},"required":["id","object","deleted"]},"LlmThreadRun.v1.CreateThreadRunDTO":{"type":"object","properties":{"assistant_id":{"type":"string","description":"The ID of the assistant to use to execute this run"},"additional_instructions":{"type":"string","nullable":true,"description":"Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions."},"additional_messages":{"type":"array","nullable":true,"items":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string","description":"The text contents of the message"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"string","description":"Text content to be sent to the model"},"type":{"type":"string","enum":["text"]}},"required":["text","type"]}]},"description":"An array of content parts with a defined type, each can be of type text or images can be passed with image_url or image_file"}]},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}},"required":["role","content"]},"description":"Adds additional messages to the thread before creating the run."},"instructions":{"type":"string","nullable":true,"description":"Overrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis."},"max_completion_tokens":{"type":"integer","nullable":true,"description":"The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete"},"max_prompt_tokens":{"type":"integer","nullable":true,"description":"The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete"},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"model":{"type":"string","enum":["gpt-4o","gpt-4o-2024-08-06","gpt-4o-2024-05-13","gpt-4o-mini","gpt-4o-mini-2024-07-18","chatgpt-4o-latest","gpt-4-turbo","gpt-4-turbo-2024-04-09","gpt-4","gpt-4-0125-preview","gpt-4-1106-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125","gpt-3.5-turbo-1106","o1-preview","o1-preview-2024-09-12","o1-mini","o1-mini-2024-09-12","o3-mini","gpt-4.5-preview","gpt-4o-audio-preview","gpt-4o-mini-audio-preview","gpt-4o-search-preview","gpt-4o-mini-search-preview"],"description":"The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used."},"parallel_tool_calls":{"type":"boolean","description":"Whether to enable parallel function calling during tool use."},"reasoning_effort":{"type":"string","enum":["low","medium","high"],"description":"Constrains effort on reasoning for reasoning models"},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}],"description":"Specifies the format that the model must output"},"stream":{"type":"boolean","nullable":true,"description":"If true, returns a stream of events that happen during the Run as server-sent events"},"temperature":{"type":"number","minimum":0,"maximum":2,"description":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function","code_interpreter","file_search"],"description":"The type of the tool. If type is function, the function name must be set"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to call."}},"required":["name"]}},"required":["type"]},{"nullable":true}],"description":"Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user"},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]},"description":"Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis."},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1,"description":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string","enum":["auto","last_messages"]},"last_messages":{"type":"integer","nullable":true}},"required":["type"],"description":"Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run."}},"required":["assistant_id"]},"LlmThreadRun.v1.CreateThreadRunResponseDTO":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expires_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string"}}},"instructions":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded","invalid_prompt"]},"message":{"type":"string"}},"required":["code","message"]},"max_completion_tokens":{"type":"integer","nullable":true},"max_prompt_tokens":{"type":"integer","nullable":true},"metadata":{"nullable":true},"model":{"type":"string"},"object":{"type":"string","enum":["thread.run"]},"parallel_tool_calls":{"type":"boolean"},"required_action":{"type":"object","nullable":true,"properties":{"submit_tool_outputs":{"type":"object","properties":{"tool_calls":{"type":"array","items":{"type":"object","properties":{"function":{"type":"object","properties":{"arguments":{"type":"string"},"name":{"type":"string"}},"required":["arguments","name"]},"id":{"type":"string"},"type":{"type":"string","enum":["function"]}},"required":["function","id","type"]}}},"required":["tool_calls"]},"type":{"type":"string","enum":["submit_tool_outputs"]}},"required":["submit_tool_outputs","type"]},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}]},"started_at":{"type":"integer","nullable":true},"status":{"type":"string","enum":["queued","in_progress","requires_action","cancelling","cancelled","failed","completed","incomplete","expired"]},"temperature":{"type":"number","nullable":true},"thread_id":{"type":"string"},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string"},"function":{"type":"object","nullable":true,"properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type"]},{"nullable":true}]},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]}},"top_p":{"type":"number","nullable":true},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string"},"last_messages":{"type":"integer","nullable":true}},"required":["type"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expires_at","failed_at","id","incomplete_details","instructions","last_error","max_completion_tokens","max_prompt_tokens","model","object","parallel_tool_calls","required_action","response_format","started_at","status","thread_id"]},"LlmThreadRun.v1.CreateThreadAndRunDTO":{"type":"object","properties":{"assistant_id":{"type":"string","description":"The ID of the assistant to use to execute this run"},"instructions":{"type":"string","nullable":true,"description":"Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis."},"max_completion_tokens":{"type":"integer","nullable":true,"description":"The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status incomplete"},"max_prompt_tokens":{"type":"integer","nullable":true,"description":"The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status incomplete"},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"model":{"type":"string","nullable":true,"enum":["gpt-4o","gpt-4o-2024-08-06","gpt-4o-2024-05-13","gpt-4o-mini","gpt-4o-mini-2024-07-18","chatgpt-4o-latest","gpt-4-turbo","gpt-4-turbo-2024-04-09","gpt-4","gpt-4-0125-preview","gpt-4-1106-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125","gpt-3.5-turbo-1106","o1-preview","o1-preview-2024-09-12","o1-mini","o1-mini-2024-09-12","o3-mini","gpt-4.5-preview","gpt-4o-audio-preview","gpt-4o-mini-audio-preview","gpt-4o-search-preview","gpt-4o-mini-search-preview"],"description":"The ID of the Model to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used."},"parallel_tool_calls":{"type":"boolean","description":"Whether to enable parallel function calling during tool use."},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}],"description":"Specifies the format that the model must output"},"stream":{"type":"boolean","nullable":true,"description":"If true, returns a stream of events that happen during the Run as server-sent events"},"temperature":{"type":"number","nullable":true,"minimum":0,"maximum":2,"description":"What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."},"thread":{"type":"object","properties":{"messages":{"type":"array","items":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"],"description":"The role of the entity that is creating the message"},"content":{"anyOf":[{"type":"string","description":"The text contents of the message"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"image_file":{"type":"object","properties":{"file_id":{"type":"string","description":"The File ID of the image in the message content"},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image if specified by the user. low uses fewer tokens, you can opt in to high resolution using high."}},"required":["file_id"]},"type":{"type":"string","enum":["image_file"]}},"required":["image_file","type"]},{"type":"object","properties":{"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp."},"detail":{"type":"string","enum":["auto","low","high"],"description":"Specifies the detail level of the image. low uses fewer tokens, you can opt in to high resolution using high. Default value is auto"}},"required":["url"]},"type":{"type":"string","enum":["image_url"]}},"required":["image_url","type"]},{"type":"object","properties":{"text":{"type":"string","description":"Text content to be sent to the model"},"type":{"type":"string","enum":["text"]}},"required":["text","type"]}]},"description":"An array of content parts with a defined type, each can be of type text or images can be passed with image_url or image_file"}]},"attachments":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string","description":"The ID of the file to attach to the message"},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter","file_search"],"description":"The type of tool being defined"}},"required":["type"]},"description":"The tools to add this file to"}}},"description":"A list of files attached to the message, and the tools they should be added to."},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}},"required":["role","content"]}},"metadata":{"type":"object","nullable":true,"additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."}},"required":["messages"],"description":"Options to create a new thread. If no thread is provided when running a request, an empty thread will be created"},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function","code_interpreter","file_search"],"description":"The type of the tool. If type is function, the function name must be set"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to call."}},"required":["name"]}},"required":["type"]}],"description":"Controls which (if any) tool is called by the model. none means the model will not call any tools and instead generates a message. auto is the default value and means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools before responding to the user"},"tool_resources":{"type":"object","nullable":true,"properties":{"code_interpreter":{"type":"object","properties":{"file_ids":{"type":"array","items":{"nullable":true},"description":"A list of file IDs made available to the code_interpreter tool. There can be a maximum of 20 files associated with the tool."}}},"file_search":{"type":"object","properties":{"vector_store_ids":{"type":"array","items":{"type":"string"},"description":"The vector store attached to this assistant. There can be a maximum of 1 vector store attached to the assistant."},"vector_stores":{"type":"array","items":{"type":"object","properties":{"chunking_strategy":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["static"]},"static":{"type":"object","properties":{"chunk_overlap_tokens":{"type":"integer","description":"The number of tokens that overlap between chunks. The default value is 400. Note that the overlap must not exceed half of max_chunk_size_tokens"},"max_chunk_size_tokens":{"type":"integer","description":"The maximum number of tokens in each chunk. The default value is 800. The minimum value is 100 and the maximum value is 4096"}},"required":["chunk_overlap_tokens","max_chunk_size_tokens"]}},"required":["type","static"]}],"description":"The chunking strategy used to chunk the file(s). If not set, will use the auto strategy."},"file_ids":{"type":"array","items":{"type":"string"},"description":"A list of file IDs to add to the vector store. There can be a maximum of 10000 files in a vector store."},"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}}},"description":"A helper to create a vector store with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant."}}}},"description":"A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs."},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]},"description":"Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis."},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1,"description":"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string","enum":["auto","last_messages"],"description":"The truncation strategy to use for the thread. The default is auto. If set to last_messages, the thread will be truncated to the n most recent messages in the thread. When set to auto, messages in the middle of the thread will be dropped to fit the context length of the model, max_prompt_tokens."},"last_messages":{"type":"integer","nullable":true,"description":"The number of most recent messages from the thread when constructing the context for the run."}},"required":["type"],"description":"Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run."}},"required":["assistant_id"]},"LlmThreadRun.v1.GetThreadRunsDTO":{"type":"object","properties":{"limit":{"type":"integer","minimum":1,"maximum":100,"description":"A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20."},"order":{"type":"string","enum":["asc","desc"],"description":"Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order."},"before":{"type":"string","description":"A cursor for use in pagination. before is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list."},"after":{"type":"string","description":"A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list."}},"additionalProperties":false},"LlmThreadRun.v1.GetThreadRunsResponseDTO":{"type":"object","properties":{"object":{"type":"string","enum":["list"]},"data":{"type":"array","items":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expires_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string"}}},"instructions":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded","invalid_prompt"]},"message":{"type":"string"}},"required":["code","message"]},"max_completion_tokens":{"type":"integer","nullable":true},"max_prompt_tokens":{"type":"integer","nullable":true},"metadata":{"nullable":true},"model":{"type":"string"},"object":{"type":"string","enum":["thread.run"]},"parallel_tool_calls":{"type":"boolean"},"required_action":{"type":"object","nullable":true,"properties":{"submit_tool_outputs":{"type":"object","properties":{"tool_calls":{"type":"array","items":{"type":"object","properties":{"function":{"type":"object","properties":{"arguments":{"type":"string"},"name":{"type":"string"}},"required":["arguments","name"]},"id":{"type":"string"},"type":{"type":"string","enum":["function"]}},"required":["function","id","type"]}}},"required":["tool_calls"]},"type":{"type":"string","enum":["submit_tool_outputs"]}},"required":["submit_tool_outputs","type"]},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}]},"started_at":{"type":"integer","nullable":true},"status":{"type":"string","enum":["queued","in_progress","requires_action","cancelling","cancelled","failed","completed","incomplete","expired"]},"temperature":{"type":"number","nullable":true},"thread_id":{"type":"string"},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string"},"function":{"type":"object","nullable":true,"properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type"]},{"nullable":true}]},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]}},"top_p":{"type":"number","nullable":true},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string"},"last_messages":{"type":"integer","nullable":true}},"required":["type"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expires_at","failed_at","id","incomplete_details","instructions","last_error","max_completion_tokens","max_prompt_tokens","model","object","parallel_tool_calls","required_action","response_format","started_at","status","thread_id"]}},"first_id":{"type":"string"},"last_id":{"type":"string"},"has_more":{"type":"boolean"}},"required":["object","data","first_id","last_id","has_more"]},"LlmThreadRun.v1.GetThreadRunReponsetDTO":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expires_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string"}}},"instructions":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded","invalid_prompt"]},"message":{"type":"string"}},"required":["code","message"]},"max_completion_tokens":{"type":"integer","nullable":true},"max_prompt_tokens":{"type":"integer","nullable":true},"metadata":{"nullable":true},"model":{"type":"string"},"object":{"type":"string","enum":["thread.run"]},"parallel_tool_calls":{"type":"boolean"},"required_action":{"type":"object","nullable":true,"properties":{"submit_tool_outputs":{"type":"object","properties":{"tool_calls":{"type":"array","items":{"type":"object","properties":{"function":{"type":"object","properties":{"arguments":{"type":"string"},"name":{"type":"string"}},"required":["arguments","name"]},"id":{"type":"string"},"type":{"type":"string","enum":["function"]}},"required":["function","id","type"]}}},"required":["tool_calls"]},"type":{"type":"string","enum":["submit_tool_outputs"]}},"required":["submit_tool_outputs","type"]},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}]},"started_at":{"type":"integer","nullable":true},"status":{"type":"string","enum":["queued","in_progress","requires_action","cancelling","cancelled","failed","completed","incomplete","expired"]},"temperature":{"type":"number","nullable":true},"thread_id":{"type":"string"},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string"},"function":{"type":"object","nullable":true,"properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type"]},{"nullable":true}]},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]}},"top_p":{"type":"number","nullable":true},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string"},"last_messages":{"type":"integer","nullable":true}},"required":["type"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expires_at","failed_at","id","incomplete_details","instructions","last_error","max_completion_tokens","max_prompt_tokens","model","object","parallel_tool_calls","required_action","response_format","started_at","status","thread_id"]},"LlmThreadRun.v1.UpdateThreadRunDTO":{"type":"object","properties":{"metadata":{"type":"object","additionalProperties":{"type":"string"},"description":"Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters."}},"required":["metadata"],"additionalProperties":false},"LlmThreadRun.v1.UpdateThreadRunResponseDTO":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expires_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string"}}},"instructions":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded","invalid_prompt"]},"message":{"type":"string"}},"required":["code","message"]},"max_completion_tokens":{"type":"integer","nullable":true},"max_prompt_tokens":{"type":"integer","nullable":true},"metadata":{"nullable":true},"model":{"type":"string"},"object":{"type":"string","enum":["thread.run"]},"parallel_tool_calls":{"type":"boolean"},"required_action":{"type":"object","nullable":true,"properties":{"submit_tool_outputs":{"type":"object","properties":{"tool_calls":{"type":"array","items":{"type":"object","properties":{"function":{"type":"object","properties":{"arguments":{"type":"string"},"name":{"type":"string"}},"required":["arguments","name"]},"id":{"type":"string"},"type":{"type":"string","enum":["function"]}},"required":["function","id","type"]}}},"required":["tool_calls"]},"type":{"type":"string","enum":["submit_tool_outputs"]}},"required":["submit_tool_outputs","type"]},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}]},"started_at":{"type":"integer","nullable":true},"status":{"type":"string","enum":["queued","in_progress","requires_action","cancelling","cancelled","failed","completed","incomplete","expired"]},"temperature":{"type":"number","nullable":true},"thread_id":{"type":"string"},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string"},"function":{"type":"object","nullable":true,"properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type"]},{"nullable":true}]},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]}},"top_p":{"type":"number","nullable":true},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string"},"last_messages":{"type":"integer","nullable":true}},"required":["type"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expires_at","failed_at","id","incomplete_details","instructions","last_error","max_completion_tokens","max_prompt_tokens","model","object","parallel_tool_calls","required_action","response_format","started_at","status","thread_id"]},"LlmThreadRun.v1.SubmitToolToRunDTO":{"type":"object","properties":{"tool_outputs":{"type":"array","items":{"type":"object","properties":{"output":{"type":"string","description":"The output of the tool call to be submitted to continue the run."},"tool_call_id":{"type":"string","description":"The ID of the tool call in the required_action object within the run object the output is being submitted for."}}},"description":"A list of tools for which the outputs are being submitted."},"stream":{"type":"boolean","nullable":true,"description":"If true, returns a stream of events that happen during the Run as server-sent events"}},"required":["tool_outputs"],"additionalProperties":false},"LlmThreadRun.v1.SubmitToolToRunResponseDTO":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expires_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"incomplete_details":{"type":"object","nullable":true,"properties":{"reason":{"type":"string"}}},"instructions":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded","invalid_prompt"]},"message":{"type":"string"}},"required":["code","message"]},"max_completion_tokens":{"type":"integer","nullable":true},"max_prompt_tokens":{"type":"integer","nullable":true},"metadata":{"nullable":true},"model":{"type":"string"},"object":{"type":"string","enum":["thread.run"]},"parallel_tool_calls":{"type":"boolean"},"required_action":{"type":"object","nullable":true,"properties":{"submit_tool_outputs":{"type":"object","properties":{"tool_calls":{"type":"array","items":{"type":"object","properties":{"function":{"type":"object","properties":{"arguments":{"type":"string"},"name":{"type":"string"}},"required":["arguments","name"]},"id":{"type":"string"},"type":{"type":"string","enum":["function"]}},"required":["function","id","type"]}}},"required":["tool_calls"]},"type":{"type":"string","enum":["submit_tool_outputs"]}},"required":["submit_tool_outputs","type"]},"response_format":{"anyOf":[{"type":"string","enum":["auto"]},{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},{"nullable":true}]},"started_at":{"type":"integer","nullable":true},"status":{"type":"string","enum":["queued","in_progress","requires_action","cancelling","cancelled","failed","completed","incomplete","expired"]},"temperature":{"type":"number","nullable":true},"thread_id":{"type":"string"},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string"},"function":{"type":"object","nullable":true,"properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type"]},{"nullable":true}]},"tools":{"type":"array","nullable":true,"items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["code_interpreter"],"description":"The type of tool being defined"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["file_search"],"description":"The type of tool being defined"},"file_search":{"type":"object","properties":{"max_num_results":{"type":"integer","minimum":1,"maximum":50,"description":"The maximum number of results the file search tool should output"},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1,"description":"The score threshold for the file search. All values must be a floating point number between 0 and 1"},"ranker":{"type":"string","enum":["auto","default_2024_08_21"],"description":"The ranker to use for the file search. If not specified will use the auto ranker"}},"required":["score_threshold"],"description":"The ranking options for the file search. If not specified, the file search tool will use the auto ranker and a score_threshold of 0."}},"description":"Overrides for the file search tool"}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"],"description":"The type of tool being defined"},"function":{"type":"object","properties":{"name":{"type":"string","description":"The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64."},"description":{"type":"string","description":"A description of what the function does, used by the model to choose when and how to call the function."},"parameters":{"type":"object","additionalProperties":{"nullable":true},"description":"The parameters the functions accepts, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the parameters field. Only a subset of JSON Schema is supported when strict is true"}},"required":["name"]}},"required":["type","function"]}]}},"top_p":{"type":"number","nullable":true},"truncation_strategy":{"type":"object","nullable":true,"properties":{"type":{"type":"string"},"last_messages":{"type":"integer","nullable":true}},"required":["type"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expires_at","failed_at","id","incomplete_details","instructions","last_error","max_completion_tokens","max_prompt_tokens","model","object","parallel_tool_calls","required_action","response_format","started_at","status","thread_id"]},"LlmThreadRunSteps.v1.GetRunStepsResponseDTO":{"type":"object","properties":{"object":{"type":"string","enum":["list"]},"data":{"type":"array","items":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expired_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded"]},"message":{"type":"string"}},"required":["code","message"]},"metadata":{"nullable":true},"object":{"type":"string","enum":["thread.run.step"]},"run_id":{"type":"string"},"status":{"type":"string","enum":["in_progress","cancelled","failed","completed","expired"]},"step_details":{"anyOf":[{"type":"object","properties":{"message_creation":{"type":"object","properties":{"message_id":{"type":"string"}},"required":["message_id"]},"type":{"type":"string","enum":["message_creation"]}},"required":["message_creation","type"]},{"type":"object","properties":{"tool_calls":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"id":{"type":"string"},"code_interpreter":{"type":"object","properties":{"input":{"type":"string"},"outputs":{"type":"array","items":{"anyOf":[{"type":"object","properties":{"logs":{"type":"string"},"type":{"type":"string","enum":["logs"]}},"required":["logs","type"]},{"type":"object","properties":{"image":{"type":"object","properties":{"file_id":{"type":"string"}},"required":["file_id"]},"type":{"type":"string","enum":["image"]}},"required":["image","type"]}]}}},"required":["input","outputs"]},"type":{"type":"string","enum":["code_interpreter"]}},"required":["id","code_interpreter","type"]},{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["file_search"]},"file_search":{"type":"object","properties":{"results":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string"},"file_name":{"type":"string"},"score":{"type":"number"},"content":{"type":"array","nullable":true,"items":{"type":"object","properties":{"text":{"type":"string","nullable":true},"type":{"type":"string","nullable":true}}}}},"required":["file_id","file_name","score"]}},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1},"ranker":{"type":"string"}},"required":["score_threshold","ranker"]}}}},"required":["id","type"]},{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"},"ouptut":{"type":"string","nullable":true}},"required":["name"]}},"required":["id","type","function"]}]}},"type":{"type":"string","enum":["tool_calls"]}},"required":["tool_calls","type"]}]},"thread_id":{"type":"string"},"type":{"type":"string","enum":["message_creation","tool_calls"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expired_at","failed_at","id","last_error","object","run_id","status","step_details","thread_id","type","usage"]}},"first_id":{"type":"string"},"last_id":{"type":"string"},"has_more":{"type":"boolean"}},"required":["object","data","first_id","last_id","has_more"]},"LlmThreadRunSteps.v1.GetRunStepResponseDTO":{"type":"object","properties":{"assistant_id":{"type":"string"},"cancelled_at":{"type":"integer","nullable":true},"completed_at":{"type":"integer","nullable":true},"created_at":{"type":"integer"},"expired_at":{"type":"integer","nullable":true},"failed_at":{"type":"integer","nullable":true},"id":{"type":"string"},"last_error":{"type":"object","nullable":true,"properties":{"code":{"type":"string","enum":["server_error","rate_limit_exceeded"]},"message":{"type":"string"}},"required":["code","message"]},"metadata":{"nullable":true},"object":{"type":"string","enum":["thread.run.step"]},"run_id":{"type":"string"},"status":{"type":"string","enum":["in_progress","cancelled","failed","completed","expired"]},"step_details":{"anyOf":[{"type":"object","properties":{"message_creation":{"type":"object","properties":{"message_id":{"type":"string"}},"required":["message_id"]},"type":{"type":"string","enum":["message_creation"]}},"required":["message_creation","type"]},{"type":"object","properties":{"tool_calls":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"id":{"type":"string"},"code_interpreter":{"type":"object","properties":{"input":{"type":"string"},"outputs":{"type":"array","items":{"anyOf":[{"type":"object","properties":{"logs":{"type":"string"},"type":{"type":"string","enum":["logs"]}},"required":["logs","type"]},{"type":"object","properties":{"image":{"type":"object","properties":{"file_id":{"type":"string"}},"required":["file_id"]},"type":{"type":"string","enum":["image"]}},"required":["image","type"]}]}}},"required":["input","outputs"]},"type":{"type":"string","enum":["code_interpreter"]}},"required":["id","code_interpreter","type"]},{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["file_search"]},"file_search":{"type":"object","properties":{"results":{"type":"array","nullable":true,"items":{"type":"object","properties":{"file_id":{"type":"string"},"file_name":{"type":"string"},"score":{"type":"number"},"content":{"type":"array","nullable":true,"items":{"type":"object","properties":{"text":{"type":"string","nullable":true},"type":{"type":"string","nullable":true}}}}},"required":["file_id","file_name","score"]}},"ranking_options":{"type":"object","properties":{"score_threshold":{"type":"number","minimum":0,"maximum":1},"ranker":{"type":"string"}},"required":["score_threshold","ranker"]}}}},"required":["id","type"]},{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"},"ouptut":{"type":"string","nullable":true}},"required":["name"]}},"required":["id","type","function"]}]}},"type":{"type":"string","enum":["tool_calls"]}},"required":["tool_calls","type"]}]},"thread_id":{"type":"string"},"type":{"type":"string","enum":["message_creation","tool_calls"]},"usage":{"type":"object","nullable":true,"properties":{"completion_tokens":{"type":"integer"},"prompt_tokens":{"type":"integer"},"total_tokens":{"type":"integer"}},"required":["completion_tokens","prompt_tokens","total_tokens"]}},"required":["assistant_id","cancelled_at","completed_at","created_at","expired_at","failed_at","id","last_error","object","run_id","status","step_details","thread_id","type","usage"]},"Voice.v1.SpeechToTextPayloadDTO":{"anyOf":[{"type":"object","properties":{"model":{"type":"string","enum":["#g1_nova-2-general","#g1_nova-2-meeting","#g1_nova-2-phonecall","#g1_nova-2-voicemail","#g1_nova-2-finance","#g1_nova-2-conversationalai","#g1_nova-2-video","#g1_nova-2-medical","#g1_nova-2-drivethru","#g1_nova-2-automotive","#g1_whisper-large","#g1_whisper-medium","#g1_whisper-small","#g1_whisper-tiny","#g1_whisper-base"]},"custom_intent":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}}]},"custom_topic":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}}]},"custom_intent_mode":{"type":"string","enum":["strict","extended"]},"custom_topic_mode":{"type":"string","enum":["strict","extended"]},"detect_language":{"type":"boolean"},"detect_entities":{"type":"boolean"},"detect_topics":{"type":"boolean"},"diarize":{"type":"boolean"},"dictation":{"type":"boolean"},"diarize_version":{"type":"string"},"extra":{"type":"string"},"filler_words":{"type":"boolean"},"intents":{"type":"boolean"},"keywords":{"type":"string"},"language":{"type":"string"},"measurements":{"type":"boolean"},"multi_channel":{"type":"boolean"},"numerals":{"type":"boolean"},"paragraphs":{"type":"boolean"},"profanity_filter":{"type":"boolean"},"punctuate":{"type":"boolean"},"search":{"type":"string"},"sentiment":{"type":"boolean"},"smart_format":{"type":"boolean"},"summarize":{"type":"string"},"tag":{"type":"array","items":{"type":"string"}},"topics":{"type":"boolean"},"utterances":{"type":"boolean"},"utt_split":{"type":"number"}},"required":["model"]},{"type":"object","properties":{"model":{"type":"string","enum":["#g1_nova-2-general","#g1_nova-2-meeting","#g1_nova-2-phonecall","#g1_nova-2-voicemail","#g1_nova-2-finance","#g1_nova-2-conversationalai","#g1_nova-2-video","#g1_nova-2-medical","#g1_nova-2-drivethru","#g1_nova-2-automotive","#g1_whisper-large","#g1_whisper-medium","#g1_whisper-small","#g1_whisper-tiny","#g1_whisper-base"]},"custom_intent":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}}]},"custom_topic":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}}]},"custom_intent_mode":{"type":"string","enum":["strict","extended"]},"custom_topic_mode":{"type":"string","enum":["strict","extended"]},"detect_language":{"type":"boolean"},"detect_entities":{"type":"boolean"},"detect_topics":{"type":"boolean"},"diarize":{"type":"boolean"},"dictation":{"type":"boolean"},"diarize_version":{"type":"string"},"extra":{"type":"string"},"filler_words":{"type":"boolean"},"intents":{"type":"boolean"},"keywords":{"type":"string"},"language":{"type":"string"},"measurements":{"type":"boolean"},"multi_channel":{"type":"boolean"},"numerals":{"type":"boolean"},"paragraphs":{"type":"boolean"},"profanity_filter":{"type":"boolean"},"punctuate":{"type":"boolean"},"search":{"type":"string"},"sentiment":{"type":"boolean"},"smart_format":{"type":"boolean"},"summarize":{"type":"string"},"tag":{"type":"array","items":{"type":"string"}},"topics":{"type":"boolean"},"utterances":{"type":"boolean"},"utt_split":{"type":"number"},"url":{"type":"string","format":"uri"}},"required":["model","url"]}]},"Voice.v1.SpeechToTextResponse":{"type":"object","properties":{"metadata":{"type":"object","properties":{"transaction_key":{"type":"string"},"request_id":{"type":"string"},"sha256":{"type":"string"},"created":{"type":"string","format":"date-time"},"duration":{"type":"number"},"channels":{"type":"number"},"models":{"type":"array","items":{"type":"string"}},"model_info":{"type":"object","additionalProperties":{"type":"object","properties":{"name":{"type":"string"},"version":{"type":"string"},"arch":{"type":"string"}},"required":["name","version","arch"]}}},"required":["transaction_key","request_id","sha256","created","duration","channels","models","model_info"]}},"required":["metadata"],"additionalProperties":false},"Voice.v1.SpeechToTextCreateResponseDTO":{"type":"object","properties":{"generation_id":{"type":"string","format":"uuid"}},"required":["generation_id"]},"Voice.v1.SpeechToTextGetResponseDTO":{"type":"object","properties":{"status":{"type":"string"},"result":{"type":"object","properties":{"metadata":{"type":"object","properties":{"transaction_key":{"type":"string"},"request_id":{"type":"string"},"sha256":{"type":"string"},"created":{"type":"string","format":"date-time"},"duration":{"type":"number"},"channels":{"type":"number"},"models":{"type":"array","items":{"type":"string"}},"model_info":{"type":"object","additionalProperties":{"type":"object","properties":{"name":{"type":"string"},"version":{"type":"string"},"arch":{"type":"string"}},"required":["name","version","arch"]}}},"required":["transaction_key","request_id","sha256","created","duration","channels","models","model_info"]}},"required":["metadata"],"additionalProperties":false}},"required":["status"]},"Voice.v1.TextToSpeechPayload":{"type":"object","properties":{"model":{"type":"string","enum":["#g1_aura-asteria-en","#g1_aura-hera-en","#g1_aura-luna-en","#g1_aura-stella-en","#g1_aura-athena-en","#g1_aura-zeus-en","#g1_aura-orion-en","#g1_aura-arcas-en","#g1_aura-perseus-en","#g1_aura-angus-en","#g1_aura-orpheus-en","#g1_aura-helios-en"]},"text":{"type":"string"},"container":{"type":"string"},"encoding":{"type":"string","enum":["linear16","mulaw","alaw","mp3","opus","flac","aac"],"default":"linear16"},"sample_rate":{"type":"string"}},"required":["model","text"],"additionalProperties":false},"Voice.v1.TextToSpeechResponse":{"type":"object","properties":{"metadata":{"type":"object","properties":{"transaction_key":{"type":"string"},"request_id":{"type":"string"},"sha256":{"type":"string"},"created":{"type":"string","format":"date-time"},"duration":{"type":"number"},"channels":{"type":"number"},"models":{"type":"array","items":{"type":"string"}},"model_info":{"type":"object","additionalProperties":{"type":"object","properties":{"name":{"type":"string"},"version":{"type":"string"},"arch":{"type":"string"}},"required":["name","version","arch"]}}},"required":["transaction_key","request_id","sha256","created","duration","channels","models","model_info"]}},"required":["metadata"]},"LlmThreadMessage.v1.CreateMessageDTO":{"type":"object","properties":{"model":{"type":"string","enum":["claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307","claude-3-5-sonnet-20240620","claude-3-5-sonnet-20241022","claude-3-5-haiku-20241022","claude-3-7-sonnet-20250219","anthropic/claude-3.5-sonnet-20240620","anthropic/claude-3.5-sonnet-20241022","anthropic/claude-3.5-sonnet","claude-3-5-sonnet-latest","anthropic/claude-3-haiku-20240307","anthropic/claude-3-haiku","claude-3-haiku-latest","anthropic/claude-3-opus-20240229","anthropic/claude-3-opus","claude-3-opus-latest","anthropic/claude-3-sonnet-20240229","anthropic/claude-3-sonnet","claude-3-sonnet-latest","anthropic/claude-3-5-haiku-20241022","anthropic/claude-3-5-haiku","claude-3-5-haiku-latest","claude-3-7-sonnet-latest","anthropic/claude-3.7-sonnet"]},"messages":{"type":"array","items":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["image"]},"source":{"type":"object","properties":{"type":{"type":"string","enum":["base64"]},"media_type":{"type":"string","enum":["image/jpeg","image/png","image/gif","image/webp"]},"data":{"type":"string"}},"required":["type","media_type","data"]}},"required":["type","source"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["thinking"]},"thinking":{"type":"string"},"signature":{"type":"string"}},"required":["type","thinking","signature"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["tool_result"]},"tool_use_id":{"type":"string"},"is_error":{"type":"boolean"},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["image"]},"source":{"type":"object","properties":{"type":{"type":"string","enum":["base64"]},"media_type":{"type":"string","enum":["image/jpeg","image/png","image/gif","image/webp"]},"data":{"type":"string"}},"required":["type","media_type","data"]}},"required":["type","source"],"additionalProperties":false}]}}]}},"required":["type","tool_use_id"]},{"type":"object","properties":{"id":{"type":"string"},"input":{"type":"object","additionalProperties":{"nullable":true}},"name":{"type":"string"},"type":{"type":"string","enum":["tool_use"]}},"required":["id","input","name","type"]},{"type":"object","properties":{"type":{"type":"string","enum":["redacted_thinking"]},"data":{"type":"string"}},"required":["type","data"]}]},"maxItems":5}]}},"required":["role","content"],"additionalProperties":false}},"max_tokens":{"type":"number","default":512},"metadata":{"type":"object","additionalProperties":{"type":"string"}},"stop_sequences":{"type":"array","items":{"type":"string"}},"stream":{"type":"boolean","default":false},"system":{"type":"string"},"temperature":{"type":"number","minimum":0,"maximum":1,"default":1},"tool_choice":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["any"]}},"required":["type"]},{"type":"object","properties":{"name":{"type":"string"},"type":{"type":"string","enum":["tool"]}},"required":["name","type"]},{"type":"object","properties":{"type":{"type":"string","enum":["none"]}},"required":["type"]}]},"tools":{"type":"array","items":{"type":"object","properties":{"name":{"type":"string"},"description":{"type":"string"},"input_schema":{"type":"object","properties":{"type":{"type":"string","enum":["object"]},"properties":{"nullable":true}},"required":["type"],"additionalProperties":{"nullable":true}}},"required":["name","input_schema"],"additionalProperties":false}},"top_k":{"type":"number"},"top_p":{"type":"number"},"thinking":{"type":"object","properties":{"budget_tokens":{"type":"integer","minimum":1024},"type":{"type":"string","enum":["enabled"]}},"required":["budget_tokens","type"]}},"required":["model","messages"],"additionalProperties":false},"Bagoodex.v1.FetchDetailsDTO":{"type":"object","properties":{"followup_id":{"type":"string","format":"uuid"}},"required":["followup_id"]},"Bagoodex.v1.FetchImagesResponseDTO":{"type":"array","items":{"type":"object","properties":{"source":{"type":"string","nullable":true},"original":{"type":"string","nullable":true,"format":"uri"},"title":{"type":"string","nullable":true},"source_name":{"type":"string","nullable":true}}}},"Bagoodex.v1.FetchVideosResponseDTO":{"type":"array","items":{"type":"object","properties":{"link":{"type":"string","nullable":true,"format":"uri"},"thumbnail":{"type":"string","nullable":true,"format":"uri"},"title":{"type":"string","nullable":true}}}},"Bagoodex.v1.FetchKnowledgeResponseDTO":{"type":"object","properties":{"title":{"type":"string","nullable":true},"type":{"type":"string","nullable":true},"description":{"type":"string","nullable":true},"born":{"type":"string","nullable":true},"died":{"type":"string","nullable":true}}},"Bagoodex.v1.FetchWeatherResponseDTO":{"type":"object","properties":{"type":{"type":"string","nullable":true},"temperature":{"type":"string","nullable":true},"unit":{"type":"string","nullable":true},"precipitation":{"type":"string","nullable":true},"humidity":{"type":"string","nullable":true},"wind":{"type":"string","nullable":true},"location":{"type":"string","nullable":true},"date":{"type":"string","nullable":true},"weather":{"type":"string","nullable":true},"thumbnail":{"type":"string","nullable":true,"format":"uri"},"forecast":{"type":"array","nullable":true,"items":{"type":"object","properties":{"day":{"type":"string"},"temperature":{"type":"object","properties":{"high":{"type":"string"},"low":{"type":"string"}},"required":["high","low"]},"thumbnail":{"type":"string","format":"uri"},"weather":{"type":"string"},"humidity":{"type":"string"},"precipitation":{"type":"string"},"wind":{"type":"string"}},"required":["day","temperature","thumbnail","weather","humidity","precipitation","wind"]}},"hourly_forecast":{"type":"array","nullable":true,"items":{"type":"object","properties":{"time":{"type":"string"},"thumbnail":{"type":"string","format":"uri"},"weather":{"type":"string"},"temperature":{"type":"string"},"precipitation":{"type":"string"},"humidity":{"type":"string"},"wind":{"type":"string"}},"required":["time","thumbnail","weather","temperature","precipitation","humidity","wind"]}},"precipitation_forecast":{"type":"array","nullable":true,"items":{"type":"object","properties":{"precipitation":{"type":"string"},"day":{"type":"string"},"time":{"type":"string"}},"required":["precipitation","day","time"]}},"wind_forecast":{"type":"array","nullable":true,"items":{"type":"object","properties":{"angle":{"type":"number"},"direction":{"type":"string"},"speed":{"type":"string"},"time":{"type":"string"}},"required":["angle","direction","speed","time"]}},"sources":{"type":"array","nullable":true,"items":{"type":"object","properties":{"title":{"type":"string"},"link":{"type":"string","format":"uri"}},"required":["title","link"]}}}},"Bagoodex.v1.FetchLocalMapResponseDTO":{"type":"object","properties":{"link":{"type":"string","nullable":true},"image":{"type":"string","nullable":true,"format":"uri"},"gps_coordinates":{"type":"object","nullable":true,"properties":{"latitude":{"type":"number"},"longitude":{"type":"number"}},"required":["latitude","longitude"]}}},"Bagoodex.v1.FetchLinksResponseDTO":{"type":"array","items":{"type":"string","format":"uri"}},"LumaAi.v1.FetchGenerationsByIdsPayload":{"type":"object","properties":{"ids":{"anyOf":[{"type":"array","items":{"type":"string","format":"uuid"},"minItems":1},{"type":"string"}],"description":"Array of UUID strings or string with comma-separated UUID strings"}},"required":["ids"],"additionalProperties":false},"LumaAi.v1.CreateGenerationPayload":{"type":"object","properties":{"aspect_ratio":{"type":"string","enum":["1:1","16:9","9:16","4:3","3:4","21:9","9:21"],"description":"The aspect ratio of the image","example":"16:9"},"expand_prompt":{"type":"boolean","default":false,"description":"Whether to expand the prompt","example":true},"image_end_url":{"type":"string","format":"uri","description":"The URL for the end of the image","example":"https://example.com/image-end.jpg"},"image_url":{"type":"string","format":"uri","description":"The URL of the main image","example":"https://example.com/main-image.jpg"},"user_prompt":{"type":"string","description":"The user-provided prompt for image generation","example":"A beautiful sunset over the ocean"}},"required":["aspect_ratio","user_prompt"]},"LumaAi.v1.ExtendGenerationPayload":{"allOf":[{"$ref":"#/components/schemas/LumaAi.v1.CreateGenerationPayload"},{"type":"object","properties":{}}]},"LumaAi.v2.FetchGenerationPayload":{"type":"object","properties":{"generation_id":{"type":"string","format":"uuid"},"state":{"type":"string","enum":["queued","dreaming","completed"]}},"required":["generation_id"]},"LumaAi.v2.FetchGenerationsPayload":{"type":"object","properties":{"generation_ids":{"anyOf":[{"type":"array","items":{"type":"string","format":"uuid"},"minItems":1},{"type":"string"}]},"status":{"type":"string","enum":["queued","dreaming","completed"]}},"required":["generation_ids"]},"LumaAi.v2.CreateGenerationPayload":{"type":"object","properties":{"generation_type":{"type":"string","nullable":true,"enum":["video"]},"prompt":{"type":"string"},"aspect_ratio":{"type":"string","enum":["1:1","16:9","9:16","4:3","3:4","21:9","9:21"]},"loop":{"type":"boolean","default":false},"keyframes":{"type":"object","nullable":true,"properties":{"frame0":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["generation"]},"id":{"type":"string","format":"uuid"}},"required":["type","id"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["image"]},"url":{"type":"string","format":"uri"}},"required":["type","url"],"additionalProperties":false},{"nullable":true}]},"frame1":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["generation"]},"id":{"type":"string","format":"uuid"}},"required":["type","id"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["image"]},"url":{"type":"string","format":"uri"}},"required":["type","url"],"additionalProperties":false},{"nullable":true}]}}},"callback_url":{"type":"string","nullable":true,"format":"uri"},"model":{"type":"string","nullable":true},"resolution":{"nullable":true},"duration":{"type":"string","nullable":true}},"required":["prompt","aspect_ratio"],"additionalProperties":false},"Runway.v2.GenerateVideoPayloadDTO":{"type":"object","properties":{"model":{"type":"string","enum":["gen3a_turbo"]},"prompt":{"type":"string","maxLength":512,"description":"A non-empty string up to 512 UTF-16 code points in length. This should describe in detail what should appear in the output."},"image_url":{"type":"string","format":"uri","description":"A HTTPS URL or data URI containing an encoded image to be used as the first frame of the generated"},"last_image_url":{"type":"string","format":"uri","description":"A HTTPS URL or data URI containing an encoded image to be used as the last frame of the generated"},"duration":{"anyOf":[{"type":"number","enum":[5]},{"type":"number","enum":[10]}],"default":10,"description":"The number of seconds of duration for the output video"},"ratio":{"type":"string","enum":["16:9","9:16"],"description":"The aspect ratio of the generated video"},"seed":{"type":"integer","minimum":0,"maximum":4294967295,"description":"If unspecified, a random number is chosen. Varying the seed integer is a way to get different results for the same other request parameters. Using the same seed integer for an identical request will produce similar results"},"watermark":{"type":"boolean","description":"A boolean indicating whether or not the output video will contain a Runway watermark."}},"required":["model","image_url"]},"Runway.v2.GenerateVideoResponsedDTO":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Generation ID","example":"a12b3456-7c89-0de1-23f4-g567d584f98d"},"status":{"type":"string","enum":["queued","generating","completed","error"],"description":"Generation status"}},"required":["id","status"]},"Runway.v2.PollVideoDTO":{"type":"object","properties":{"generation_id":{"type":"string","format":"uuid","description":"Generation ID","example":"a12b3456-7c89-0de1-23f4-g567d584f98d"}},"required":["generation_id"]},"Runway.v2.PollGenerationResponseDTO":{"allOf":[{"$ref":"#/components/schemas/Runway.v2.GenerateVideoResponsedDTO"},{"type":"object","properties":{"video":{"type":"array","items":{"type":"string","format":"uri"},"description":"If the status is success, this will contain an array of strings. Each string will be a URL that returns an output from the task. URLs expire within 24-48 hours."}},"required":["video"]}]},"Kling.v2.SubmitGenerationPayloadDTO":{"anyOf":[{"$ref":"#/components/schemas/Kling.v2.klingV1StandardTextToVideo"},{"$ref":"#/components/schemas/Kling.v2.klingV1StandardImageToVideo"},{"$ref":"#/components/schemas/Kling.v2.klingV1ProImageToVideo"},{"$ref":"#/components/schemas/Kling.v2.klingV16StandardImageToVideo"},{"$ref":"#/components/schemas/Kling.v2.klingV16ProImageToVideo"},{"$ref":"#/components/schemas/Kling.v2.klingTextToVideoPayload"}]},"Kling.v2.klingV1StandardTextToVideo":{"type":"object","properties":{"model":{"type":"string","enum":["kling-video/v1/standard/text-to-video"]},"ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"aspect_ratio":{"type":"string","enum":["16:9","9:16","1:1"],"description":"The aspect ratio of the generated video frame"},"camera_control":{"type":"string","enum":["down_back","forward_up","right_turn_forward","left_turn_forward"],"description":"Camera control parameters"},"advanced_camera_control":{"type":"object","properties":{"movement_type":{"type":"string","enum":["horizontal","vertical","pan","tilt","roll","zoom"],"description":"The type of camera movement"},"movement_value":{"type":"integer","minimum":-10,"maximum":10,"description":"The value of the camera movement"}},"required":["movement_type","movement_value"],"description":"Advanced Camera control parameters"},"prompt":{"type":"string","description":"The text prompt to guide video generation"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 10"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated video"},"cfg_scale":{"type":"number","minimum":0,"maximum":1,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"}},"required":["model","prompt"]},"Kling.v2.klingV1StandardImageToVideo":{"type":"object","properties":{"model":{"type":"string","enum":["kling-video/v1/standard/image-to-video"]},"tail_image_url":{"type":"string","format":"uri","description":"URL of the image to be used for the end of the video"},"static_mask_url":{"type":"string","format":"uri","description":"URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)"},"dynamic_masks":{"type":"array","items":{"type":"object","properties":{"mask_url":{"type":"string","format":"uri","description":"URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)"},"trajectories":{"type":"array","items":{"type":"object","properties":{"x":{"type":"integer","description":"X coordinate of the motion trajectory"},"y":{"type":"integer","description":"Y coordinate of the motion trajectory"}},"required":["x","y"]},"description":"List of trajectories"}},"required":["mask_url"]},"description":"List of dynamic masks"},"image_url":{"type":"string","format":"uri"},"ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"aspect_ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"prompt":{"type":"string","description":"The text prompt to guide video generation"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 10"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated video"},"cfg_scale":{"type":"number","minimum":0,"maximum":1,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"}},"required":["model","image_url","prompt"]},"Kling.v2.klingV1ProImageToVideo":{"type":"object","properties":{"model":{"type":"string","enum":["kling-video/v1/pro/image-to-video"]},"tail_image_url":{"type":"string","format":"uri","description":"URL of the image to be used for the end of the video"},"static_mask_url":{"type":"string","format":"uri","description":"URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)"},"dynamic_masks":{"type":"array","items":{"type":"object","properties":{"mask_url":{"type":"string","format":"uri","description":"URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)"},"trajectories":{"type":"array","items":{"type":"object","properties":{"x":{"type":"integer","description":"X coordinate of the motion trajectory"},"y":{"type":"integer","description":"Y coordinate of the motion trajectory"}},"required":["x","y"]},"description":"List of trajectories"}},"required":["mask_url"]},"description":"List of dynamic masks"},"image_url":{"type":"string","format":"uri"},"ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"aspect_ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"prompt":{"type":"string","description":"The text prompt to guide video generation"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 10"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated video"},"cfg_scale":{"type":"number","minimum":0,"maximum":1,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"}},"required":["model","image_url","prompt"]},"Kling.v2.klingV16StandardImageToVideo":{"type":"object","properties":{"model":{"type":"string","enum":["kling-video/v1.6/standard/image-to-video"]},"image_url":{"type":"string","format":"uri"},"ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"aspect_ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"prompt":{"type":"string","description":"The text prompt to guide video generation"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 10"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated video"},"cfg_scale":{"type":"number","minimum":0,"maximum":1,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"}},"required":["model","image_url","prompt"]},"Kling.v2.klingV16ProImageToVideo":{"type":"object","properties":{"model":{"type":"string","enum":["kling-video/v1.6/pro/image-to-video"]},"tail_image_url":{"type":"string","format":"uri","description":"URL of the image to be used for the end of the video"},"image_url":{"type":"string","format":"uri"},"ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"aspect_ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"prompt":{"type":"string","description":"The text prompt to guide video generation"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 10"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated video"},"cfg_scale":{"type":"number","minimum":0,"maximum":1,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"}},"required":["model","image_url","prompt"]},"Kling.v2.klingTextToVideoPayload":{"type":"object","properties":{"model":{"type":"string","enum":["kling-video/v1/pro/text-to-video","kling-video/v1.6/standard/text-to-video","kling-video/v1.6/pro/text-to-video"]},"ratio":{"type":"string","enum":["16:9","9:16","1:1"],"deprecated":true},"aspect_ratio":{"type":"string","enum":["16:9","9:16","1:1"],"description":"The aspect ratio of the generated video frame"},"prompt":{"type":"string","description":"The text prompt to guide video generation"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 10"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated video"},"cfg_scale":{"type":"number","minimum":0,"maximum":1,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt"}},"required":["model","prompt"]},"Kling.v2.PollGenerationPayloadDTO":{"type":"object","properties":{"generation_id":{"type":"string"}},"required":["generation_id"]},"Minimax.v2.CreateGenerationVideoDTO":{"type":"object","properties":{"model":{"type":"string","enum":["video-01","video-01-live2d"],"description":"Model id"},"prompt":{"type":"string","maxLength":2000,"description":"Description of the video"},"prompt_optimizer":{"type":"boolean","default":true,"description":"The model will automatically optimize the incoming prompt to improve the generation quality If necessary.\nFor more precise control, this parameter can be set to False, and the model will follow the instructions more strictly. At this time\nIt is recommended to provide finer prompts for best results."},"first_frame_image":{"type":"string","format":"uri","description":"\n        The model will use the image passed in this parameter as the first frame to generate a video. \n        Supported formats:\n        - URL of the image\n        - base64 encoding of the image\n        Image specifications:\n        - format must be JPG, JPEG, or PNG;\n        - aspect ratio should be greater than 2:5 and less than 5:2; the shorter side must exceed 300 pixels\n        - file size must not exceed 20MB."}},"required":["model","prompt"]},"Minimax.v2.CreateGenerationVideoResponseDTO":{"type":"object","properties":{"generation_id":{"type":"string","description":"Generation ID","example":"222226666699999"}},"required":["generation_id"]},"Minimax.v2.FetchVideoDTO":{"type":"object","properties":{"generation_id":{"type":"string","description":"Generation ID","example":"222226666699999"}},"required":["generation_id"]},"Minimax.v2.FetchVideoResponseDTO":{"type":"object","properties":{"id":{"type":"string","description":"Generation ID","example":"222226666699999"},"status":{"type":"string","enum":["queued","generating","completed","error"],"description":"Generation status"},"video":{"type":"object","properties":{"url":{"type":"string","format":"uri","description":"The URL you get to download the video"}}}},"required":["id","status","video"]},"Alibaba.v2.SubmitGenerationPayloadDTO":{"type":"object","properties":{"model":{"type":"string","enum":["wan/v2.1/1.3b/text-to-video"]},"prompt":{"type":"string","description":"The text prompt to guide video generation.","example":"Mona Lisa puts on glasses with her hands"},"negative_prompt":{"type":"string","description":"The negative prompt to use. Use it to address details that you don't want in the image. This could be colors, objects, scenery and even the small details (e.g. moustache, blurry, low resolution)."},"seed":{"type":"integer","description":"Random seed for reproducibility. If None, a random seed is chosen."},"aspect_ratio":{"type":"string","enum":["9:16","16:9"],"default":"16:9","description":"Aspect ratio of the generated video (16:9 or 9:16)."},"inference_steps":{"type":"integer","default":30,"description":"Number of inference steps for sampling. Higher values give better quality but take longer."},"guidance_scale":{"type":"number","default":5,"description":"Classifier-free guidance scale. Controls prompt adherence / creativity."},"shift":{"type":"number","default":5,"description":"Noise schedule shift parameter. Affects temporal dynamics."},"sampler":{"type":"string","enum":["unipc","dpm+"],"default":"unipc","description":"The sampler to use for generation."},"enable_safety_checker":{"type":"boolean","description":"If set to true, the safety checker will be enabled."},"enable_prompt_expansion":{"type":"boolean","description":"Whether to enable prompt expansion."}},"required":["model","prompt"]},"Alibaba.v2.PollGenerationPayloadDTO":{"type":"object","properties":{"generation_id":{"type":"string"}},"required":["generation_id"]},"Google.v2.SubmitGenerationPayloadDTO":{"anyOf":[{"type":"object","properties":{"model":{"type":"string","enum":["veo2/image-to-video"]},"prompt":{"type":"string","description":"The text prompt describing how the image should be animated"},"image_url":{"type":"string","format":"uri","description":"URL of the input image to animate. Should be 720p or higher resolution"},"aspect_ratio":{"type":"string","enum":["auto","16:9","9:16"],"description":"The aspect ratio of the generated video"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 6, 7, 8"}},"required":["model","prompt","image_url"]},{"type":"object","properties":{"model":{"type":"string","enum":["veo2"]},"prompt":{"type":"string","description":"The text prompt describing the video you want to generate"},"aspect_ratio":{"type":"string","enum":["16:9","9:16"],"description":"The aspect ratio of the generated video"},"duration":{"type":"string","default":"5","description":"The duration of the generated video in seconds. Possible values: 5, 6, 7, 8"}},"required":["model","prompt"]}]},"Google.v2.PollGenerationPayloadDTO":{"type":"object","properties":{"generation_id":{"type":"string"}},"required":["generation_id"]},"Audio.v2.SubmitGenerationPayloadDTO":{"anyOf":[{"type":"object","properties":{"model":{"type":"string","enum":["stable-audio"]},"prompt":{"type":"string"},"seconds_start":{"type":"integer","maximum":47,"minimum":1,"description":"The start point of the audio clip to generate"},"seconds_total":{"type":"integer","maximum":47,"minimum":1,"default":30,"description":"The duration of the audio clip to generate"},"steps":{"type":"integer","minimum":1,"maximum":1000,"default":100,"description":"The number of steps to denoise the audio"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["minimax-music"]},"prompt":{"type":"string"},"reference_audio_url":{"type":"string","format":"uri","description":"Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds"}},"required":["model","prompt","reference_audio_url"]}]},"Audio.v2.SubmitAudioResponseDTO":{"type":"object","properties":{"id":{"type":"string"},"status":{"type":"string","enum":["queued","completed","generating","error"]}},"required":["id","status"]},"Audio.v2.PollGenerationPayloadDTO":{"type":"object","properties":{"generation_id":{"type":"string"}},"required":["generation_id"]},"Audio.v2.PollAudioResponseDTO":{"type":"object","properties":{"audio_file":{"type":"object","properties":{"url":{"type":"string","format":"uri"}},"required":["url"]},"id":{"type":"string"},"status":{"type":"string","enum":["queued","completed","generating","error"]},"error":{"nullable":true}},"required":["id","status"]},"Minimax.v2.UploadPayloadDTO":{"type":"object","properties":{"purpose":{"type":"string","enum":["song","voice","instrumental"],"description":"1. If purpose is song:\n- You need to upload a music file containing both acapella (vocals) and accompaniment.\n- The acapella must be in singing form; normal speech is not supported.\n- Outputs: voice_id and instrumental_id.\n2. If purpose is voice:\n- You need to upload a file containing only acapella in singing form (normal speech audio is not supported).\n- Output: voice_id.\n3. If purpose is instrumental:\n- You need to upload a file containing only accompaniment.\n- Output: instrumental_id."}},"required":["purpose"]},"Minimax.v2.UploadResponsePayloadDTO":{"type":"object","properties":{"voice_id":{"type":"string","description":"The voice_id will only be returned when the purpose is song or voice.","example":"vocal-2025011003141025-d5ZEMxmp"},"instrumental_id":{"type":"string","description":"The instrumental_id will only be returned when the purpose is song or instrumental.","example":"instrumental-2025011003141125-Akz9eWnD"},"base_resp":{"type":"object","properties":{"status_code":{"type":"integer"},"status_msg":{"type":"string"}},"required":["status_code","status_msg"]}},"required":["base_resp"],"additionalProperties":false},"Minimax.v2.CreateGenerationPayloadDTO":{"allOf":[{"type":"object","properties":{"lyrics":{"type":"string","description":"You can use a newline character (\\n) to separate each line of lyrics.\nYou can use two consecutive newline characters (\\n\\n) to add a pause between lines.\nYou can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment.","example":"##Swift and Boundless \n In the realm of innovation, where visions align, \n\nAIML API's the name, making tech shine. \nIntelligent solutions, breaking the mold, \n\nSwift inference power, bold and untold.\n##"},"model":{"type":"string","enum":["music-01"],"description":"Model id"},"audio_setting":{"type":"object","properties":{"sample_rate":{"anyOf":[{"type":"number","enum":[16000]},{"type":"number","enum":[24000]},{"type":"number","enum":[32000]},{"type":"number","enum":[44100]}],"description":"The sampling rate of the generated music"},"bitrate":{"anyOf":[{"type":"number","enum":[32000]},{"type":"number","enum":[64000]},{"type":"number","enum":[128000]},{"type":"number","enum":[256000]}],"description":"The bit rate of the generated music"},"format":{"type":"string","enum":["mp3","wav","pcm"],"description":"The format of the generated music"}},"required":["sample_rate","bitrate","format"]}},"required":["lyrics","model"]},{"type":"object","properties":{"refer_voice":{"type":"string","description":"At least one of refer_voice or refer_instrumental is required. When only refer_voice is provided, the system can still output music data. The generated music will be an a cappella vocal hum that aligns with the provided refer_voice and the generated lyrics, without any instrumental accompaniment.","example":"vocal-2025010100000000-a0AAAaaa"},"refer_instrumental":{"type":"string","description":"At least one of refer_voice or refer_instrumental is required. When only refer_instrumental is provided, the system can still output music data. The generated music will be a purely instrumental track that aligns with the provided refer_instrumental, without any vocals.","example":"instrumental-2025010100000000-Aaa0aAaA"}}}]},"Minimax.v2.GenerateAudioResponseDTO":{"type":"object","properties":{"data":{"type":"object","properties":{"status":{"type":"integer","description":"Music generation status. 1: In progress; 2: Completed."},"audio":{"type":"string","description":"Hex-encoded audio data. Currently, can generate music with a duration of no more than 1 minute."}},"required":["status","audio"]},"extra_info":{"type":"object","properties":{"audio_length":{"type":"integer"},"audio_size":{"type":"integer"},"audio_bitrate":{"type":"integer"},"audio_sample_rate":{"type":"integer"}},"required":["audio_length","audio_size","audio_bitrate","audio_sample_rate"]},"trace_id":{"type":"string"},"base_resp":{"type":"object","properties":{"status_code":{"type":"integer"},"status_msg":{"type":"string"}},"required":["status_code","status_msg"]}},"required":["base_resp"]},"Vision.v1.OCRPayloadDTO":{"anyOf":[{"$ref":"#/components/schemas/Vision.v1.OCRGoogleRequestDTO"},{"$ref":"#/components/schemas/Vision.v1.OCRMistralRequestDTO"}]},"Vision.v1.OCRGoogleRequestDTO":{"type":"object","properties":{"model":{"type":"string","enum":["google/gc-document-ai"],"default":"google/gc-document-ai","deprecated":true},"document":{"anyOf":[{"type":"string","format":"uri"},{"type":"string"}]},"mimeType":{"type":"string","enum":["application/pdf","image/gif","image/tiff","image/jpeg","image/png","image/bmp","image/webp","text/html"]},"pages":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["start"]},"start":{"type":"integer","minimum":1}},"required":["type","start"]},{"type":"object","properties":{"type":{"type":"string","enum":["end"]},"end":{"type":"integer","minimum":1}},"required":["type","end"]},{"type":"object","properties":{"type":{"type":"string","enum":["range"]},"start":{"type":"integer","minimum":1},"end":{"type":"integer","minimum":2}},"required":["type","start","end"]},{"type":"object","properties":{"type":{"type":"string","enum":["indices"]},"indices":{"type":"array","items":{"type":"integer","minimum":1},"maxItems":15}},"required":["type","indices"]}]}},"required":["document"],"additionalProperties":false},"Vision.v1.OCRMistralRequestDTO":{"type":"object","properties":{"model":{"type":"string","enum":["mistral/mistral-ocr-latest"],"default":"mistral/mistral-ocr-latest","description":"Model ID"},"document":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["document_url"],"description":"Type of document"},"document_url":{"type":"string","format":"uri","description":"Document url"}},"required":["type","document_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["image_url"],"description":"Type of document"},"image_url":{"type":"string","format":"uri","description":"Image url"}},"required":["type","image_url"]}],"description":"Document to run OCR"},"pages":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"integer"}},{"nullable":true}],"description":"Specific pages you wants to process","example":"\"3\" or \"0-2\" or [0, 3, 4]"},"include_image_base64":{"type":"boolean","nullable":true,"description":"Include base64 images in response"},"image_limit":{"type":"integer","nullable":true,"description":"Max images to extract"},"image_min_size":{"type":"integer","nullable":true,"description":"Minimum height and width of image to extract"}},"required":["document"]},"Vision.v1.VisionRequestDTO":{"type":"object","properties":{"image":{"type":"object","properties":{"source":{"type":"object","properties":{"imageUri":{"type":"string"}},"required":["imageUri"],"additionalProperties":false}},"required":["source"],"additionalProperties":false},"features":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["FACE_DETECTION","LANDMARK_DETECTION","LOGO_DETECTION","LABEL_DETECTION","TEXT_DETECTION","DOCUMENT_TEXT_DETECTION","SAFE_SEARCH_DETECTION","IMAGE_PROPERTIES","CROP_HINTS","WEB_DETECTION","PRODUCT_SEARCH","OBJECT_LOCALIZATION"]},"maxResults":{"type":"number"},"model":{"type":"string","enum":["builtin/stable","builtin/latest"]}},"required":["type"],"additionalProperties":false}},"imageContext":{"type":"object","properties":{"latLongRect":{"type":"object","properties":{"minLatLng":{"type":"object","properties":{"latitude":{"type":"number"},"longitude":{"type":"number"}},"required":["latitude","longitude"],"additionalProperties":false},"maxLatLng":{"type":"object","properties":{"latitude":{"type":"number"},"longitude":{"type":"number"}},"required":["latitude","longitude"],"additionalProperties":false}},"required":["minLatLng","maxLatLng"],"additionalProperties":false},"languageHints":{"type":"array","items":{"type":"string"}},"cropHintsParams":{"type":"object","properties":{"aspectRatios":{"type":"array","items":{"type":"number"}}},"required":["aspectRatios"],"additionalProperties":false},"faceRecognitionParams":{"type":"object","properties":{"celebritySet":{"type":"array","items":{"type":"string"}}},"required":["celebritySet"],"additionalProperties":false},"textDetectionParams":{"type":"object","properties":{"enableTextDetectionConfidenceScore":{"type":"boolean"}},"required":["enableTextDetectionConfidenceScore"],"additionalProperties":false}},"additionalProperties":false}},"required":["image","features"]},"Llm.v1.ChatCompletionPayload":{"oneOf":[{"type":"object","properties":{"model":{"type":"string","enum":["microsoft/WizardLM-2-8x22B","meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo","google/gemma-2-27b-it","meta-llama/Llama-Vision-Free","Gryphe/MythoMax-L2-13b","mistralai/Mixtral-8x22B-Instruct-v0.1","Qwen/Qwen2-72B-Instruct","mistralai/Mixtral-8x7B-Instruct-v0.1","nvidia/Llama-3.1-Nemotron-70B-Instruct-HF","NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO","meta-llama/Llama-3.3-70B-Instruct-Turbo","upstage/SOLAR-10.7B-Instruct-v1.0","meta-llama/Llama-3.2-3B-Instruct-Turbo","meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo","meta-llama/Llama-2-13b-chat-hf","meta-llama/Llama-Guard-3-11B-Vision-Turbo","Qwen/Qwen2.5-7B-Instruct-Turbo","Qwen/Qwen2.5-Coder-32B-Instruct","meta-llama/Meta-Llama-3-8B-Instruct-Lite","meta-llama/Llama-3-8b-chat-hf","meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-128K","meta-llama/Llama-3-70b-chat-hf","Qwen/Qwen2.5-72B-Instruct-Turbo","Qwen/QwQ-32B","meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo","meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo","meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo","google/gemma-2b-it","mistralai/Mistral-7B-Instruct-v0.2","meta-llama/LlamaGuard-2-8b","mistralai/Mistral-7B-Instruct-v0.1","mistralai/Mistral-7B-Instruct-v0.3","meta-llama/Meta-Llama-3-70B-Instruct-Turbo","google/gemma-2-9b-it","Gryphe/MythoMax-L2-13b-Lite","meta-llama/Meta-Llama-Guard-3-8B"]},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"type":"string"},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string"},"name":{"type":"string"}},"required":["role"],"additionalProperties":false}]}},"max_tokens":{"type":"number","minimum":1,"default":512},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"n":{"type":"integer","minimum":1},"seed":{"type":"integer","minimum":1},"top_p":{"type":"number","minimum":0.01,"maximum":1},"top_k":{"type":"number"},"temperature":{"type":"number"},"repetition_penalty":{"type":"number","nullable":true},"logprobs":{"type":"boolean","nullable":true},"echo":{"type":"boolean"},"min_p":{"type":"number","minimum":0,"maximum":1},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true}},"required":["description","name"]}},"required":["type","function"]}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"]},"json_schema":{"type":"object","properties":{"name":{"type":"string"},"schema":{"type":"object","additionalProperties":{"nullable":true}},"strict":{"type":"boolean"},"description":{"type":"string"}},"required":["name"],"additionalProperties":false}},"required":["type","json_schema"],"additionalProperties":false}]}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307","claude-3-5-sonnet-20240620","claude-3-5-sonnet-20241022","claude-3-5-haiku-20241022","claude-3-7-sonnet-20250219","anthropic/claude-3.5-sonnet-20240620","anthropic/claude-3.5-sonnet-20241022","anthropic/claude-3.5-sonnet","claude-3-5-sonnet-latest","anthropic/claude-3-haiku-20240307","anthropic/claude-3-haiku","claude-3-haiku-latest","anthropic/claude-3-opus-20240229","anthropic/claude-3-opus","claude-3-opus-latest","anthropic/claude-3-sonnet-20240229","anthropic/claude-3-sonnet","claude-3-sonnet-latest","anthropic/claude-3-5-haiku-20241022","anthropic/claude-3-5-haiku","claude-3-5-haiku-latest","claude-3-7-sonnet-latest","anthropic/claude-3.7-sonnet"]},"messages":{"type":"array","items":{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["image"]},"source":{"type":"object","properties":{"type":{"type":"string","enum":["base64"]},"media_type":{"type":"string","enum":["image/jpeg","image/png","image/gif","image/webp"]},"data":{"type":"string"}},"required":["type","media_type","data"]}},"required":["type","source"]},{"type":"object","properties":{"type":{"type":"string","enum":["tool_result"]},"tool_use_id":{"type":"string"},"is_error":{"type":"boolean"},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["image"]},"source":{"type":"object","properties":{"type":{"type":"string","enum":["base64"]},"media_type":{"type":"string","enum":["image/jpeg","image/png","image/gif","image/webp"]},"data":{"type":"string"}},"required":["type","media_type","data"]}},"required":["type","source"]}]}}]}},"required":["type","tool_use_id"]},{"type":"object","properties":{"id":{"type":"string"},"input":{"type":"object","additionalProperties":{"nullable":true}},"name":{"type":"string"},"type":{"type":"string","enum":["tool_use"]}},"required":["id","input","name","type"]},{"type":"object","properties":{"type":{"type":"string","enum":["thinking"]},"thinking":{"type":"string"},"signature":{"type":"string"}},"required":["type","thinking","signature"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["redacted_thinking"]},"data":{"type":"string"}},"required":["type","data"]}]}}]},"role":{"type":"string","enum":["user","assistant"]}},"required":["content","role"]}},"stop_sequences":{"type":"array","items":{"type":"string"}},"max_tokens":{"type":"number","minimum":1,"default":512},"stream":{"type":"boolean","default":false},"frequency_penalty":{"type":"number"},"top_p":{"type":"number"},"top_k":{"type":"number"},"metadata":{"type":"object","additionalProperties":{"type":"string"}},"temperature":{"type":"number","minimum":0,"maximum":1},"tools":{"type":"array","items":{"type":"object","properties":{"name":{"type":"string"},"description":{"type":"string"},"input_schema":{"type":"object","properties":{"type":{"type":"string","enum":["object"]},"properties":{"nullable":true}},"required":["type"],"additionalProperties":{"nullable":true}}},"required":["name","input_schema"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["auto"]}},"required":["type"]},{"type":"object","properties":{"type":{"type":"string","enum":["any"]}},"required":["type"]},{"type":"object","properties":{"name":{"type":"string"},"type":{"type":"string","enum":["tool"]}},"required":["name","type"]},{"type":"object","properties":{"type":{"type":"string","enum":["none"]}},"required":["type"]}]},"system":{"type":"string"},"thinking":{"type":"object","properties":{"budget_tokens":{"type":"integer","minimum":1024},"type":{"type":"string","enum":["enabled"]}},"required":["budget_tokens","type"]}},"required":["model","messages"],"additionalProperties":false},{"type":"object","properties":{"model":{"type":"string","enum":["o1"]},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"max_completion_tokens":{"type":"integer","minimum":1},"n":{"type":"integer","nullable":true,"minimum":1},"prediction":{"type":"object","properties":{"type":{"type":"string","enum":["content"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]}},"required":["type","content"]},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"seed":{"type":"integer","minimum":1},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"type":{"type":"string","enum":["input_audio"]},"input_audio":{"type":"object","properties":{"data":{"type":"string"},"format":{"type":"string","enum":["wav","mp3"]}},"required":["data","format"]}},"required":["type","input_audio"]},{"type":"object","properties":{"type":{"type":"string","enum":["file"]},"file":{"type":"object","properties":{"file_data":{"type":"string"},"file_id":{"type":"string"},"filename":{"type":"string"}}}},"required":["type","file"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"},"name":{"type":"string","nullable":true}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}]},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string","nullable":true},"audio":{"type":"object","nullable":true,"properties":{"id":{"type":"string"}},"required":["id"]},"function_call":{"nullable":true},"name":{"type":"string"}},"required":["role"],"additionalProperties":false},{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"role":{"type":"string","enum":["developer"]},"name":{"type":"string"}},"required":["content","role"],"additionalProperties":false}]}},"stream":{"type":"boolean","enum":[false],"default":false,"deprecated":true},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"parallel_tool_calls":{"type":"boolean"},"reasoning_effort":{"type":"string","enum":["low","medium","high"]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},"audio":{"type":"object","nullable":true,"properties":{"format":{"type":"string","enum":["wav","mp3","flac","opus","pcm16"],"description":"Specifies the output audio format"},"voice":{"type":"string","enum":["alloy","ash","ballad","coral","echo","sage","shimmer"],"description":"The voice the model uses to respond"}},"required":["format","voice"],"description":"Parameters for audio output. Required when audio output is requested with modalities: [\"audio\"]"},"modalities":{"type":"array","nullable":true,"items":{"type":"string","enum":["text","audio"]},"description":"Output types that you would like the model to generate"},"web_search_options":{"type":"object","properties":{"search_context_size":{"type":"string","enum":["low","medium","high"],"description":"High level guidance for the amount of context window space to use for the search"},"user_location":{"type":"object","nullable":true,"properties":{"approximate":{"type":"object","properties":{"city":{"type":"string","description":"Free text input for the city of the user, e.g. San Francisco."},"country":{"type":"string","description":"The two-letter ISO country code of the user, e.g. US"},"region":{"type":"string","description":"Free text input for the region of the user, e.g. California"},"timezone":{"type":"string","description":"The IANA timezone of the user, e.g. America/Los_Angeles"}},"description":"Approximate location parameters for the search"},"type":{"type":"string","enum":["approximate"],"description":"The type of location approximation"}},"required":["approximate","type"],"description":"Approximate location parameters for the search"}},"description":"This tool searches the web for relevant results to use in a response"}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["gpt-4o","gpt-4o-2024-08-06","gpt-4o-2024-05-13","gpt-4o-mini","gpt-4o-mini-2024-07-18","chatgpt-4o-latest","gpt-4-turbo","gpt-4-turbo-2024-04-09","gpt-4","gpt-4-0125-preview","gpt-4-1106-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125","gpt-3.5-turbo-1106","o1-preview","o1-preview-2024-09-12","o1-mini","o1-mini-2024-09-12","o3-mini","gpt-4.5-preview","gpt-4o-audio-preview","gpt-4o-mini-audio-preview","gpt-4o-search-preview","gpt-4o-mini-search-preview"]},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"max_completion_tokens":{"type":"integer","minimum":1},"n":{"type":"integer","nullable":true,"minimum":1},"prediction":{"type":"object","properties":{"type":{"type":"string","enum":["content"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]}},"required":["type","content"]},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"seed":{"type":"integer","minimum":1},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"type":{"type":"string","enum":["input_audio"]},"input_audio":{"type":"object","properties":{"data":{"type":"string"},"format":{"type":"string","enum":["wav","mp3"]}},"required":["data","format"]}},"required":["type","input_audio"]},{"type":"object","properties":{"type":{"type":"string","enum":["file"]},"file":{"type":"object","properties":{"file_data":{"type":"string"},"file_id":{"type":"string"},"filename":{"type":"string"}}}},"required":["type","file"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"},"name":{"type":"string","nullable":true}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}]},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string","nullable":true},"audio":{"type":"object","nullable":true,"properties":{"id":{"type":"string"}},"required":["id"]},"function_call":{"nullable":true},"name":{"type":"string"}},"required":["role"],"additionalProperties":false},{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"role":{"type":"string","enum":["developer"]},"name":{"type":"string"}},"required":["content","role"],"additionalProperties":false}]}},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"parallel_tool_calls":{"type":"boolean"},"reasoning_effort":{"type":"string","enum":["low","medium","high"]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},"audio":{"type":"object","nullable":true,"properties":{"format":{"type":"string","enum":["wav","mp3","flac","opus","pcm16"],"description":"Specifies the output audio format"},"voice":{"type":"string","enum":["alloy","ash","ballad","coral","echo","sage","shimmer"],"description":"The voice the model uses to respond"}},"required":["format","voice"],"description":"Parameters for audio output. Required when audio output is requested with modalities: [\"audio\"]"},"modalities":{"type":"array","nullable":true,"items":{"type":"string","enum":["text","audio"]},"description":"Output types that you would like the model to generate"},"web_search_options":{"type":"object","properties":{"search_context_size":{"type":"string","enum":["low","medium","high"],"description":"High level guidance for the amount of context window space to use for the search"},"user_location":{"type":"object","nullable":true,"properties":{"approximate":{"type":"object","properties":{"city":{"type":"string","description":"Free text input for the city of the user, e.g. San Francisco."},"country":{"type":"string","description":"The two-letter ISO country code of the user, e.g. US"},"region":{"type":"string","description":"Free text input for the region of the user, e.g. California"},"timezone":{"type":"string","description":"The IANA timezone of the user, e.g. America/Los_Angeles"}},"description":"Approximate location parameters for the search"},"type":{"type":"string","enum":["approximate"],"description":"The type of location approximation"}},"required":["approximate","type"],"description":"Approximate location parameters for the search"}},"description":"This tool searches the web for relevant results to use in a response"}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["gemini-1.5-flash","gemini-1.5-pro","gemini-pro","gemini-2.0-flash-exp","gemini-2.5-pro-exp-03-25"]},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"max_tokens":{"type":"number","minimum":1,"default":512},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"type":"string"},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"],"additionalProperties":false}},"required":["id","type","function"]}},"refusal":{"type":"string"},"name":{"type":"string"}},"required":["role"],"additionalProperties":false}]}},"stream":{"type":"boolean","default":false},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"type":"object","additionalProperties":{"nullable":true}}},"required":["description","name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["mistralai/mistral-tiny","x-ai/grok-beta","mistralai/mistral-nemo","neversleep/llama-3.1-lumimaid-70b","anthracite-org/magnum-v4-72b","nvidia/llama-3.1-nemotron-70b-instruct","cohere/command-r-plus","ai21/jamba-1-5-mini","mistralai/codestral-2501","google/gemma-3-1b-it","google/gemma-3-4b-it","google/gemma-3-12b-it","google/gemma-3-27b-it"]},"top_k":{"type":"integer","minimum":0},"repetition_penalty":{"type":"number","minimum":0,"maximum":2},"min_p":{"type":"number","minimum":0,"maximum":1},"top_a":{"type":"number","minimum":0,"maximum":1},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"max_completion_tokens":{"type":"integer","minimum":1},"n":{"type":"integer","nullable":true,"minimum":1},"prediction":{"type":"object","properties":{"type":{"type":"string","enum":["content"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]}},"required":["type","content"]},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"seed":{"type":"integer","minimum":1},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"type":{"type":"string","enum":["input_audio"]},"input_audio":{"type":"object","properties":{"data":{"type":"string"},"format":{"type":"string","enum":["wav","mp3"]}},"required":["data","format"]}},"required":["type","input_audio"]},{"type":"object","properties":{"type":{"type":"string","enum":["file"]},"file":{"type":"object","properties":{"file_data":{"type":"string"},"file_id":{"type":"string"},"filename":{"type":"string"}}}},"required":["type","file"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"},"name":{"type":"string","nullable":true}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}]},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string","nullable":true},"audio":{"type":"object","nullable":true,"properties":{"id":{"type":"string"}},"required":["id"]},"function_call":{"nullable":true},"name":{"type":"string"}},"required":["role"],"additionalProperties":false},{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"role":{"type":"string","enum":["developer"]},"name":{"type":"string"}},"required":["content","role"],"additionalProperties":false}]}},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"parallel_tool_calls":{"type":"boolean"},"reasoning_effort":{"type":"string","enum":["low","medium","high"]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},"audio":{"type":"object","nullable":true,"properties":{"format":{"type":"string","enum":["wav","mp3","flac","opus","pcm16"],"description":"Specifies the output audio format"},"voice":{"type":"string","enum":["alloy","ash","ballad","coral","echo","sage","shimmer"],"description":"The voice the model uses to respond"}},"required":["format","voice"],"description":"Parameters for audio output. Required when audio output is requested with modalities: [\"audio\"]"},"modalities":{"type":"array","nullable":true,"items":{"type":"string","enum":["text","audio"]},"description":"Output types that you would like the model to generate"},"web_search_options":{"type":"object","properties":{"search_context_size":{"type":"string","enum":["low","medium","high"],"description":"High level guidance for the amount of context window space to use for the search"},"user_location":{"type":"object","nullable":true,"properties":{"approximate":{"type":"object","properties":{"city":{"type":"string","description":"Free text input for the city of the user, e.g. San Francisco."},"country":{"type":"string","description":"The two-letter ISO country code of the user, e.g. US"},"region":{"type":"string","description":"Free text input for the region of the user, e.g. California"},"timezone":{"type":"string","description":"The IANA timezone of the user, e.g. America/Los_Angeles"}},"description":"Approximate location parameters for the search"},"type":{"type":"string","enum":["approximate"],"description":"The type of location approximation"}},"required":["approximate","type"],"description":"Approximate location parameters for the search"}},"description":"This tool searches the web for relevant results to use in a response"}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["MiniMax-Text-01","abab6.5s-chat"]},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"type":"string"},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string"},"name":{"type":"string"}},"required":["role"],"additionalProperties":false}]}},"max_tokens":{"type":"number","minimum":1,"default":256},"stream":{"type":"boolean","default":false},"temperature":{"type":"number","minimum":0,"maximum":1,"default":0.1},"top_p":{"type":"number","minimum":0.01,"maximum":1,"default":0.95},"mask_sensitive_info":{"type":"boolean","default":false},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true}},"required":["description","name"]}},"required":["type","function"]}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"]},"json_schema":{"type":"object","properties":{"name":{"type":"string"},"schema":{"type":"object","additionalProperties":{"nullable":true}},"strict":{"type":"boolean"},"description":{"type":"string"}},"required":["name"],"additionalProperties":false}},"required":["type","json_schema"],"additionalProperties":false}]}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["deepseek-chat","deepseek-reasoner","deepseek/deepseek-chat","deepseek/deepseek-chat-v3-0324","deepseek/deepseek-r1"]},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"max_completion_tokens":{"type":"integer","minimum":1},"n":{"type":"integer","nullable":true,"minimum":1},"prediction":{"type":"object","properties":{"type":{"type":"string","enum":["content"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]}},"required":["type","content"]},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"seed":{"type":"integer","minimum":1},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"type":{"type":"string","enum":["input_audio"]},"input_audio":{"type":"object","properties":{"data":{"type":"string"},"format":{"type":"string","enum":["wav","mp3"]}},"required":["data","format"]}},"required":["type","input_audio"]},{"type":"object","properties":{"type":{"type":"string","enum":["file"]},"file":{"type":"object","properties":{"file_data":{"type":"string"},"file_id":{"type":"string"},"filename":{"type":"string"}}}},"required":["type","file"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"},"name":{"type":"string","nullable":true}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}]},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string","nullable":true},"audio":{"type":"object","nullable":true,"properties":{"id":{"type":"string"}},"required":["id"]},"function_call":{"nullable":true},"name":{"type":"string"}},"required":["role"],"additionalProperties":false},{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"role":{"type":"string","enum":["developer"]},"name":{"type":"string"}},"required":["content","role"],"additionalProperties":false}]}},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"parallel_tool_calls":{"type":"boolean"},"reasoning_effort":{"type":"string","enum":["low","medium","high"]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},"audio":{"type":"object","nullable":true,"properties":{"format":{"type":"string","enum":["wav","mp3","flac","opus","pcm16"],"description":"Specifies the output audio format"},"voice":{"type":"string","enum":["alloy","ash","ballad","coral","echo","sage","shimmer"],"description":"The voice the model uses to respond"}},"required":["format","voice"],"description":"Parameters for audio output. Required when audio output is requested with modalities: [\"audio\"]"},"modalities":{"type":"array","nullable":true,"items":{"type":"string","enum":["text","audio"]},"description":"Output types that you would like the model to generate"},"web_search_options":{"type":"object","properties":{"search_context_size":{"type":"string","enum":["low","medium","high"],"description":"High level guidance for the amount of context window space to use for the search"},"user_location":{"type":"object","nullable":true,"properties":{"approximate":{"type":"object","properties":{"city":{"type":"string","description":"Free text input for the city of the user, e.g. San Francisco."},"country":{"type":"string","description":"The two-letter ISO country code of the user, e.g. US"},"region":{"type":"string","description":"Free text input for the region of the user, e.g. California"},"timezone":{"type":"string","description":"The IANA timezone of the user, e.g. America/Los_Angeles"}},"description":"Approximate location parameters for the search"},"type":{"type":"string","enum":["approximate"],"description":"The type of location approximation"}},"required":["approximate","type"],"description":"Approximate location parameters for the search"}},"description":"This tool searches the web for relevant results to use in a response"}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["qwen-max","qwen-plus","qwen-turbo","qwen-max-2025-01-25"]},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"max_completion_tokens":{"type":"integer","minimum":1},"n":{"type":"integer","nullable":true,"minimum":1},"prediction":{"type":"object","properties":{"type":{"type":"string","enum":["content"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]}},"required":["type","content"]},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"seed":{"type":"integer","minimum":1},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"type":{"type":"string","enum":["input_audio"]},"input_audio":{"type":"object","properties":{"data":{"type":"string"},"format":{"type":"string","enum":["wav","mp3"]}},"required":["data","format"]}},"required":["type","input_audio"]},{"type":"object","properties":{"type":{"type":"string","enum":["file"]},"file":{"type":"object","properties":{"file_data":{"type":"string"},"file_id":{"type":"string"},"filename":{"type":"string"}}}},"required":["type","file"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"},"name":{"type":"string","nullable":true}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}]},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string","nullable":true},"audio":{"type":"object","nullable":true,"properties":{"id":{"type":"string"}},"required":["id"]},"function_call":{"nullable":true},"name":{"type":"string"}},"required":["role"],"additionalProperties":false},{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"role":{"type":"string","enum":["developer"]},"name":{"type":"string"}},"required":["content","role"],"additionalProperties":false}]}},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"parallel_tool_calls":{"type":"boolean"},"reasoning_effort":{"type":"string","enum":["low","medium","high"]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},"audio":{"type":"object","nullable":true,"properties":{"format":{"type":"string","enum":["wav","mp3","flac","opus","pcm16"],"description":"Specifies the output audio format"},"voice":{"type":"string","enum":["alloy","ash","ballad","coral","echo","sage","shimmer"],"description":"The voice the model uses to respond"}},"required":["format","voice"],"description":"Parameters for audio output. Required when audio output is requested with modalities: [\"audio\"]"},"modalities":{"type":"array","nullable":true,"items":{"type":"string","enum":["text","audio"]},"description":"Output types that you would like the model to generate"},"web_search_options":{"type":"object","properties":{"search_context_size":{"type":"string","enum":["low","medium","high"],"description":"High level guidance for the amount of context window space to use for the search"},"user_location":{"type":"object","nullable":true,"properties":{"approximate":{"type":"object","properties":{"city":{"type":"string","description":"Free text input for the city of the user, e.g. San Francisco."},"country":{"type":"string","description":"The two-letter ISO country code of the user, e.g. US"},"region":{"type":"string","description":"Free text input for the region of the user, e.g. California"},"timezone":{"type":"string","description":"The IANA timezone of the user, e.g. America/Los_Angeles"}},"description":"Approximate location parameters for the search"},"type":{"type":"string","enum":["approximate"],"description":"The type of location approximation"}},"required":["approximate","type"],"description":"Approximate location parameters for the search"}},"description":"This tool searches the web for relevant results to use in a response"}},"required":["model","messages"]},{"type":"object","properties":{"model":{"type":"string","enum":["bagoodex/bagoodex-search-v1"]},"messages":{"type":"array","items":{"type":"object","properties":{"role":{"type":"string","enum":["user","assistant"]},"content":{"type":"string"}},"required":["role","content"]}},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"n":{"type":"integer","nullable":true,"minimum":1},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"]}},"required":["type"],"additionalProperties":false}]},"seed":{"type":"integer","minimum":1},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"stream":{"type":"boolean","default":false},"temperature":{"type":"number","minimum":0,"maximum":2},"top_p":{"type":"number","minimum":0.1,"maximum":1},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false},"deprecated":true},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}],"deprecated":true},"user":{"type":"string"},"best_of":{"type":"integer","nullable":true,"minimum":1},"use_beam_search":{"type":"boolean","nullable":true},"top_k":{"type":"integer","nullable":true},"min_p":{"type":"number","nullable":true},"repetition_penalty":{"type":"number","nullable":true},"length_penalty":{"type":"number","nullable":true},"early_stopping":{"type":"boolean","nullable":true},"ignore_eos":{"type":"boolean","nullable":true},"min_tokens":{"type":"integer","nullable":true},"stop_token_ids":{"type":"array","nullable":true,"items":{"type":"integer"}},"skip_special_tokens":{"type":"boolean","nullable":true},"spaces_between_special_tokens":{"nullable":true},"echo":{"type":"boolean","nullable":true,"description":"If true, the new message will be prepended with the last message if they belong to the same role."},"add_generation_prompt":{"type":"boolean","nullable":true,"description":"If true, the generation prompt will be added to the chat template. This is a parameter used by chat template in tokenizer config of the model."},"add_special_tokens":{"type":"boolean","nullable":true,"description":"If true, special tokens (e.g. BOS) will be added to the prompt on top of what is added by the chat template. For most models, the chat template takes care of adding the special tokens so this should be set to False (as is the default)."},"documents":{"type":"array","nullable":true,"items":{"type":"object","additionalProperties":{"type":"string"}},"description":"A list of dicts representing documents that will be accessible to the model if it is performing RAG (retrieval-augmented generation). If the template does not support RAG, this argument will have no effect. We recommend that each document should be a dict containing \"title\" and \"text\" keys."},"chat_template":{"type":"string","nullable":true,"description":"A Jinja template to use for this conversion. If this is not passed, the model's default chat template will be used instead."},"chat_template_kwargs":{"type":"object","nullable":true,"additionalProperties":{"nullable":true},"description":"Additional kwargs to pass to the template renderer. Will be accessible by the chat template"},"include_stop_str_in_output":{"type":"boolean","nullable":true,"description":"Whether to include the stop string in the output. This is only applied when the stop or stop_token_ids is set"},"guided_json":{"anyOf":[{"type":"string"},{"type":"object","additionalProperties":{"nullable":true}},{"nullable":true}],"description":"If specified, the output will follow the JSON schema."},"guided_regex":{"type":"string","nullable":true,"description":"If specified, the output will follow the regex pattern."},"guided_choice":{"type":"array","nullable":true,"items":{"type":"string"},"description":"If specified, the output will be exactly one of the choices."},"guided_grammar":{"type":"string","nullable":true,"description":"If specified, the output will follow the context free grammar."},"guided_decoding_backend":{"type":"string","nullable":true,"enum":["outlines","lm-format-enforcer"],"description":"If specified, will override the default guided decoding backend of the server for this specific request. If set, must be either 'outlines' / 'lm-format-enforcer'"},"guided_whitespace_pattern":{"type":"string","nullable":true,"description":"If specified, will override the default whitespace pattern for guided json decoding."},"ip":{"type":"string","format":"ip","description":"IP from which a request is executed"}},"required":["model","messages"]}]},"Llm.v2.CompleteChatPayload":{"type":"object","properties":{"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","nullable":true,"additionalProperties":{"type":"number","minimum":-100,"maximum":100}},"logprobs":{"type":"boolean","nullable":true},"top_logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":20},"max_tokens":{"type":"number","minimum":1,"default":512},"max_completion_tokens":{"type":"integer","minimum":1},"n":{"type":"integer","nullable":true,"minimum":1},"prediction":{"type":"object","properties":{"type":{"type":"string","enum":["content"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]}},"required":["type","content"]},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"seed":{"type":"integer","minimum":1},"messages":{"type":"array","items":{"oneOf":[{"type":"object","properties":{"role":{"type":"string","enum":["system"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["user"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["image_url"]},"image_url":{"type":"object","properties":{"url":{"type":"string","format":"uri"},"detail":{"type":"string","enum":["low","high","auto"]}},"required":["url"]}},"required":["type","image_url"]},{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"type":{"type":"string","enum":["input_audio"]},"input_audio":{"type":"object","properties":{"data":{"type":"string"},"format":{"type":"string","enum":["wav","mp3"]}},"required":["data","format"]}},"required":["type","input_audio"]},{"type":"object","properties":{"type":{"type":"string","enum":["file"]},"file":{"type":"object","properties":{"file_data":{"type":"string"},"file_id":{"type":"string"},"filename":{"type":"string"}}}},"required":["type","file"]}]}}]},"name":{"type":"string"}},"required":["role","content"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["tool"]},"content":{"type":"string"},"tool_call_id":{"type":"string"},"name":{"type":"string","nullable":true}},"required":["role","content","tool_call_id"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["function"]},"content":{"type":"string"},"name":{"type":"string"}},"required":["role","content","name"],"additionalProperties":false},{"type":"object","properties":{"role":{"type":"string","enum":["assistant"]},"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"anyOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]},{"type":"object","properties":{"refusal":{"type":"string"},"type":{"type":"string","enum":["refusal"]}},"required":["refusal","type"]}]}}]},"tool_calls":{"type":"array","items":{"type":"object","properties":{"id":{"type":"string"},"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"},"arguments":{"type":"string"}},"required":["name","arguments"]}},"required":["id","type","function"]}},"refusal":{"type":"string","nullable":true},"audio":{"type":"object","nullable":true,"properties":{"id":{"type":"string"}},"required":["id"]},"function_call":{"nullable":true},"name":{"type":"string"}},"required":["role"],"additionalProperties":false},{"type":"object","properties":{"content":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["text"]},"text":{"type":"string"}},"required":["type","text"]}}]},"role":{"type":"string","enum":["developer"]},"name":{"type":"string"}},"required":["content","role"],"additionalProperties":false}]}},"stream":{"type":"boolean","default":false},"stream_options":{"type":"object","properties":{"include_usage":{"type":"boolean"}},"required":["include_usage"]},"top_p":{"type":"number","minimum":0.1,"maximum":1},"temperature":{"type":"number","minimum":0,"maximum":2},"stop":{"anyOf":[{"type":"string"},{"type":"array","items":{"type":"string"}},{"nullable":true}]},"tools":{"type":"array","items":{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"description":{"type":"string"},"name":{"type":"string"},"parameters":{"nullable":true},"strict":{"type":"boolean","nullable":true},"required":{"type":"array","items":{"type":"string"}}},"required":["name"],"additionalProperties":false}},"required":["type","function"],"additionalProperties":false}},"tool_choice":{"anyOf":[{"type":"string","enum":["none","auto","required"]},{"type":"object","properties":{"type":{"type":"string","enum":["function"]},"function":{"type":"object","properties":{"name":{"type":"string"}},"required":["name"]}},"required":["type","function"]}]},"parallel_tool_calls":{"type":"boolean"},"reasoning_effort":{"type":"string","enum":["low","medium","high"]},"response_format":{"oneOf":[{"type":"object","properties":{"type":{"type":"string","enum":["text"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false},{"type":"object","properties":{"type":{"type":"string","enum":["json_object"],"description":"The type of response format being defined"}},"required":["type"],"additionalProperties":false,"description":"JSON object response format. An older method of generating JSON responses. Using json_schema is recommended for models that support it. Note that the model will not generate JSON without a system or user message instructing it to do so"},{"type":"object","properties":{"type":{"type":"string","enum":["json_schema"],"description":"The type of response format being defined"},"json_schema":{"type":"object","properties":{"name":{"type":"string","description":"The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64"},"schema":{"type":"object","additionalProperties":{"nullable":true},"description":"The schema for the response format, described as a JSON Schema object"},"strict":{"type":"boolean","nullable":true,"description":"Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the schema field. Only a subset of JSON Schema is supported when strict is true"},"description":{"type":"string","description":"A description of what the response format is for, used by the model to determine how to respond in the format."}},"required":["name"],"additionalProperties":false,"description":"Structured Outputs configuration options, including a JSON Schema"}},"required":["type","json_schema"],"additionalProperties":false}]},"audio":{"type":"object","nullable":true,"properties":{"format":{"type":"string","enum":["wav","mp3","flac","opus","pcm16"],"description":"Specifies the output audio format"},"voice":{"type":"string","enum":["alloy","ash","ballad","coral","echo","sage","shimmer"],"description":"The voice the model uses to respond"}},"required":["format","voice"],"description":"Parameters for audio output. Required when audio output is requested with modalities: [\"audio\"]"},"modalities":{"type":"array","nullable":true,"items":{"type":"string","enum":["text","audio"]},"description":"Output types that you would like the model to generate"},"web_search_options":{"type":"object","properties":{"search_context_size":{"type":"string","enum":["low","medium","high"],"description":"High level guidance for the amount of context window space to use for the search"},"user_location":{"type":"object","nullable":true,"properties":{"approximate":{"type":"object","properties":{"city":{"type":"string","description":"Free text input for the city of the user, e.g. San Francisco."},"country":{"type":"string","description":"The two-letter ISO country code of the user, e.g. US"},"region":{"type":"string","description":"Free text input for the region of the user, e.g. California"},"timezone":{"type":"string","description":"The IANA timezone of the user, e.g. America/Los_Angeles"}},"description":"Approximate location parameters for the search"},"type":{"type":"string","enum":["approximate"],"description":"The type of location approximation"}},"required":["approximate","type"],"description":"Approximate location parameters for the search"}},"description":"This tool searches the web for relevant results to use in a response"},"model":{"type":"string","enum":["microsoft/WizardLM-2-8x22B","meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo","google/gemma-2-27b-it","meta-llama/Llama-Vision-Free","Gryphe/MythoMax-L2-13b","mistralai/Mixtral-8x22B-Instruct-v0.1","Qwen/Qwen2-72B-Instruct","mistralai/Mixtral-8x7B-Instruct-v0.1","nvidia/Llama-3.1-Nemotron-70B-Instruct-HF","NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO","meta-llama/Llama-3.3-70B-Instruct-Turbo","upstage/SOLAR-10.7B-Instruct-v1.0","meta-llama/Llama-3.2-3B-Instruct-Turbo","meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo","meta-llama/Llama-2-13b-chat-hf","meta-llama/Llama-Guard-3-11B-Vision-Turbo","Qwen/Qwen2.5-7B-Instruct-Turbo","Qwen/Qwen2.5-Coder-32B-Instruct","meta-llama/Meta-Llama-3-8B-Instruct-Lite","meta-llama/Llama-3-8b-chat-hf","meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-128K","meta-llama/Llama-3-70b-chat-hf","Qwen/Qwen2.5-72B-Instruct-Turbo","Qwen/QwQ-32B","meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo","meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo","meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo","google/gemma-2b-it","mistralai/Mistral-7B-Instruct-v0.2","meta-llama/LlamaGuard-2-8b","mistralai/Mistral-7B-Instruct-v0.1","mistralai/Mistral-7B-Instruct-v0.3","meta-llama/Meta-Llama-3-70B-Instruct-Turbo","google/gemma-2-9b-it","Gryphe/MythoMax-L2-13b-Lite","meta-llama/Meta-Llama-Guard-3-8B","o1","gpt-4o","gpt-4o-2024-08-06","gpt-4o-2024-05-13","gpt-4o-mini","gpt-4o-mini-2024-07-18","chatgpt-4o-latest","gpt-4-turbo","gpt-4-turbo-2024-04-09","gpt-4","gpt-4-0125-preview","gpt-4-1106-preview","gpt-3.5-turbo","gpt-3.5-turbo-0125","gpt-3.5-turbo-1106","o1-preview","o1-preview-2024-09-12","o1-mini","o1-mini-2024-09-12","o3-mini","gpt-4.5-preview","gpt-4o-audio-preview","gpt-4o-mini-audio-preview","gpt-4o-search-preview","gpt-4o-mini-search-preview","claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307","claude-3-5-sonnet-20240620","claude-3-5-sonnet-20241022","claude-3-5-haiku-20241022","claude-3-7-sonnet-20250219","anthropic/claude-3.5-sonnet-20240620","anthropic/claude-3.5-sonnet-20241022","anthropic/claude-3.5-sonnet","claude-3-5-sonnet-latest","anthropic/claude-3-haiku-20240307","anthropic/claude-3-haiku","claude-3-haiku-latest","anthropic/claude-3-opus-20240229","anthropic/claude-3-opus","claude-3-opus-latest","anthropic/claude-3-sonnet-20240229","anthropic/claude-3-sonnet","claude-3-sonnet-latest","anthropic/claude-3-5-haiku-20241022","anthropic/claude-3-5-haiku","claude-3-5-haiku-latest","claude-3-7-sonnet-latest","anthropic/claude-3.7-sonnet","gemini-1.5-flash","gemini-1.5-pro","gemini-pro","gemini-2.0-flash-exp","gemini-2.5-pro-exp-03-25","mistralai/mistral-tiny","x-ai/grok-beta","mistralai/mistral-nemo","neversleep/llama-3.1-lumimaid-70b","anthracite-org/magnum-v4-72b","nvidia/llama-3.1-nemotron-70b-instruct","cohere/command-r-plus","ai21/jamba-1-5-mini","mistralai/codestral-2501","google/gemma-3-1b-it","google/gemma-3-4b-it","google/gemma-3-12b-it","google/gemma-3-27b-it","MiniMax-Text-01","abab6.5s-chat","deepseek-chat","deepseek-reasoner","deepseek/deepseek-chat","deepseek/deepseek-chat-v3-0324","deepseek/deepseek-r1","qwen-max","qwen-plus","qwen-turbo","qwen-max-2025-01-25","bagoodex/bagoodex-search-v1"]}},"required":["messages","model"]},"Llm.v1.CompleteLanguageDTO":{"oneOf":[{"type":"object","properties":{"prompt":{"type":"string"},"model":{"type":"string","enum":["gpt-3.5-turbo-instruct","mistralai/Mixtral-8x7B-v0.1","mistralai/Mistral-7B-v0.1","NousResearch/Nous-Hermes-13b","togethercomputer/llama-2-7b","huggyllama/llama-7b","WizardLM/WizardLM-70B-V1.0","huggyllama/llama-65b","togethercomputer/llama-2-13b","togethercomputer/llama-2-70b","huggyllama/llama-13b","huggyllama/llama-30b","EleutherAI/llemma_7b","meta-llama/Llama-3-70b-hf","meta-llama/Meta-Llama-3.1-8B-Reference","meta-llama/Meta-Llama-3.1-70B-Reference"]},"max_tokens":{"type":"number","minimum":1,"maximum":8000},"stop":{"type":"array","items":{"type":"string"}},"temperature":{"type":"number","nullable":true,"minimum":0,"maximum":2},"top_p":{"type":"number","nullable":true,"minimum":0,"maximum":1},"top_k":{"type":"number","minimum":1},"repetition_penalty":{"type":"number","nullable":true,"minimum":0},"stream":{"type":"boolean","default":false},"logprobs":{"type":"number","nullable":true,"minimum":0,"maximum":1},"echo":{"type":"boolean"},"n":{"type":"number","minimum":1,"maximum":128},"safety_model":{"type":"string"},"min_p":{"type":"number","nullable":true},"presence_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"frequency_penalty":{"type":"number","nullable":true,"minimum":-2,"maximum":2},"logit_bias":{"type":"object","additionalProperties":{"type":"number"}}},"required":["prompt","model"]}]},"Image.v1.GenerateImageDTO":{"anyOf":[{"type":"object","properties":{"model":{"type":"string","enum":["dall-e-3","dall-e-2"],"default":"dall-e-2"},"prompt":{"type":"string","maxLength":4000},"n":{"type":"number","default":1},"quality":{"type":"string","enum":["standard","hd"]},"response_format":{"type":"string","nullable":true,"enum":["url","b64_json"],"default":"url"},"size":{"type":"string","nullable":true,"enum":["1024x1024","1024x1792","1792x1024","512x512","256x256"],"default":"1024x1024"},"style":{"type":"string","nullable":true,"enum":["vivid","natural"]}},"required":["prompt"],"additionalProperties":false},{"type":"object","properties":{"model":{"type":"string","enum":["stabilityai/stable-diffusion-xl-base-1.0"]},"prompt":{"type":"string","maxLength":4000},"steps":{"type":"string","default":"25"},"n":{"type":"number","default":1},"size":{"type":"string","enum":["512x512","1024x1024"],"default":"1024x1024"}},"required":["model","prompt"],"additionalProperties":false},{"type":"object","properties":{"model":{"type":"string","enum":["flux/schnell"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":64,"maximum":1536,"default":1024},"height":{"type":"integer","minimum":64,"maximum":1536,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"landscape_4_3"},"num_inference_steps":{"type":"integer","minimum":1,"description":"The number of inference steps to perform","maximum":12},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux-pro"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":256,"maximum":1440,"default":1024},"height":{"type":"integer","minimum":256,"maximum":1440,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"landscape_4_3"},"num_inference_steps":{"type":"integer","minimum":1,"maximum":50,"description":"The number of inference steps to perform"},"guidance_scale":{"type":"number","minimum":1,"maximum":20,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you"},"safety_tolerance":{"type":"string","enum":["1","2","3","4","5","6"],"default":"2","description":"The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive"},"output_format":{"type":"string","enum":["jpeg","png"],"default":"jpeg","description":"The format of the generated image"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux-pro/v1.1"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":256,"maximum":1440,"default":1024},"height":{"type":"integer","minimum":256,"maximum":1440,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"landscape_4_3"},"safety_tolerance":{"type":"string","enum":["1","2","3","4","5","6"],"default":"2","description":"The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive"},"output_format":{"type":"string","enum":["jpeg","png"],"default":"jpeg","description":"The format of the generated image"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux-pro/v1.1-ultra"]},"safety_tolerance":{"type":"string","enum":["1","2","3","4","5","6"],"default":"2","description":"The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive"},"output_format":{"type":"string","enum":["jpeg","png"],"default":"jpeg","description":"The format of the generated image"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"aspect_ratio":{"type":"string","enum":["21:9","16:9","4:3","3:2","1:1","2:3","3:4","9:16","9:21"],"default":"16:9","description":"The aspect ratio of the generated image"},"raw":{"type":"boolean","enum":[false],"default":false}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux-pro/v1.1-ultra-raw"]},"safety_tolerance":{"type":"string","enum":["1","2","3","4","5","6"],"default":"2","description":"The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive"},"output_format":{"type":"string","enum":["jpeg","png"],"default":"jpeg","description":"The format of the generated image"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"aspect_ratio":{"type":"string","enum":["21:9","16:9","4:3","3:2","1:1","2:3","3:4","9:16","9:21"],"default":"16:9","description":"The aspect ratio of the generated image"},"raw":{"type":"boolean","enum":[true],"default":true}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux/dev"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":512,"maximum":1536,"default":1024},"height":{"type":"integer","minimum":512,"maximum":1536,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"landscape_4_3"},"guidance_scale":{"type":"number","minimum":1,"maximum":20,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you"},"num_inference_steps":{"type":"integer","minimum":1,"maximum":50,"description":"The number of inference steps to perform"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux/dev/image-to-image"]},"guidance_scale":{"type":"number","minimum":1,"maximum":20,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you"},"num_inference_steps":{"type":"integer","minimum":1,"maximum":50,"description":"The number of inference steps to perform"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"},"image_url":{"type":"string","format":"uri","description":"The URL of the image to generate an image from."},"strength":{"type":"number","default":0.95,"description":"Determines how much the prompt influences the generated image."}},"required":["model","prompt","image_url"]},{"type":"object","properties":{"model":{"type":"string","enum":["stable-diffusion-v3-medium"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":64,"maximum":1536,"default":1024},"height":{"type":"integer","minimum":64,"maximum":1536,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"square_hd"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated image"},"prompt_expansion":{"type":"boolean","description":"If set to true, prompt will be upsampled with more details"},"guidance_scale":{"type":"number","minimum":1,"maximum":20,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you"},"num_inference_steps":{"type":"integer","minimum":1,"maximum":50,"description":"The number of inference steps to perform"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["stable-diffusion-v35-large"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":64,"maximum":1536,"default":1024},"height":{"type":"integer","minimum":64,"maximum":1536,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"square_hd"},"negative_prompt":{"type":"string","description":"The description of elements to avoid in the generated image"},"guidance_scale":{"type":"number","minimum":1,"maximum":20,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you"},"num_inference_steps":{"type":"integer","minimum":1,"maximum":50,"description":"The number of inference steps to perform"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"},"output_format":{"type":"string","enum":["jpeg","png"],"default":"jpeg","description":"The format of the generated image"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["flux-realism"]},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":512,"maximum":1536,"default":1024},"height":{"type":"integer","minimum":512,"maximum":1536,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"landscape_4_3"},"guidance_scale":{"type":"number","minimum":1,"maximum":20,"description":"The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you"},"num_inference_steps":{"type":"integer","minimum":1,"maximum":50,"description":"The number of inference steps to perform"},"enable_safety_checker":{"type":"boolean","default":true,"description":"If set to true, the safety checker will be enabled"},"output_format":{"type":"string","enum":["jpeg","png"],"default":"jpeg","description":"The format of the generated image"},"prompt":{"type":"string","maxLength":4000,"description":"The prompt to generate an image from"},"num_images":{"type":"number","minimum":1,"maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":1,"description":"The same seed and the same prompt given to the same version of the model will output the same image every time"}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["triposr"]},"image_url":{"type":"string","format":"uri","description":"Path for the image file to be processed."},"output_format":{"type":"string","enum":["glb","obj"],"default":"glb","description":"Output format for the 3D model."},"do_remove_background":{"type":"boolean","description":"Whether to remove the background from the input image."},"foreground_ratio":{"type":"number","minimum":0.5,"maximum":1,"default":0.9,"description":"Ratio of the foreground image to the original image."},"mc_resolution":{"type":"integer","minimum":32,"maximum":1024,"default":256,"description":"Resolution of the marching cubes. Above 512 is not recommended."}},"required":["model","image_url"]},{"type":"object","properties":{"model":{"type":"string","enum":["recraft-v3"]},"prompt":{"type":"string","maxLength":4000},"image_size":{"anyOf":[{"type":"object","properties":{"width":{"type":"integer","minimum":64,"maximum":1536,"default":1024},"height":{"type":"integer","minimum":64,"maximum":1536,"default":768}},"description":"For both height and width, the value must be a multiple of 32."},{"type":"string","enum":["square_hd","square","portrait_4_3","portrait_16_9","landscape_4_3","landscape_16_9"],"description":"The size of the generated image"}],"default":"square_hd"},"style":{"type":"string","enum":["any","realistic_image","digital_illustration","vector_illustration","realistic_image/b_and_w","realistic_image/hard_flash","realistic_image/hdr","realistic_image/natural_light","realistic_image/studio_portrait","realistic_image/enterprise","realistic_image/motion_blur","digital_illustration/pixel_art","digital_illustration/hand_drawn","digital_illustration/grain","digital_illustration/infantile_sketch","digital_illustration/2d_art_poster","digital_illustration/handmade_3d","digital_illustration/hand_drawn_outline","digital_illustration/engraving_color","digital_illustration/2d_art_poster_2","vector_illustration/engraving","vector_illustration/line_art","vector_illustration/line_circuit","vector_illustration/linocut"],"default":"realistic_image"},"colors":{"type":"array","items":{"type":"object","properties":{"r":{"type":"integer","minimum":0,"maximum":255},"g":{"type":"integer","minimum":0,"maximum":255},"b":{"type":"integer","minimum":0,"maximum":255}},"required":["r","g","b"]},"default":[]},"num_images":{"type":"number","enum":[1],"default":1}},"required":["model","prompt"]},{"type":"object","properties":{"model":{"type":"string","enum":["imagen-3.0-generate-002"]},"prompt":{"type":"string","maxLength":400,"description":"The text prompt for the image"},"convert_base64_to_url":{"type":"boolean","default":false,"description":"If the condition is true, the url to the image will be returned; otherwise, the file will be provided in base64 format."},"num_images":{"type":"integer","maximum":4,"default":1,"description":"The number of images to generate"},"seed":{"type":"integer","minimum":0,"maximum":4294967295,"description":"The random seed for image generation"},"enhance_prompt":{"type":"boolean","default":true,"description":"An optional parameter to use an LLM-based prompt rewriting feature to deliver higher quality images that better reflect the original prompt's intent. Disabling this feature may impact image quality and prompt adherence"},"aspect_ratio":{"type":"string","enum":["1:1","9:16","16:9","3:4","4:3"],"default":"1:1","description":"The aspect ratio for the image"},"person_generation":{"type":"string","enum":["dont_allow","allow_adult"],"default":"allow_adult","description":"Allow generation of people by the model"},"safety_setting":{"type":"string","enum":["block_low_and_above","block_medium_and_above","block_only_high"],"default":"block_medium_and_above","description":"Adds a filter level to safety filtering"},"add_watermark":{"type":"boolean","default":false,"description":"Add an invisible watermark to the generated images"}},"required":["model","prompt"]}]},"Embedding.v1.CreateEmbeddingsDTO":{"oneOf":[{"type":"object","properties":{"model":{"type":"string","enum":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"]},"input":{"anyOf":[{"type":"string","minLength":1},{"type":"array","items":{"type":"string"},"minItems":1}]},"encoding_format":{"type":"string","nullable":true,"enum":["float","base64"],"default":"float"},"dimensions":{"type":"number","nullable":true}},"required":["model","input"],"additionalProperties":false},{"type":"object","properties":{"model":{"type":"string","enum":["voyage-large-2-instruct","voyage-finance-2","voyage-multilingual-2","voyage-law-2","voyage-code-2","voyage-large-2","voyage-2"]},"input":{"anyOf":[{"type":"string","minLength":1,"maxLength":8000},{"type":"array","items":{"type":"string","maxLength":800}}]},"input_type":{"type":"string","enum":["document"],"default":"document"},"encoding_format":{"type":"string"}},"required":["model","input"],"additionalProperties":false},{"type":"object","properties":{"model":{"type":"string","enum":["togethercomputer/m2-bert-80M-32k-retrieval","BAAI/bge-base-en-v1.5","togethercomputer/m2-bert-80M-2k-retrieval","BAAI/bge-large-en-v1.5","togethercomputer/m2-bert-80M-8k-retrieval"]},"input":{"type":"string","minLength":1,"maxLength":3000},"encoding_format":{"type":"string"}},"required":["model","input"],"additionalProperties":false},{"type":"object","properties":{"model":{"type":"string","enum":["textembedding-gecko@001","textembedding-gecko@003","textembedding-gecko-multilingual@001","text-multilingual-embedding-002"]},"input":{"anyOf":[{"type":"string","minLength":1},{"type":"array","items":{"type":"string"},"minItems":1}]},"dimensions":{"type":"number","nullable":true},"auto_truncate":{"type":"boolean","default":true},"task_type":{"type":"string","enum":["RETRIEVAL_QUERY","RETRIEVAL_DOCUMENT","SEMANTIC_SIMILARITY","CLASSIFICATION","CLUSTERING","QUESTION_ANSWERING","FACT_VERIFICATION"]},"title":{"type":"string"},"encoding_format":{"type":"string"}},"required":["model","input"],"additionalProperties":false}]},"FileApi.v1.UploadFileDTO":{"type":"object","properties":{"purpose":{"type":"string","enum":["assistants"],"description":"The intended purpose of the uploaded file"}},"required":["purpose"]},"FileApi.v1.UploadFileResponseDTO":{"type":"object","properties":{"bytes":{"type":"integer","description":"The size of the file, in bytes"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the file was created."},"filename":{"type":"string","description":"The name of the file."},"expires_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the file will expire."},"id":{"type":"string","description":"The file identifier, which can be referenced in the API endpoints"},"object":{"type":"string","enum":["file"],"description":"The object type"},"purpose":{"type":"string","enum":["assistants"],"description":"The intended purpose of the file"}},"required":["bytes","created_at","filename","id","object","purpose"]},"FileApi.v1.GetFileResponseDTO":{"type":"object","properties":{"bytes":{"type":"integer","description":"The size of the file, in bytes"},"created_at":{"type":"integer","description":"The Unix timestamp (in seconds) for when the file was created."},"filename":{"type":"string","description":"The name of the file."},"expires_at":{"type":"integer","nullable":true,"description":"The Unix timestamp (in seconds) for when the file will expire."},"id":{"type":"string","description":"The file identifier, which can be referenced in the API endpoints"},"object":{"type":"string","enum":["file"],"description":"The object type"},"purpose":{"type":"string","enum":["assistants"],"description":"The intended purpose of the file"}},"required":["bytes","created_at","filename","id","object","purpose"]},"FileApi.v1.DeleteFileResponseDTO":{"type":"object","properties":{"id":{"type":"string"},"object":{"type":"string"},"deleted":{"type":"boolean"}},"required":["id","object","deleted"]}}}}