{
  "paths": {
    "/v1/tts": {
      "post": {
        "x-hideTryItPanel": true,
        "operationId": "VoiceModelsController_textToSpeech_v1",
        "parameters": [],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "type": "object",
                "properties": {
                  "model": {
                    "enum": [
                      "hume/octave-2"
                    ]
                  },
                  "text": {
                    "type": "string",
                    "minLength": 1,
                    "maxLength": 500000,
                    "description": "The text content to be converted to speech."
                  },
                  "voice": {
                    "type": "string",
                    "enum": [
                      "Vince Douglas",
                      "Male English Actor",
                      "Ava Song",
                      "Campfire Narrator",
                      "TikTok Fashion Influencer",
                      "Colton Rivers",
                      "Literature Professor",
                      "Booming American Narrator",
                      "Imani Carter",
                      "Terrence Bentley",
                      "Nature Documentary Narrator",
                      "Alice Bennett",
                      "Sitcom Girl",
                      "Unserious Movie Trailer Narrator",
                      "Articulate ASMR British Narrator",
                      "Big Dicky",
                      "English Children's Book Narrator",
                      "Sebastian Lockwood",
                      "Donovan Sinclair",
                      "Booming British Narrator",
                      "Relaxing ASMR Woman",
                      "Lady Elizabeth",
                      "Male Protagonist",
                      "Tough Guy",
                      "French Chef",
                      "Spanish Instructor",
                      "Charming Cowgirl"
                    ],
                    "default": "Vince Douglas",
                    "description": "Name of the voice to be used."
                  },
                  "format": {
                    "type": "string",
                    "enum": [
                      "wav",
                      "mp3"
                    ],
                    "description": "Audio output format. MP3 provides good compression and compatibility, PCM offers uncompressed high quality, and FLAC provides lossless compression."
                  }
                },
                "required": [
                  "model",
                  "text"
                ]
              }
            }
          }
        },
        "responses": {
          "201": {
            "description": "",
            "content": {
              "application/json": {
                "schema": {
                }
              }
            }
          }
        },
        "tags": [
          "Voice Models"
        ],
        "security": [
          {
            "access-token": []
          }
        ],
        "x-codeSamples": [
          {
            "lang": "cURL",
            "source": "curl -L \\\n  --request POST \\\n  --url 'https://api.aimlapi.com/v1/tts' \\\n  --header 'Authorization: Bearer <YOUR_API_KEY>' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n      \"model\": \"hume/octave-2\",\n      \"text\": \"Cities of the future promise to radically transform how people live, work, and move. Instead of sprawling layouts, we’ll see vertical structures that integrate residential, work, and public spaces into single, self-sustaining ecosystems. Architecture will adapt to climate conditions, and buildings will be energy-efficient—generating power through solar panels, wind turbines, and even foot traffic.\"\n    }'"
          },
          {
            "lang": "JavaScript",
            "source": "async function main() {\n  const response = await fetch('https://api.aimlapi.com/v1/tts', {\n    method: 'POST',\n    headers: {\n      'Authorization': 'Bearer <YOUR_API_KEY>',\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      \"model\": \"hume/octave-2\",\n      \"text\": \"Cities of the future promise to radically transform how people live, work, and move. Instead of sprawling layouts, we’ll see vertical structures that integrate residential, work, and public spaces into single, self-sustaining ecosystems. Architecture will adapt to climate conditions, and buildings will be energy-efficient—generating power through solar panels, wind turbines, and even foot traffic.\"\n    }),\n  });\n\n  const data = await response.json();\n  console.log(JSON.stringify(data, null, 2));\n}\n\nmain();"
          },
          {
            "lang": "Python",
            "source": "import requests\n\nresponse = requests.post(\n    \"https://api.aimlapi.com/v1/tts\",\n    headers={\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": \"Bearer <YOUR_API_KEY>\",\n    },\n    json={\n        \"model\": \"hume/octave-2\",\n        \"text\": \"Cities of the future promise to radically transform how people live, work, and move. Instead of sprawling layouts, we’ll see vertical structures that integrate residential, work, and public spaces into single, self-sustaining ecosystems. Architecture will adapt to climate conditions, and buildings will be energy-efficient—generating power through solar panels, wind turbines, and even foot traffic.\"\n      }\n)\n\ndata = response.json()\nprint(data)"
          }
        ]
      }
    }
  },
  "openapi": "3.0.0",
  "info": {
    "title": "AI/ML Gateway",
    "description": "",
    "version": "1.0",
    "contact": {}
  },
  "tags": [],
  "servers": [
    {
      "url": "https://api.aimlapi.com"
    }
  ],
  "components": {
    "securitySchemes": {
      "access-token": {
        "scheme": "bearer",
        "bearerFormat": "<YOUR_AIMLAPI_KEY>",
        "type": "http",
        "description": "Bearer key"
      }
    },
    "schemas": {
      "Voice.v1.SpeechToTextPayloadDTO": {
        "anyOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "#g1_nova-2-general",
                  "#g1_nova-2-meeting",
                  "#g1_nova-2-phonecall",
                  "#g1_nova-2-voicemail",
                  "#g1_nova-2-finance",
                  "#g1_nova-2-conversationalai",
                  "#g1_nova-2-video",
                  "#g1_nova-2-medical",
                  "#g1_nova-2-drivethru",
                  "#g1_nova-2-automotive",
                  "#g1_whisper-large",
                  "#g1_whisper-medium",
                  "#g1_whisper-small",
                  "#g1_whisper-tiny",
                  "#g1_whisper-base"
                ]
              },
              "custom_intent": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                ],
                "description": "A custom intent you want the model to detect within your input audio if present. Submit up to 100."
              },
              "custom_topic": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                ],
                "description": "A custom topic you want the model to detect within your input audio if present. Submit up to 100."
              },
              "custom_intent_mode": {
                "type": "string",
                "enum": [
                  "strict",
                  "extended"
                ],
                "description": "Sets how the model will interpret strings submitted to the custom_intent param. When strict, the model will only return intents submitted using the custom_intent param. When extended, the model will return its own detected intents in addition those submitted using the custom_intents param."
              },
              "custom_topic_mode": {
                "type": "string",
                "enum": [
                  "strict",
                  "extended"
                ],
                "description": "Sets how the model will interpret strings submitted to the custom_topic param. When strict, the model will only return topics submitted using the custom_topic param. When extended, the model will return its own detected topics in addition to those submitted using the custom_topic param."
              },
              "detect_language": {
                "type": "boolean",
                "description": "Enables language detection to identify the dominant language spoken in the submitted audio."
              },
              "detect_entities": {
                "type": "boolean",
                "description": "When Entity Detection is enabled, the Punctuation feature will be enabled by default."
              },
              "detect_topics": {
                "type": "boolean",
                "description": "Detects the most important and relevant topics that are referenced in speech within the audio."
              },
              "diarize": {
                "type": "boolean",
                "description": "Recognizes speaker changes. Each word in the transcript will be assigned a speaker number starting at 0."
              },
              "dictation": {
                "type": "boolean",
                "description": "Identifies and extracts key entities from content in submitted audio."
              },
              "diarize_version": {
                "type": "string",
                "description": ""
              },
              "extra": {
                "type": "string",
                "description": "Arbitrary key-value pairs that are attached to the API response for usage in downstream processing."
              },
              "filler_words": {
                "type": "boolean",
                "description": "Filler Words can help transcribe interruptions in your audio, like “uh” and “um”."
              },
              "intents": {
                "type": "boolean",
                "description": "Recognizes speaker intent throughout a transcript or text."
              },
              "keywords": {
                "type": "string",
                "description": "Keywords can boost or suppress specialized terminology and brands."
              },
              "language": {
                "type": "string",
                "description": "The BCP-47 language tag that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available"
              },
              "measurements": {
                "type": "boolean",
                "description": "Spoken measurements will be converted to their corresponding abbreviations"
              },
              "multi_channel": {
                "type": "boolean",
                "description": "Transcribes each audio channel independently"
              },
              "numerals": {
                "type": "boolean",
                "description": "Numerals converts numbers from written format to numerical format"
              },
              "paragraphs": {
                "type": "boolean",
                "description": "Splits audio into paragraphs to improve transcript readability"
              },
              "profanity_filter": {
                "type": "boolean",
                "description": "Profanity Filter looks for recognized profanity and converts it to the nearest recognized non-profane word or removes it from the transcript completely"
              },
              "punctuate": {
                "type": "boolean",
                "description": "Adds punctuation and capitalization to the transcript"
              },
              "search": {
                "type": "string",
                "description": "Search for terms or phrases in submitted audio"
              },
              "sentiment": {
                "type": "boolean",
                "description": "Recognizes the sentiment throughout a transcript or text"
              },
              "smart_format": {
                "type": "boolean",
                "description": "Applies formatting to transcript output. When set to true, additional formatting will be applied to transcripts to improve readability"
              },
              "summarize": {
                "type": "string",
                "description": "Summarizes content. For Listen API, supports string version option. For Read API, accepts boolean only."
              },
              "tag": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Labels your requests for the purpose of identification during usage reporting"
              },
              "topics": {
                "type": "boolean",
                "description": "Detects topics throughout a transcript or text"
              },
              "utterances": {
                "type": "boolean",
                "description": "Segments speech into meaningful semantic units"
              },
              "utt_split": {
                "type": "number",
                "description": "Seconds to wait before detecting a pause between words in submitted audio"
              },
              "url": {
                "type": "string",
                "format": "uri"
              }
            },
            "required": [
              "model",
              "url"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "#g1_nova-2-general",
                  "#g1_nova-2-meeting",
                  "#g1_nova-2-phonecall",
                  "#g1_nova-2-voicemail",
                  "#g1_nova-2-finance",
                  "#g1_nova-2-conversationalai",
                  "#g1_nova-2-video",
                  "#g1_nova-2-medical",
                  "#g1_nova-2-drivethru",
                  "#g1_nova-2-automotive",
                  "#g1_whisper-large",
                  "#g1_whisper-medium",
                  "#g1_whisper-small",
                  "#g1_whisper-tiny",
                  "#g1_whisper-base"
                ]
              },
              "custom_intent": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                ],
                "description": "A custom intent you want the model to detect within your input audio if present. Submit up to 100."
              },
              "custom_topic": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "type": "array",
                    "items": {
                      "type": "string"
                    }
                  }
                ],
                "description": "A custom topic you want the model to detect within your input audio if present. Submit up to 100."
              },
              "custom_intent_mode": {
                "type": "string",
                "enum": [
                  "strict",
                  "extended"
                ],
                "description": "Sets how the model will interpret strings submitted to the custom_intent param. When strict, the model will only return intents submitted using the custom_intent param. When extended, the model will return its own detected intents in addition those submitted using the custom_intents param."
              },
              "custom_topic_mode": {
                "type": "string",
                "enum": [
                  "strict",
                  "extended"
                ],
                "description": "Sets how the model will interpret strings submitted to the custom_topic param. When strict, the model will only return topics submitted using the custom_topic param. When extended, the model will return its own detected topics in addition to those submitted using the custom_topic param."
              },
              "detect_language": {
                "type": "boolean",
                "description": "Enables language detection to identify the dominant language spoken in the submitted audio."
              },
              "detect_entities": {
                "type": "boolean",
                "description": "When Entity Detection is enabled, the Punctuation feature will be enabled by default."
              },
              "detect_topics": {
                "type": "boolean",
                "description": "Detects the most important and relevant topics that are referenced in speech within the audio."
              },
              "diarize": {
                "type": "boolean",
                "description": "Recognizes speaker changes. Each word in the transcript will be assigned a speaker number starting at 0."
              },
              "dictation": {
                "type": "boolean",
                "description": "Identifies and extracts key entities from content in submitted audio."
              },
              "diarize_version": {
                "type": "string",
                "description": ""
              },
              "extra": {
                "type": "string",
                "description": "Arbitrary key-value pairs that are attached to the API response for usage in downstream processing."
              },
              "filler_words": {
                "type": "boolean",
                "description": "Filler Words can help transcribe interruptions in your audio, like “uh” and “um”."
              },
              "intents": {
                "type": "boolean",
                "description": "Recognizes speaker intent throughout a transcript or text."
              },
              "keywords": {
                "type": "string",
                "description": "Keywords can boost or suppress specialized terminology and brands."
              },
              "language": {
                "type": "string",
                "description": "The BCP-47 language tag that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available"
              },
              "measurements": {
                "type": "boolean",
                "description": "Spoken measurements will be converted to their corresponding abbreviations"
              },
              "multi_channel": {
                "type": "boolean",
                "description": "Transcribes each audio channel independently"
              },
              "numerals": {
                "type": "boolean",
                "description": "Numerals converts numbers from written format to numerical format"
              },
              "paragraphs": {
                "type": "boolean",
                "description": "Splits audio into paragraphs to improve transcript readability"
              },
              "profanity_filter": {
                "type": "boolean",
                "description": "Profanity Filter looks for recognized profanity and converts it to the nearest recognized non-profane word or removes it from the transcript completely"
              },
              "punctuate": {
                "type": "boolean",
                "description": "Adds punctuation and capitalization to the transcript"
              },
              "search": {
                "type": "string",
                "description": "Search for terms or phrases in submitted audio"
              },
              "sentiment": {
                "type": "boolean",
                "description": "Recognizes the sentiment throughout a transcript or text"
              },
              "smart_format": {
                "type": "boolean",
                "description": "Applies formatting to transcript output. When set to true, additional formatting will be applied to transcripts to improve readability"
              },
              "summarize": {
                "type": "string",
                "description": "Summarizes content. For Listen API, supports string version option. For Read API, accepts boolean only."
              },
              "tag": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Labels your requests for the purpose of identification during usage reporting"
              },
              "topics": {
                "type": "boolean",
                "description": "Detects topics throughout a transcript or text"
              },
              "utterances": {
                "type": "boolean",
                "description": "Segments speech into meaningful semantic units"
              },
              "utt_split": {
                "type": "number",
                "description": "Seconds to wait before detecting a pause between words in submitted audio"
              }
            },
            "required": [
              "model"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "aai/slam-1",
                  "aai/universal"
                ]
              },
              "audio": {
                "type": "object",
                "properties": {
                  "buffer": {
                    "nullable": true
                  },
                  "mimetype": {
                    "type": "string"
                  },
                  "size": {
                    "type": "integer"
                  },
                  "originalname": {
                    "type": "string"
                  },
                  "encoding": {
                    "type": "string"
                  },
                  "fieldname": {
                    "type": "string"
                  }
                },
                "required": [
                  "mimetype",
                  "originalname",
                  "encoding",
                  "fieldname"
                ],
                "description": "The audio file to transcribe."
              },
              "audio_start_from": {
                "type": "integer",
                "description": "The point in time, in milliseconds, in the file at which the transcription was started."
              },
              "audio_end_at": {
                "type": "integer",
                "description": "The point in time, in milliseconds, in the file at which the transcription was terminated."
              },
              "language_code": {
                "type": "string",
                "description": "The language of your audio file. Possible values are found in Supported Languages. The default value is 'en_us'."
              },
              "language_confidence_threshold": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "The confidence threshold for the automatically detected language. An error will be returned if the language confidence is below this threshold. Defaults to 0."
              },
              "language_detection": {
                "type": "boolean",
                "description": "Enable Automatic language detection, either true or false. Available for universal model only."
              },
              "punctuate": {
                "type": "boolean",
                "nullable": true,
                "default": null,
                "description": "Adds punctuation and capitalization to the transcript"
              },
              "format_text": {
                "type": "boolean",
                "default": true,
                "description": "Enable Text Formatting, can be true or false."
              },
              "disfluencies": {
                "type": "boolean",
                "default": false,
                "description": "Transcribe Filler Words, like \"umm\", in your media file; can be true or false."
              },
              "multichannel": {
                "type": "boolean",
                "default": false,
                "description": "Enable Multichannel transcription, can be true or false."
              },
              "speaker_labels": {
                "type": "boolean",
                "nullable": true,
                "default": null,
                "description": "Enable Speaker diarization, can be true or false."
              },
              "speakers_expected": {
                "type": "integer",
                "nullable": true,
                "default": null,
                "description": "Tell the speaker label model how many speakers it should attempt to identify. See Speaker diarization for more details."
              },
              "content_safety": {
                "type": "boolean",
                "default": false,
                "description": "Enable Content Moderation, can be true or false."
              },
              "iab_categories": {
                "type": "boolean",
                "default": false,
                "description": "Enable Topic Detection, can be true or false."
              },
              "custom_spelling": {
                "type": "array",
                "items": {
                  "type": "object",
                  "properties": {
                    "from": {
                      "type": "string"
                    },
                    "to": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "from",
                    "to"
                  ]
                },
                "description": "Customize how words are spelled and formatted using to and from values."
              },
              "auto_highlights": {
                "type": "boolean",
                "default": false,
                "description": "Enable Key Phrases, either true or false."
              },
              "word_boost": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "The list of custom vocabulary to boost transcription probability for."
              },
              "boost_param": {
                "type": "string",
                "enum": [
                  "low",
                  "default",
                  "high"
                ],
                "description": "How much to boost specified words. Allowed values: low, default, high."
              },
              "filter_profanity": {
                "type": "boolean",
                "default": false,
                "description": "Filter profanity from the transcribed text, can be true or false."
              },
              "redact_pii": {
                "type": "boolean",
                "default": false,
                "description": "Redact PII from the transcribed text using the Redact PII model, can be true or false."
              },
              "redact_pii_audio": {
                "type": "boolean",
                "default": false,
                "description": "Generate a copy of the original media file with spoken PII \"beeped\" out, can be true or false. See PII redaction for more details."
              },
              "redact_pii_audio_quality": {
                "type": "string",
                "enum": [
                  "mp3",
                  "wav"
                ],
                "description": "Controls the filetype of the audio created by redact_pii_audio. Currently supports mp3 (default) and wav. See PII redaction for more details."
              },
              "redact_pii_policies": {
                "type": "array",
                "items": {
                  "type": "string",
                  "enum": [
                    "account_number",
                    "banking_information",
                    "blood_type",
                    "credit_card_cvv",
                    "credit_card_expiration",
                    "credit_card_number",
                    "date",
                    "date_interval",
                    "date_of_birth",
                    "drivers_license",
                    "drug",
                    "duration",
                    "email_address",
                    "event",
                    "filename",
                    "gender_sexuality",
                    "healthcare_number",
                    "injury",
                    "ip_address",
                    "language",
                    "location",
                    "marital_status",
                    "medical_condition",
                    "medical_process",
                    "money_amount",
                    "nationality",
                    "number_sequence",
                    "occupation",
                    "organization",
                    "passport_number",
                    "password",
                    "person_age",
                    "person_name",
                    "phone_number",
                    "physical_attribute",
                    "political_affiliation",
                    "religion",
                    "statistics",
                    "time",
                    "url",
                    "us_social_security_number",
                    "username",
                    "vehicle_id",
                    "zodiac_sign"
                  ]
                },
                "description": "The list of PII Redaction policies to enable. See PII redaction for more details."
              },
              "redact_pii_sub": {
                "type": "string",
                "enum": [
                  "entity_name",
                  "hash"
                ],
                "description": "The replacement logic for detected PII, can be `entity_type` or `hash`. See PII redaction for more details."
              },
              "sentiment_analysis": {
                "type": "boolean",
                "default": false,
                "description": "Enable Sentiment Analysis, can be true or false."
              },
              "entity_detection": {
                "type": "boolean",
                "default": false,
                "description": "Enable Entity Detection, can be true or false."
              },
              "summarization": {
                "type": "boolean",
                "default": false,
                "description": "Enable Summarization, can be true or false."
              },
              "summary_model": {
                "type": "string",
                "enum": [
                  "informative",
                  "conversational",
                  "catchy"
                ],
                "description": "The model to summarize the transcript. Allowed values: informative, conversational, catchy."
              },
              "summary_type": {
                "type": "string",
                "enum": [
                  "bullets",
                  "bullets_verbose",
                  "gist",
                  "headline",
                  "paragraph"
                ],
                "description": "The type of summary. Allowed values: bullets, bullets_verbose, gist, headline, paragraph."
              },
              "auto_chapters": {
                "type": "boolean",
                "default": false,
                "description": "Enable Auto Chapters, either true or false."
              },
              "speech_threshold": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Reject audio files that contain less than this fraction of speech. Valid values are in the range [0, 1] inclusive."
              }
            },
            "required": [
              "model",
              "audio"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "aai/slam-1",
                  "aai/universal"
                ]
              },
              "url": {
                "type": "string",
                "format": "uri",
                "description": "URL of the input audio file."
              },
              "audio_start_from": {
                "type": "integer",
                "description": "The point in time, in milliseconds, in the file at which the transcription was started."
              },
              "audio_end_at": {
                "type": "integer",
                "description": "The point in time, in milliseconds, in the file at which the transcription was terminated."
              },
              "language_code": {
                "type": "string",
                "description": "The language of your audio file. Possible values are found in Supported Languages. The default value is 'en_us'."
              },
              "language_confidence_threshold": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "The confidence threshold for the automatically detected language. An error will be returned if the language confidence is below this threshold. Defaults to 0."
              },
              "language_detection": {
                "type": "boolean",
                "description": "Enable Automatic language detection, either true or false. Available for universal model only."
              },
              "punctuate": {
                "type": "boolean",
                "nullable": true,
                "default": null,
                "description": "Adds punctuation and capitalization to the transcript"
              },
              "format_text": {
                "type": "boolean",
                "default": true,
                "description": "Enable Text Formatting, can be true or false."
              },
              "disfluencies": {
                "type": "boolean",
                "default": false,
                "description": "Transcribe Filler Words, like \"umm\", in your media file; can be true or false."
              },
              "multichannel": {
                "type": "boolean",
                "default": false,
                "description": "Enable Multichannel transcription, can be true or false."
              },
              "speaker_labels": {
                "type": "boolean",
                "nullable": true,
                "default": false,
                "description": "Enable Speaker diarization, can be true or false."
              },
              "speakers_expected": {
                "type": "integer",
                "nullable": true,
                "default": null,
                "description": "Tell the speaker label model how many speakers it should attempt to identify. See Speaker diarization for more details."
              },
              "content_safety": {
                "type": "boolean",
                "default": false,
                "description": "Enable Content Moderation, can be true or false."
              },
              "iab_categories": {
                "type": "boolean",
                "default": false,
                "description": "Enable Topic Detection, can be true or false."
              },
              "custom_spelling": {
                "type": "array",
                "items": {
                  "type": "object",
                  "properties": {
                    "from": {
                      "type": "string"
                    },
                    "to": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "from",
                    "to"
                  ]
                },
                "description": "Customize how words are spelled and formatted using to and from values."
              },
              "auto_highlights": {
                "type": "boolean",
                "default": false,
                "description": "Enable Key Phrases, either true or false."
              },
              "word_boost": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "The list of custom vocabulary to boost transcription probability for."
              },
              "boost_param": {
                "type": "string",
                "enum": [
                  "low",
                  "default",
                  "high"
                ],
                "description": "How much to boost specified words. Allowed values: low, default, high."
              },
              "filter_profanity": {
                "type": "boolean",
                "default": false,
                "description": "Filter profanity from the transcribed text, can be true or false."
              },
              "redact_pii": {
                "type": "boolean",
                "default": false,
                "description": "Redact PII from the transcribed text using the Redact PII model, can be true or false."
              },
              "redact_pii_audio": {
                "type": "boolean",
                "default": false,
                "description": "Generate a copy of the original media file with spoken PII \"beeped\" out, can be true or false. See PII redaction for more details."
              },
              "redact_pii_audio_quality": {
                "type": "string",
                "enum": [
                  "mp3",
                  "wav"
                ],
                "description": "Controls the filetype of the audio created by redact_pii_audio. Currently supports mp3 (default) and wav. See PII redaction for more details."
              },
              "redact_pii_policies": {
                "type": "array",
                "items": {
                  "type": "string",
                  "enum": [
                    "account_number",
                    "banking_information",
                    "blood_type",
                    "credit_card_cvv",
                    "credit_card_expiration",
                    "credit_card_number",
                    "date",
                    "date_interval",
                    "date_of_birth",
                    "drivers_license",
                    "drug",
                    "duration",
                    "email_address",
                    "event",
                    "filename",
                    "gender_sexuality",
                    "healthcare_number",
                    "injury",
                    "ip_address",
                    "language",
                    "location",
                    "marital_status",
                    "medical_condition",
                    "medical_process",
                    "money_amount",
                    "nationality",
                    "number_sequence",
                    "occupation",
                    "organization",
                    "passport_number",
                    "password",
                    "person_age",
                    "person_name",
                    "phone_number",
                    "physical_attribute",
                    "political_affiliation",
                    "religion",
                    "statistics",
                    "time",
                    "url",
                    "us_social_security_number",
                    "username",
                    "vehicle_id",
                    "zodiac_sign"
                  ]
                },
                "description": "The list of PII Redaction policies to enable. See PII redaction for more details."
              },
              "redact_pii_sub": {
                "type": "string",
                "enum": [
                  "entity_name",
                  "hash"
                ],
                "description": "The replacement logic for detected PII, can be `entity_type` or `hash`. See PII redaction for more details."
              },
              "sentiment_analysis": {
                "type": "boolean",
                "default": false,
                "description": "Enable Sentiment Analysis, can be true or false."
              },
              "entity_detection": {
                "type": "boolean",
                "default": false,
                "description": "Enable Entity Detection, can be true or false."
              },
              "summarization": {
                "type": "boolean",
                "default": false,
                "description": "Enable Summarization, can be true or false."
              },
              "summary_model": {
                "type": "string",
                "enum": [
                  "informative",
                  "conversational",
                  "catchy"
                ],
                "description": "The model to summarize the transcript. Allowed values: informative, conversational, catchy."
              },
              "summary_type": {
                "type": "string",
                "enum": [
                  "bullets",
                  "bullets_verbose",
                  "gist",
                  "headline",
                  "paragraph"
                ],
                "description": "The type of summary. Allowed values: bullets, bullets_verbose, gist, headline, paragraph."
              },
              "auto_chapters": {
                "type": "boolean",
                "default": false,
                "description": "Enable Auto Chapters, either true or false."
              },
              "speech_threshold": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Reject audio files that contain less than this fraction of speech. Valid values are in the range [0, 1] inclusive."
              }
            },
            "required": [
              "model",
              "url"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "openai/gpt-4o-transcribe",
                  "openai/gpt-4o-mini-transcribe"
                ]
              },
              "language": {
                "type": "string",
                "description": "The BCP-47 language tag that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available"
              },
              "prompt": {
                "type": "string",
                "description": "An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language."
              },
              "temperature": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "default": 0,
                "description": "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
              },
              "url": {
                "type": "string",
                "format": "uri",
                "description": "URL of the input audio file."
              }
            },
            "required": [
              "model",
              "url"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "openai/gpt-4o-transcribe",
                  "openai/gpt-4o-mini-transcribe"
                ]
              },
              "language": {
                "type": "string",
                "description": "The BCP-47 language tag that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available"
              },
              "prompt": {
                "type": "string",
                "description": "An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language."
              },
              "temperature": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "default": 0,
                "description": "The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
              }
            },
            "required": [
              "model"
            ]
          }
        ]
      },
      "Voice.v1.TextToSpeechPayload": {
        "anyOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "#g1_aura-asteria-en",
                  "#g1_aura-hera-en",
                  "#g1_aura-luna-en",
                  "#g1_aura-stella-en",
                  "#g1_aura-athena-en",
                  "#g1_aura-zeus-en",
                  "#g1_aura-orion-en",
                  "#g1_aura-arcas-en",
                  "#g1_aura-perseus-en",
                  "#g1_aura-angus-en",
                  "#g1_aura-orpheus-en",
                  "#g1_aura-helios-en",
                  "#g1_aura-2-amalthea-en",
                  "#g1_aura-2-andromeda-en",
                  "#g1_aura-2-apollo-en",
                  "#g1_aura-2-arcas-en",
                  "#g1_aura-2-aries-en",
                  "#g1_aura-2-asteria-en",
                  "#g1_aura-2-athena-en",
                  "#g1_aura-2-atlas-en",
                  "#g1_aura-2-aurora-en",
                  "#g1_aura-2-callista-en",
                  "#g1_aura-2-cora-en",
                  "#g1_aura-2-cordelia-en",
                  "#g1_aura-2-delia-en",
                  "#g1_aura-2-draco-en",
                  "#g1_aura-2-electra-en",
                  "#g1_aura-2-harmonia-en",
                  "#g1_aura-2-helena-en",
                  "#g1_aura-2-hera-en",
                  "#g1_aura-2-hermes-en",
                  "#g1_aura-2-hyperion-en",
                  "#g1_aura-2-iris-en",
                  "#g1_aura-2-janus-en",
                  "#g1_aura-2-juno-en",
                  "#g1_aura-2-jupiter-en",
                  "#g1_aura-2-luna-en",
                  "#g1_aura-2-mars-en",
                  "#g1_aura-2-minerva-en",
                  "#g1_aura-2-neptune-en",
                  "#g1_aura-2-odysseus-en",
                  "#g1_aura-2-ophelia-en",
                  "#g1_aura-2-orion-en",
                  "#g1_aura-2-orpheus-en",
                  "#g1_aura-2-pandora-en",
                  "#g1_aura-2-phoebe-en",
                  "#g1_aura-2-pluto-en",
                  "#g1_aura-2-saturn-en",
                  "#g1_aura-2-selene-en",
                  "#g1_aura-2-thalia-en",
                  "#g1_aura-2-theia-en",
                  "#g1_aura-2-vesta-en",
                  "#g1_aura-2-zeus-en",
                  "#g1_aura-2-celeste-es",
                  "#g1_aura-2-estrella-es",
                  "#g1_aura-2-nestor-es"
                ]
              },
              "text": {
                "type": "string",
                "description": "The text content to be converted to speech."
              },
              "container": {
                "type": "string",
                "description": "The file format wrapper for the output audio. The available options depend on the encoding type."
              },
              "encoding": {
                "type": "string",
                "enum": [
                  "linear16",
                  "mulaw",
                  "alaw",
                  "mp3",
                  "opus",
                  "flac",
                  "aac"
                ],
                "default": "linear16",
                "description": "Specifies the expected encoding of your audio output"
              },
              "sample_rate": {
                "type": "string",
                "description": "Audio sample rate in Hz."
              }
            },
            "required": [
              "model",
              "text"
            ]
          },
          {
            "oneOf": [
              {
                "type": "object",
                "properties": {
                  "model": {
                    "type": "string",
                    "enum": [
                      "elevenlabs/eleven_multilingual_v2",
                      "elevenlabs/eleven_turbo_v2_5"
                    ]
                  },
                  "text": {
                    "type": "string",
                    "description": "The text content to be converted to speech."
                  },
                  "voice": {
                    "type": "string",
                    "enum": [
                      "Rachel",
                      "Drew",
                      "Clyde",
                      "Paul",
                      "Aria",
                      "Domi",
                      "Dave",
                      "Roger",
                      "Fin",
                      "Sarah",
                      "Antoni",
                      "Laura",
                      "Thomas",
                      "Charlie",
                      "George",
                      "Emily",
                      "Elli",
                      "Callum",
                      "Patrick",
                      "River",
                      "Harry",
                      "Liam",
                      "Dorothy",
                      "Josh",
                      "Arnold",
                      "Charlotte",
                      "Alice",
                      "Matilda",
                      "James",
                      "Joseph",
                      "Will",
                      "Jeremy",
                      "Jessica",
                      "Eric",
                      "Michael",
                      "Ethan",
                      "Chris",
                      "Gigi",
                      "Freya",
                      "Santa Claus",
                      "Brian",
                      "Grace",
                      "Daniel",
                      "Lily",
                      "Serena",
                      "Adam",
                      "Nicole",
                      "Bill",
                      "Jessie",
                      "Sam",
                      "Glinda",
                      "Giovanni",
                      "Mimi"
                    ],
                    "default": "Rachel",
                    "description": "Name of the voice to be used."
                  },
                  "apply_text_normalization": {
                    "type": "string",
                    "enum": [
                      "auto",
                      "on",
                      "off"
                    ],
                    "description": "This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped."
                  },
                  "next_text": {
                    "type": "string",
                    "description": "The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation."
                  },
                  "previous_text": {
                    "type": "string",
                    "description": "The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation."
                  },
                  "output_format": {
                    "type": "string",
                    "enum": [
                      "mp3_22050_32",
                      "mp3_44100_32",
                      "mp3_44100_64",
                      "mp3_44100_96",
                      "mp3_44100_128",
                      "mp3_44100_192",
                      "pcm_8000",
                      "pcm_16000",
                      "pcm_22050",
                      "pcm_24000",
                      "pcm_44100",
                      "pcm_48000",
                      "ulaw_8000",
                      "alaw_8000",
                      "opus_48000_32",
                      "opus_48000_64",
                      "opus_48000_96",
                      "opus_48000_128",
                      "opus_48000_192"
                    ],
                    "description": "Format of the output content for non-streaming requests. Controls how the generated audio data is encoded in the response."
                  },
                  "voice_settings": {
                    "type": "object",
                    "properties": {
                      "stability": {
                        "type": "number",
                        "description": "Determines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion."
                      },
                      "use_speaker_boost": {
                        "type": "boolean",
                        "description": "This setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency."
                      },
                      "similarity_boost": {
                        "type": "number",
                        "description": "Determines how closely the AI should adhere to the original voice when attempting to replicate it."
                      },
                      "style": {
                        "type": "number",
                        "description": "Determines the style exaggeration of the voice. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0."
                      },
                      "speed": {
                        "type": "number",
                        "description": "Adjusts the speed of the voice. A value of 1.0 is the default speed, while values less than 1.0 slow down the speech, and values greater than 1.0 speed it up."
                      }
                    },
                    "description": "Voice settings overriding stored settings for the given voice. They are applied only on the given request."
                  },
                  "seed": {
                    "type": "integer",
                    "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed."
                  }
                },
                "required": [
                  "model",
                  "text"
                ]
              },
              {
                "type": "object",
                "properties": {
                  "model": {
                    "type": "string",
                    "enum": [
                      "elevenlabs/v3_alpha"
                    ]
                  },
                  "text": {
                    "type": "string",
                    "description": "The text content to be converted to speech."
                  },
                  "voice": {
                    "type": "string",
                    "enum": [
                      "Rachel",
                      "Drew",
                      "Clyde",
                      "Paul",
                      "Aria",
                      "Domi",
                      "Dave",
                      "Roger",
                      "Fin",
                      "Sarah",
                      "Antoni",
                      "Laura",
                      "Thomas",
                      "Charlie",
                      "George",
                      "Emily",
                      "Elli",
                      "Callum",
                      "Patrick",
                      "River",
                      "Harry",
                      "Liam",
                      "Dorothy",
                      "Josh",
                      "Arnold",
                      "Charlotte",
                      "Alice",
                      "Matilda",
                      "James",
                      "Joseph",
                      "Will",
                      "Jeremy",
                      "Jessica",
                      "Eric",
                      "Michael",
                      "Ethan",
                      "Chris",
                      "Gigi",
                      "Freya",
                      "Santa Claus",
                      "Brian",
                      "Grace",
                      "Daniel",
                      "Lily",
                      "Serena",
                      "Adam",
                      "Nicole",
                      "Bill",
                      "Jessie",
                      "Sam",
                      "Glinda",
                      "Giovanni",
                      "Mimi"
                    ],
                    "default": "Rachel",
                    "description": "Name of the voice to be used."
                  },
                  "apply_text_normalization": {
                    "type": "string",
                    "enum": [
                      "auto",
                      "on",
                      "off"
                    ],
                    "description": "This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped."
                  },
                  "output_format": {
                    "type": "string",
                    "enum": [
                      "mp3_22050_32",
                      "mp3_44100_32",
                      "mp3_44100_64",
                      "mp3_44100_96",
                      "mp3_44100_128",
                      "mp3_44100_192",
                      "pcm_8000",
                      "pcm_16000",
                      "pcm_22050",
                      "pcm_24000",
                      "pcm_44100",
                      "pcm_48000",
                      "ulaw_8000",
                      "alaw_8000",
                      "opus_48000_32",
                      "opus_48000_64",
                      "opus_48000_96",
                      "opus_48000_128",
                      "opus_48000_192"
                    ],
                    "description": "Format of the output content for non-streaming requests. Controls how the generated audio data is encoded in the response."
                  },
                  "voice_settings": {
                    "type": "object",
                    "properties": {
                      "stability": {
                        "type": "number",
                        "description": "Determines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion."
                      },
                      "use_speaker_boost": {
                        "type": "boolean",
                        "description": "This setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency."
                      },
                      "similarity_boost": {
                        "type": "number",
                        "description": "Determines how closely the AI should adhere to the original voice when attempting to replicate it."
                      },
                      "style": {
                        "type": "number",
                        "description": "Determines the style exaggeration of the voice. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0."
                      },
                      "speed": {
                        "type": "number",
                        "description": "Adjusts the speed of the voice. A value of 1.0 is the default speed, while values less than 1.0 slow down the speech, and values greater than 1.0 speed it up."
                      }
                    },
                    "description": "Voice settings overriding stored settings for the given voice. They are applied only on the given request."
                  },
                  "seed": {
                    "type": "integer",
                    "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed."
                  }
                },
                "required": [
                  "model",
                  "text"
                ]
              }
            ]
          },
          {
            "$ref": "#/components/schemas/Minimax.v2.TextToSpeechPayloadDTO"
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "microsoft/vibevoice-7b",
                  "microsoft/vibevoice-1.5b"
                ]
              },
              "script": {
                "type": "string",
                "minLength": 1,
                "maxLength": 5000,
                "description": "The script to convert to speech. Can be formatted with \"Speaker X:\" prefixes for multi-speaker dialogues."
              },
              "speakers": {
                "type": "array",
                "items": {
                  "type": "object",
                  "properties": {
                    "preset": {
                      "type": "string",
                      "enum": [
                        "Alice [EN]",
                        "Alice [EN] (Background Music)",
                        "Carter [EN]",
                        "Frank [EN]",
                        "Maya [EN]",
                        "Anchen [ZH] (Background Music)",
                        "Bowen [ZH]",
                        "Xinran [ZH]"
                      ],
                      "description": "Default voice preset to use for the speaker. Not used if audio_url is provided."
                    },
                    "audio_url": {
                      "type": "string",
                      "format": "uri",
                      "description": "URL to a voice sample audio file. If provided, preset will be ignored."
                    }
                  }
                },
                "minItems": 1,
                "maxItems": 4,
                "default": [
                  {
                    "preset": "Alice [EN]"
                  }
                ],
                "description": "List of speakers to use for the script. If not provided, will be inferred from the script or voice samples."
              },
              "seed": {
                "type": "integer",
                "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed."
              },
              "cfg_scale": {
                "type": "number",
                "minimum": 0.1,
                "maximum": 2,
                "default": 1.3,
                "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt."
              }
            },
            "required": [
              "model",
              "script"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "alibaba/qwen3-tts-flash"
                ]
              },
              "text": {
                "type": "string",
                "minLength": 1,
                "maxLength": 600,
                "description": "The text content to be converted to speech."
              },
              "voice": {
                "type": "string",
                "enum": [
                  "Cherry",
                  "Ethan",
                  "Nofish",
                  "Jennifer",
                  "Ryan",
                  "Katerina",
                  "Elias",
                  "Jada",
                  "Dylan",
                  "Sunny",
                  "Li",
                  "Marcus",
                  "Roy",
                  "Peter",
                  "Rocky",
                  "Kiki",
                  "Eric"
                ],
                "default": "Cherry",
                "description": "Name of the voice to be used."
              }
            },
            "required": [
              "model",
              "text"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "openai/gpt-4o-mini-tts",
                  "openai/tts-1",
                  "openai/tts-1-hd"
                ]
              },
              "text": {
                "type": "string",
                "minLength": 1,
                "maxLength": 4096,
                "description": "The text content to be converted to speech."
              },
              "voice": {
                "type": "string",
                "enum": [
                  "alloy",
                  "ash",
                  "ballad",
                  "coral",
                  "echo",
                  "fable",
                  "nova",
                  "onyx",
                  "sage",
                  "shimmer",
                  "verse"
                ],
                "default": "alloy",
                "description": "Name of the voice to be used."
              },
              "style": {
                "type": "string",
                "description": "Determines the style exaggeration of the voice. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0."
              },
              "response_format": {
                "type": "string",
                "enum": [
                  "mp3",
                  "opus",
                  "aac",
                  "flac",
                  "wav",
                  "pcm"
                ],
                "default": "mp3",
                "description": "Format of the output content for non-streaming requests. Controls how the generated audio data is encoded in the response."
              },
              "speed": {
                "type": "number",
                "minimum": 0.25,
                "maximum": 4,
                "default": 1,
                "description": "Adjusts the speed of the voice. A value of 1.0 is the default speed, while values less than 1.0 slow down the speech, and values greater than 1.0 speed it up."
              }
            },
            "required": [
              "model",
              "text"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "hume/octave-2"
                ]
              },
              "text": {
                "type": "string",
                "minLength": 1,
                "maxLength": 500000,
                "description": "The text content to be converted to speech."
              },
              "voice": {
                "type": "string",
                "enum": [
                  "Vince Douglas",
                  "Male English Actor",
                  "Ava Song",
                  "Campfire Narrator",
                  "TikTok Fashion Influencer",
                  "Colton Rivers",
                  "Literature Professor",
                  "Booming American Narrator",
                  "Imani Carter",
                  "Terrence Bentley",
                  "Nature Documentary Narrator",
                  "Alice Bennett",
                  "Sitcom Girl",
                  "Unserious Movie Trailer Narrator",
                  "Articulate ASMR British Narrator",
                  "Big Dicky",
                  "English Children's Book Narrator",
                  "Sebastian Lockwood",
                  "Donovan Sinclair",
                  "Booming British Narrator",
                  "Relaxing ASMR Woman",
                  "Lady Elizabeth",
                  "Male Protagonist",
                  "Tough Guy",
                  "French Chef",
                  "Spanish Instructor",
                  "Charming Cowgirl"
                ],
                "default": "Vince Douglas",
                "description": "Name of the voice to be used."
              },
              "format": {
                "type": "string",
                "enum": [
                  "wav",
                  "mp3"
                ],
                "description": "Audio output format. MP3 provides good compression and compatibility, PCM offers uncompressed high quality, and FLAC provides lossless compression."
              }
            },
            "required": [
              "model",
              "text"
            ]
          },
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "enum": [
                  "inworld/tts-1",
                  "inworld/tts-1-max"
                ]
              },
              "text": {
                "type": "string",
                "minLength": 1,
                "maxLength": 500000,
                "description": "The text content to be converted to speech."
              },
              "voice": {
                "type": "string",
                "enum": [
                  "Alex",
                  "Ashley",
                  "Craig",
                  "Deborah",
                  "Dennis",
                  "Dominus",
                  "Edward",
                  "Elizabeth",
                  "Hades",
                  "Heitor",
                  "Julia",
                  "Maitê",
                  "Mark",
                  "Olivia",
                  "Pixie",
                  "Priya",
                  "Ronald",
                  "Sarah",
                  "Shaun",
                  "Theodore",
                  "Timothy",
                  "Wendy"
                ],
                "default": "Alex",
                "description": "Name of the voice to be used."
              },
              "format": {
                "type": "string",
                "enum": [
                  "wav",
                  "mp3"
                ],
                "default": "mp3",
                "description": "Audio output format. WAV delivers uncompressed audio in a widely supported container format, while MP3 provides good compression and compatibility."
              }
            },
            "required": [
              "model",
              "text"
            ]
          }
        ]
      },
      "Voice.v1.TextToSpeechResponse": {
        "type": "object",
        "properties": {
          "metadata": {
            "type": "object",
            "properties": {
              "transaction_key": {
                "type": "string"
              },
              "request_id": {
                "type": "string"
              },
              "sha256": {
                "type": "string"
              },
              "created": {
                "type": "string",
                "format": "date-time"
              },
              "duration": {
                "type": "number"
              },
              "channels": {
                "type": "number"
              },
              "models": {
                "type": "array",
                "items": {
                  "type": "string"
                }
              },
              "model_info": {
                "type": "object",
                "additionalProperties": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string"
                    },
                    "version": {
                      "type": "string"
                    },
                    "arch": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "name",
                    "version",
                    "arch"
                  ]
                }
              }
            },
            "required": [
              "transaction_key",
              "request_id",
              "sha256",
              "created",
              "duration",
              "channels",
              "models",
              "model_info"
            ]
          }
        },
        "required": [
          "metadata"
        ]
      }
    }
  }
}