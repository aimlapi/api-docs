# Table of contents

## Quickstart

* [üß≠ Documentation Map](README.md)
* [Setting Up](quickstart/setting-up.md)
* [Supported SDKs](quickstart/supported-sdks.md)

## API REFERENCES

* [üìí All Model IDs](api-references/model-database.md)
* [Text Models (LLM)](api-references/text-models-llm/README.md)
  * [Alibaba Cloud](api-references/text-models-llm/Alibaba-Cloud/README.md)
    * [qwen-max](api-references/text-models-llm/Alibaba-Cloud/qwen-max.md)
    * [qwen-plus](api-references/text-models-llm/Alibaba-Cloud/qwen-plus.md)
    * [qwen-turbo](api-references/text-models-llm/Alibaba-Cloud/qwen-turbo.md)
    * [Qwen2-72B-Instruct](api-references/text-models-llm/Alibaba-Cloud/Qwen2-72B-Instruct.md)
    * [Qwen2.5-7B-Instruct-Turbo](api-references/text-models-llm/Alibaba-Cloud/Qwen2.5-7B-Instruct-Turbo.md)
    * [Qwen2.5-72B-Instruct-Turbo](api-references/text-models-llm/Alibaba-Cloud/Qwen2.5-72B-Instruct-Turbo.md)
    * [Qwen2.5-Coder-32B-Instruct](api-references/text-models-llm/Alibaba-Cloud/Qwen2.5-Coder-32B-Instruct.md)
    * [Qwen-QwQ-32B](api-references/text-models-llm/alibaba-cloud/qwen-qwq-32b.md)
    * [Qwen3-235B-A22B](api-references/text-models-llm/alibaba-cloud/qwen3-235b-a22b.md)
    * [qwen3-32b](api-references/text-models-llm/alibaba-cloud/qwen3-32b.md)
    * [qwen3-coder-480b-a35b-instruct](api-references/text-models-llm/alibaba-cloud/qwen3-coder-480b-a35b-instruct.md)
    * [qwen3-235b-a22b-thinking-2507](api-references/text-models-llm/alibaba-cloud/qwen3-235b-a22b-thinking-2507.md)
  * [Anthracite](api-references/text-models-llm/Anthracite/README.md)
    * [magnum-v4](api-references/text-models-llm/Anthracite/magnum-v4.md)
  * [Anthropic](api-references/text-models-llm/Anthropic/README.md)
    * [Claude 3 Haiku](api-references/text-models-llm/Anthropic/claude-3-haiku.md)
    * [Claude 3 Opus](api-references/text-models-llm/Anthropic/claude-3-opus.md)
    * [Claude 3.5 Haiku](api-references/text-models-llm/anthropic/claude-3.5-haiku.md)
    * [Claude 3.5 Sonnet](api-references/text-models-llm/Anthropic/claude-3.5-sonnet.md)
    * [Claude 3.7 Sonnet](api-references/text-models-llm/anthropic/claude-3.7-sonnet.md)
    * [Claude 4 Opus](api-references/text-models-llm/anthropic/claude-4-opus.md)
    * [Claude 4 Sonnet](api-references/text-models-llm/anthropic/claude-4-sonnet.md)
  * [Cohere](api-references/text-models-llm/Cohere/README.md)
    * [command-r-plus](api-references/text-models-llm/Cohere/command-r-plus.md)
    * [command-a](api-references/text-models-llm/cohere/command-a.md)
  * [DeepSeek](api-references/text-models-llm/DeepSeek/README.md)
    * [DeepSeek V3](api-references/text-models-llm/DeepSeek/deepseek-chat.md)
    * [DeepSeek R1](api-references/text-models-llm/DeepSeek/deepseek-r1.md)
    * [DeepSeek Prover V2](api-references/text-models-llm/deepseek/deepseek-prover-v2.md)
  * [Google](api-references/text-models-llm/Google/README.md)
    * [gemini-2.0-flash-exp](api-references/text-models-llm/Google/gemini-2.0-flash-exp.md)
    * [gemini-2.0-flash](api-references/text-models-llm/google/gemini-2.0-flash.md)
    * [gemini-2.5-flash-lite-preview](api-references/text-models-llm/google/gemini-2.5-flash-lite-preview.md)
    * [gemini-2.5-flash](api-references/text-models-llm/google/gemini-2.5-flash.md)
    * [gemini-2.5-pro](api-references/text-models-llm/google/gemini-2.5-pro.md)
    * [gemma-2](api-references/text-models-llm/Google/gemma-2-27b-it.md)
    * [gemma-3](api-references/text-models-llm/google/gemma-3.md)
    * [gemma-3n-4b](api-references/text-models-llm/google/gemma-3n-4b.md)
  * [Meta](api-references/text-models-llm/Meta/README.md)
    * [Llama-3-chat-hf](api-references/text-models-llm/Meta/Llama-3-chat-hf.md)
    * [Llama-3-8B-Instruct-Lite](api-references/text-models-llm/Meta/Meta-Llama-3-8B-Instruct-Lite.md)
    * [Llama-3.1-8B-Instruct-Turbo](api-references/text-models-llm/Meta/Meta-Llama-3.1-8B-Instruct-Turbo.md)
    * [Llama-3.1-70B-Instruct-Turbo](api-references/text-models-llm/Meta/Meta-Llama-3.1-70B-Instruct-Turbo.md)
    * [Llama-3.1-405B-Instruct-Turbo](api-references/text-models-llm/Meta/Meta-Llama-3.1-405B-Instruct-Turbo.md)
    * [Llama-3.2-11B-Vision-Instruct-Turbo](api-references/text-models-llm/Meta/Llama-3.2-11B-Vision-Instruct-Turbo.md)
    * [Llama-3.2-90B-Vision-Instruct-Turbo](api-references/text-models-llm/Meta/Llama-3.2-90B-Vision-Instruct-Turbo.md)
    * [Llama-Vision-Free](api-references/text-models-llm/Meta/Llama-Vision-Free.md)
    * [Llama-3.2-3B-Instruct-Turbo](api-references/text-models-llm/Meta/Llama-3.2-3B-Instruct-Turbo.md)
    * [Llama-3.3-70B-Instruct-Turbo](api-references/text-models-llm/Meta/Llama-3.3-70B-Instruct-Turbo.md)
    * [Llama-4-scout](api-references/text-models-llm/meta/llama-4-scout.md)
    * [Llama-4-maverick](api-references/text-models-llm/meta/llama-4-maverick.md)
  * [MiniMax](api-references/text-models-llm/MiniMax/README.md)
    * [text-01](api-references/text-models-llm/MiniMax/text-01.md)
    * [abab6.5s-chat](api-references/text-models-llm/MiniMax/abab6.5s-chat.md)
    * [m1](api-references/text-models-llm/minimax/m1.md)
  * [Mistral AI](api-references/text-models-llm/Mistral-AI/README.md)
    * [codestral-2501](api-references/text-models-llm/Mistral-AI/codestral-2501.md)
    * [mistral-nemo](api-references/text-models-llm/Mistral-AI/mistral-nemo.md)
    * [mistral-tiny](api-references/text-models-llm/Mistral-AI/mistral-tiny.md)
    * [Mistral-7B-Instruct](api-references/text-models-llm/Mistral-AI/Mistral-7B-Instruct.md)
    * [Mixtral-8x7B-Instruct](api-references/text-models-llm/Mistral-AI/Mixtral-8x7B-Instruct-v0.1.md)
  * [Moonshot](api-references/text-models-llm/moonshot/README.md)
    * [kimi-k2-preview](api-references/text-models-llm/moonshot/kimi-k2-preview.md)
  * [NVIDIA](api-references/text-models-llm/NVIDIA/README.md)
    * [Llama-3.1-Nemotron-70B-Instruct-HF](api-references/text-models-llm/NVIDIA/Llama-3.1-Nemotron-70B-Instruct-HF.md)
    * [llama-3.1-nemotron-70b](api-references/text-models-llm/NVIDIA/llama-3.1-nemotron-70b.md)
  * [NousResearch](api-references/text-models-llm/NousResearch/README.md)
    * [Nous-Hermes-2-Mixtral-8x7B-DPO](api-references/text-models-llm/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO.md)
  * [OpenAI](api-references/text-models-llm/OpenAI/README.md)
    * [gpt-3.5-turbo](api-references/text-models-llm/OpenAI/gpt-3.5-turbo.md)
    * [gpt-4](api-references/text-models-llm/OpenAI/gpt-4.md)
    * [gpt-4-preview](api-references/text-models-llm/OpenAI/gpt-4-preview.md)
    * [gpt-4-turbo](api-references/text-models-llm/OpenAI/gpt-4-turbo.md)
    * [gpt-4o](api-references/text-models-llm/OpenAI/gpt-4o.md)
    * [gpt-4o-mini](api-references/text-models-llm/OpenAI/gpt-4o-mini.md)
    * [gpt-4o-audio-preview](api-references/text-models-llm/openai/gpt-4o-audio-preview.md)
    * [gpt-4o-mini-audio-preview](api-references/text-models-llm/openai/gpt-4o-mini-audio-preview.md)
    * [gpt-4o-search-preview](api-references/text-models-llm/openai/gpt-4o-search-preview.md)
    * [gpt-4o-mini-search-preview](api-references/text-models-llm/openai/gpt-4o-mini-search-preview.md)
    * [o1](api-references/text-models-llm/OpenAI/o1.md)
    * [o1-mini](api-references/text-models-llm/OpenAI/o1-mini.md)
    * [o3](api-references/text-models-llm/openai/o3.md)
    * [o3-mini](api-references/text-models-llm/OpenAI/o3-mini.md)
    * [o3-pro](api-references/text-models-llm/openai/o3-pro.md)
    * [gpt-4.1](api-references/text-models-llm/openai/gpt-4.1.md)
    * [gpt-4.1-mini](api-references/text-models-llm/openai/gpt-4.1-mini.md)
    * [gpt-4.1-nano](api-references/text-models-llm/openai/gpt-4.1-nano.md)
    * [o4-mini](api-references/text-models-llm/openai/o4-mini.md)
  * [Perplexity](api-references/text-models-llm/perplexity/README.md)
    * [sonar](api-references/text-models-llm/perplexity/sonar.md)
    * [sonar-pro](api-references/text-models-llm/perplexity/sonar-pro.md)
  * [xAI](api-references/text-models-llm/xAI/README.md)
    * [grok-3-beta](api-references/text-models-llm/xai/grok-3-beta.md)
    * [grok-3-mini-beta](api-references/text-models-llm/xai/grok-3-mini-beta.md)
    * [grok-4](api-references/text-models-llm/xai/grok-4.md)
  * [Zhipu](api-references/text-models-llm/zhipu/README.md)
    * [glm-4.5-air](api-references/text-models-llm/zhipu/glm-4.5-air.md)
    * [glm-4.5](api-references/text-models-llm/zhipu/glm-4.5.md)
* [Image Models](api-references/image-models/README.md)
  * [ByteDance](api-references/image-models/bytedance/README.md)
    * [Seedream 3.0](api-references/image-models/bytedance/seedream-3.0.md)
  * [Flux](api-references/image-models/flux/README.md)
    * [flux-pro](api-references/image-models/flux/flux-pro.md)
    * [flux-pro/v1.1](api-references/image-models/flux/flux-pro-v1.1.md)
    * [flux-pro/v1.1-ultra](api-references/image-models/flux/flux-pro-v1.1-ultra.md)
    * [flux-realism](api-references/image-models/flux/flux-realism.md)
    * [flux/dev](api-references/image-models/flux/flux-dev.md)
    * [flux/dev/image-to-image](api-references/image-models/flux/flux-dev-image-to-image.md)
    * [flux/schnell](api-references/image-models/flux/flux-schnell.md)
    * [flux/kontext-max/text-to-image](api-references/image-models/flux/flux-kontext-max-text-to-image.md)
    * [flux/kontext-max/image-to-image](api-references/image-models/flux/flux-kontext-max-image-to-image.md)
    * [flux/kontext-pro/text-to-image](api-references/image-models/flux/flux-kontext-pro-text-to-image.md)
    * [flux/kontext-pro/image-to-image](api-references/image-models/flux/flux-kontext-pro-image-to-image.md)
  * [Google](api-references/image-models/google/README.md)
    * [Imagen 3](api-references/image-models/google/imagen-3.0.md)
    * [Imagen 4 Preview](api-references/image-models/google/imagen-4-preview.md)
    * [Imagen 4 Ultra](api-references/image-models/google/imagen-4-ultra.md)
  * [OpenAI](api-references/image-models/OpenAI/README.md)
    * [DALL¬∑E 2](api-references/image-models/OpenAI/dall-e-2.md)
    * [DALL¬∑E 3](api-references/image-models/OpenAI/dall-e-3.md)
    * [gpt-image-1](api-references/image-models/openai/gpt-image-1.md)
  * [RecraftAI](api-references/image-models/RecraftAI/README.md)
    * [Recraft v3](api-references/image-models/RecraftAI/recraft-v3.md)
  * [Stability AI](api-references/image-models/Stability-AI/README.md)
    * [Stable Diffusion v3 Medium](api-references/image-models/Stability-AI/stable-diffusion-v3-medium.md)
    * [Stable Diffusion v3.5 Large](api-references/image-models/Stability-AI/stable-diffusion-v35-large.md)
* [Video Models](api-references/video-models/README.md)
  * [Alibaba Cloud](api-references/video-models/alibaba-cloud/README.md)
    * [Wan 2.1 (Text-to-Video)](api-references/video-models/alibaba-cloud/wan-2.1-text-to-video.md)
  * [ByteDance](api-references/video-models/bytedance/README.md)
    * [Seedance 1.0 lite (Text-to-Video)](api-references/video-models/bytedance/seedance-1.0-lite-text-to-video.md)
    * [Seedance 1.0 lite (Image-to-Video)](api-references/video-models/bytedance/seedance-1.0-lite-image-to-video.md)
    * [Seedance 1.0 pro (Text-to-Video)](api-references/video-models/bytedance/seedance-1.0-pro-text-to-video.md)
    * [Seedance 1.0 pro (Image-to-Video)](api-references/video-models/bytedance/seedance-1.0-pro-image-to-video.md)
  * [Google](api-references/video-models/google/README.md)
    * [Veo2 (Text-to-Video)](api-references/video-models/google/veo2-text-to-video.md)
    * [Veo2 (Image-to-Video)](api-references/video-models/google/veo2-image-to-video.md)
    * [Veo3 (Text-to-Video)](api-references/video-models/google/veo3-text-to-video.md)
  * [Kling AI](api-references/video-models/Kling-AI/README.md)
    * [v1-standard/image-to-video](api-references/video-models/Kling-AI/v1-standard-image-to-video.md)
    * [v1-standard/text-to-video](api-references/video-models/Kling-AI/v1-standard-text-to-video.md)
    * [v1-pro/image-to-video](api-references/video-models/Kling-AI/v1-pro-image-to-video.md)
    * [v1-pro/text-to-video](api-references/video-models/Kling-AI/v1-pro-text-to-video.md)
    * [v1.6-standard/text-to-video](api-references/video-models/Kling-AI/v1.6-standard-text-to-video.md)
    * [v1.6-standard/image-to-video](api-references/video-models/Kling-AI/v1.6-standart-image-to-video.md)
    * [v1.6-pro/image-to-video](api-references/video-models/Kling-AI/v1.6-pro-image-to-video.md)
    * [v1.6-pro/text-to-video](api-references/video-models/kling-ai/v1.6-pro-text-to-video.md)
    * [v1.6-standard/effects](api-references/video-models/kling-ai/v1.6-standard-effects.md)
    * [v1.6-pro/effects](api-references/video-models/kling-ai/v1.6-pro-effects.md)
    * [v2-master/image-to-video](api-references/video-models/kling-ai/v2-master-image-to-video.md)
    * [v2-master/text-to-video](api-references/video-models/kling-ai/v2-master-text-to-video.md)
    * [v2.1-master/text-to-video](api-references/video-models/kling-ai/v2.1-master-text-to-video.md)
    * [v2.1-master/image-to-video](api-references/video-models/kling-ai/v2.1-master-image-to-video.md)
  * [Luma AI](api-references/video-models/luma-ai/README.md)
    * [Text-to-Video v2](api-references/video-models/luma-ai/luma-ai-v2.md)
    * [Text-to-Video v1 (legacy)](api-references/video-models/luma-ai/luma-ai-text-to-video-v1-legacy.md)
  * [MiniMax](api-references/video-models/MiniMax/README.md)
    * [video-01](api-references/video-models/MiniMax/video-01.md)
    * [video-01-live2d](api-references/video-models/MiniMax/video-01-live2d.md)
    * [hailuo-02](api-references/video-models/minimax/hailuo-02.md)
  * [Runway](api-references/video-models/runway/README.md)
    * [gen3a\_turbo](api-references/video-models/runway/gen3a_turbo.md)
    * [gen4\_turbo](api-references/video-models/runway/gen4_turbo.md)
* [Music Models](api-references/music-models/README.md)
  * [Google](api-references/music-models/google/README.md)
    * [Lyria 2](api-references/music-models/google/lyria-2.md)
  * [MiniMax](api-references/music-models/MiniMax/README.md)
    * [minimax-music \[legacy\]](api-references/music-models/MiniMax/minimax-music-\[legacy].md)
    * [music-01](api-references/music-models/MiniMax/music-01.md)
  * [Stability AI](api-references/music-models/Stability-AI/README.md)
    * [stable-audio](api-references/music-models/Stability-AI/stable-audio.md)
* [Voice/Speech Models](api-references/speech-models/README.md)
  * [Speech-to-Text](api-references/speech-models/speech-to-text/README.md)
    * [stt \[legacy\]](api-references/speech-models/speech-to-text/stt-legacy.md)
    * [Deepgram](api-references/speech-voice-models/stt/Deepgram/README.md)
      * [nova-2](api-references/speech-voice-models/stt/Deepgram/nova-2.md)
    * [OpenAI](api-references/speech-voice-models/stt/OpenAI/README.md)
      * [whisper-base](api-references/speech-voice-models/stt/OpenAI/whisper-base.md)
      * [whisper-large](api-references/speech-voice-models/stt/OpenAI/whisper-large.md)
      * [whisper-medium](api-references/speech-voice-models/stt/OpenAI/whisper-medium.md)
      * [whisper-small](api-references/speech-voice-models/stt/OpenAI/whisper-small.md)
      * [whisper-tiny](api-references/speech-voice-models/stt/OpenAI/whisper-tiny.md)
  * [Text-to-Speech](api-references/speech-models/text-to-speech/README.md)
    * [Deepgram](api-references/speech-voice-models/tts/Deepgram/README.md)
      * [aura](api-references/speech-voice-models/tts/Deepgram/aura.md)
    * [ElevenLabs](api-references/speech-models/text-to-speech/elevenlabs/README.md)
      * [eleven\_multilingual\_v2](api-references/speech-models/text-to-speech/elevenlabs/eleven_multilingual_v2.md)
      * [eleven\_turbo\_v2\_5](api-references/speech-models/text-to-speech/elevenlabs/eleven_turbo_v2_5.md)
* [Content Moderation Models](api-references/moderation-safety-models/README.md)
  * [Meta](api-references/moderation-safety-models/Meta/README.md)
    * [Llama-Guard-3-11B-Vision-Turbo](api-references/moderation-safety-models/Meta/Llama-Guard-3-11B-Vision-Turbo.md)
    * [LlamaGuard-2-8b](api-references/moderation-safety-models/Meta/LlamaGuard-2-8b.md)
    * [Meta-Llama-Guard-3-8B](api-references/moderation-safety-models/Meta/Meta-Llama-Guard-3-8B.md)
* [3D-Generating Models](api-references/3d-generating-models/README.md)
  * [Stability AI](api-references/3d-generating-models/Stability-AI/README.md)
    * [triposr](api-references/3d-generating-models/Stability-AI/triposr.md)
* [Vision Models](api-references/vision-models/README.md)
  * [Image Analysis](api-references/vision-models/image-analysis.md)
  * [OCR: Optical Character Recognition](api-references/vision-models/ocr-optical-character-recognition/README.md)
    * [Google](api-references/vision-models/ocr-optical-character-recognition/google/README.md)
      * [Google OCR](api-references/vision-models/ocr-optical-character-recognition/google/google-ocr.md)
    * [Mistral AI](api-references/vision-models/ocr-optical-character-recognition/mistral-ai/README.md)
      * [mistral-ocr-latest](api-references/vision-models/ocr-optical-character-recognition/mistral-ai/mistral-ocr-latest.md)
  * [OFR: Optical Feature Recognition](api-references/vision-models/ofr-optical-feature-recognition.md)
* [Embedding Models](api-references/embedding-models/README.md)
  * [Anthropic](api-references/embedding-models/Anthropic/README.md)
    * [voyage-2](api-references/embedding-models/Anthropic/voyage-2.md)
    * [voyage-code-2](api-references/embedding-models/Anthropic/voyage-code-2.md)
    * [voyage-finance-2](api-references/embedding-models/Anthropic/voyage-finance-2.md)
    * [voyage-large-2](api-references/embedding-models/Anthropic/voyage-large-2.md)
    * [voyage-large-2-instruct](api-references/embedding-models/Anthropic/voyage-large-2-instruct.md)
    * [voyage-law-2](api-references/embedding-models/Anthropic/voyage-law-2.md)
    * [voyage-multilingual-2](api-references/embedding-models/Anthropic/voyage-multilingual-2.md)
  * [BAAI](api-references/embedding-models/BAAI/README.md)
    * [bge-base-en](api-references/embedding-models/BAAI/bge-base-en.md)
    * [bge-large-en](api-references/embedding-models/BAAI/bge-large-en.md)
  * [Google](api-references/embedding-models/Google/README.md)
    * [textembedding-gecko](api-references/embedding-models/Google/textembedding-gecko.md)
    * [text-multilingual-embedding-002](api-references/embedding-models/Google/text-multilingual-embedding-002.md)
  * [OpenAI](api-references/embedding-models/OpenAI/README.md)
    * [text-embedding-3-large](api-references/embedding-models/OpenAI/text-embedding-3-large.md)
    * [text-embedding-3-small](api-references/embedding-models/OpenAI/text-embedding-3-small.md)
    * [text-embedding-ada-002](api-references/embedding-models/OpenAI/text-embedding-ada-002.md)
  * [Together AI](api-references/embedding-models/Together-AI/README.md)
    * [m2-bert-80M-retrieval](api-references/embedding-models/Together-AI/m2-bert-80M-retrieval.md)

## Solutions

* [Bagoodex](solutions/bagoodex/README.md)
  * [AI Search Engine](solutions/ai-search-engine/README.md)
    * [Find Links](solutions/ai-search-engine/find-links.md)
    * [Find Images](solutions/ai-search-engine/find-images.md)
    * [Find Videos](solutions/ai-search-engine/find-videos.md)
    * [Find the Weather](solutions/ai-search-engine/find-the-weather.md)
    * [Find a Local Map](solutions/ai-search-engine/find-a-local-map.md)
    * [Get a Knowledge Structure](solutions/ai-search-engine/get-a-knowledge-structure.md)
* [OpenAI](solutions/openai/README.md)
  * [Assistants](solutions/openai/assistants/README.md)
    * [Assistant API](solutions/openai/assistants/assistant-api.md)
    * [Thread API](solutions/openai/assistants/threads.md)
    * [Message API](solutions/openai/assistants/messages.md)
    * [Run and Run Step API](solutions/openai/assistants/runs.md)
    * [Events](solutions/openai/assistants/events.md)
    * [Examples of Using Assistants](solutions/openai/assistants/using-assistants-and-threads.md)

## Use Cases

* [Create Images: Illustrate an Article](use-cases/create-images-illustrate-an-article.md)
* [Animate Images: A Children‚Äôs Encyclopedia](use-cases/animate-images-a-childrens-encyclopedia.md)
* [Create an Assistant to Discuss a Specific Document](use-cases/create-an-assistant-to-discuss-a-specific-document.md)
* [Create a 3D Model from an Image](use-cases/create-a-3d-model-from-an-image.md)
* [Create a Looped GIF for a Web Banner](use-cases/create-a-looped-gif-for-a-web-banner.md)
* [Read Text Aloud and Describe Images: Support People with Visual Impairments](use-cases/read-text-aloud-and-describe-images-ai-tool-to-support-people-with-visual-impairments.md)
* [Find Relevant Answers: Semantic Search with Text Embeddings](use-cases/find-relevant-answers-semantic-search-with-text-embeddings.md)
* [Summarize Websites with AI-Powered Chrome Extension](use-cases/summarize-websites-with-ai-powered-chrome-extension.md)

## Capabilities

* [Completion and Chat Completion](capabilities/completion-or-chat-models.md)
* [Streaming Mode](capabilities/streaming-mode.md)
* [Code Generation](capabilities/code-generation.md)
* [Thinking / Reasoning](capabilities/thinking-reasoning.md)
* [Function Calling](capabilities/function-calling.md)
* [Vision in Text Models (Image-To-Text)](capabilities/image-to-text-vision.md)
* [Web Search](capabilities/web-search.md)
* [Features of Anthropic Models](capabilities/anthropic.md)
* [Model comparison](capabilities/models-comparsion.md)

## FAQ

* [Can I use API in Python?](faq/can-i-use-api-in-python.md)
* [Can I use API in NodeJS?](faq/can-i-use-api-in-nodejs.md)
* [What are the Pro Models?](faq/pro-models.md)
* [How to use the Free Tier?](faq/free-tier.md)
* [Is API down or it just me?](faq/is-api-down-or-it-just-me.md)
* [Are my requests cropped?](faq/my-requests-are-cropped.md)
* [Can I call API in the asynchronous mode?](faq/call-api-in-the-asynchronous-mode.md)
* [OpenAI SDK doesn't work?](faq/openai-sdk-doesnt-work.md)
* [qp](faq/qp.md)

***

* [üìû Contact Sales](https://calendly.com/aimlapi/30min)
* [üóØÔ∏è Send Feedback](https://forms.aimlapi.com/doc)
* [404 Model is deprecated](<README (1).md>)

## Errors and Messages

* [General Info](errors-and-messages/general-info.md)
* [Errors with status code 4xx](errors-and-messages/errors-with-status-code-4xx.md)
* [Errors with status code 5xx](errors-and-messages/errors-with-status-code-5xx.md)

## Glossary

* [Concepts](glossary/concepts.md)

## Integrations

* [Our Integration List](integrations/our-integration-list.md)
* [Agno](integrations/agno.md)
* [Cline](integrations/cline.md)
* [continue.dev](integrations/continue.dev.md)
* [ElizaOS](integrations/elizaos.md)
* [GPT Researcher (gptr)](integrations/gpt-researcher-gptr.md)
* [Langflow](integrations/langflow.md)
* [LiteLLM](integrations/litellm.md)
* [Make](integrations/make.md)
* [n8n](integrations/n8n.md)
* [Roo Code](integrations/roo-code.md)
* [793](integrations/793.md)
* [SillyTavern](integrations/sillytavern.md)
