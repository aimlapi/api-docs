[
  {
    "name": "gpt-4o",
    "alias": "gpt-4o",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "OpenAI's flagship model designed to integrate enhanced capabilities across text, vision, and audio, providing real-time reasoning. "
  },
  {
    "name": "gpt-4o-2024-08-06",
    "alias": "gpt-4o",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "OpenAI's flagship model designed to integrate enhanced capabilities across text, vision, and audio, providing real-time reasoning. "
  },
  {
    "name": "gpt-4o-2024-05-13",
    "alias": "gpt-4o",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "OpenAI's flagship model designed to integrate enhanced capabilities across text, vision, and audio, providing real-time reasoning."
  },
  {
    "name": "gpt-4o-mini",
    "alias": "gpt-4o-mini",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "OpenAI's latest cost-efficient model designed to deliver advanced natural language processing and multimodal capabilities. It aims to make  AI more accessible and affordable, significantly enhancing the range of applications that can utilize AI technology."
  },
  {
    "name": "gpt-4o-mini-2024-07-18",
    "alias": "gpt-4o-mini",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "OpenAI's latest cost-efficient model designed to deliver advanced natural language processing and multimodal capabilities. It aims to make  AI more accessible and affordable, significantly enhancing the range of applications that can utilize AI technology."
  },
  {
    "name": "chatgpt-4o-latest",
    "alias": "chatgpt-4o",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "OpenAI's flagship model designed to integrate enhanced capabilities across text, vision, and audio, providing real-time reasoning. "
  },
  {
    "name": "gpt-4-turbo",
    "alias": "gpt-4-turbo",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "The model enhances the already impressive capabilities of ChatGPT 4 by significantly reducing response times, making it ideal for applications requiring instant feedback. It maintains the advanced conversational abilities of ChatGPT 4, ensuring that speed enhancements do not sacrifice the depth and coherence of interactions."
  },
  {
    "name": "gpt-4-turbo-2024-04-09",
    "alias": "gpt-4-turbo",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "The model enhances the already impressive capabilities of ChatGPT 4 by significantly reducing response times, making it ideal for applications requiring instant feedback. It maintains the advanced conversational abilities of ChatGPT 4, ensuring that speed enhancements do not sacrifice the depth and coherence of interactions. Replacement for all previous GPT-4 preview models."
  },
  {
    "name": "gpt-4",
    "alias": "gpt-4",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "The model represents a significant leap forward in conversational AI technology. It offers enhanced understanding and generation of natural language, capable of handling complex and nuanced dialogues with greater coherence  and context sensitivity. This model is designed to mimic human-like conversation more closely than ever before."
  },
  {
    "name": "gpt-4-0125-preview",
    "alias": "gpt-4-preview",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "Before the release of GPT-4 Turbo, OpenAI introduced two preview models that allowed users to test advanced features ahead of a full rollout. These models supported JSON mode for structured responses, parallel function calling to handle multiple API functions in a single request, and reproducible output, ensuring more consistent results across runs. They provided a glimpse into upcoming improvements in efficiency and functionality, helping developers and businesses adapt to the evolving capabilities of OpenAI's language models.\ngpt-4-1106-preview has better code generation performance, reduces cases where the model doesn't complete a task."
  },
  {
    "name": "gpt-4-1106-preview",
    "alias": "gpt-4-preview",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "Before the release of GPT-4 Turbo, OpenAI introduced two preview models that allowed users to test advanced features ahead of a full rollout. These models supported JSON mode for structured responses, parallel function calling to handle multiple API functions in a single request, and reproducible output, ensuring more consistent results across runs. They provided a glimpse into upcoming improvements in efficiency and functionality, helping developers and businesses adapt to the evolving capabilities of OpenAI's language models.\ngpt-4-1106-preview has better code generation performance, reduces cases where the model doesn't complete a task."
  },
  {
    "name": "gpt-3.5-turbo",
    "alias": "gpt-3.5-turbo",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "This model builds on the capabilities of earlier versions, offering improved natural language understanding and generation for more realistic and contextually relevant conversations. It excels in handling a wide range of conversational scenarios, providing responses that are not only accurate but also contextually appropriate."
  },
  {
    "name": "gpt-3.5-turbo-0125",
    "alias": "gpt-3.5-turbo",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "This model builds on the capabilities of earlier versions, offering improved natural language understanding and generation for more realistic and contextually relevant conversations. It excels in handling a wide range of conversational scenarios, providing responses that are not only accurate but also contextually appropriate."
  },
  {
    "name": "gpt-3.5-turbo-1106",
    "alias": "gpt-3.5-turbo",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "This model builds on the capabilities of earlier versions, offering improved natural language \nunderstanding and generation for more realistic and contextually relevant conversations. It excels in handling a wide range of conversational scenarios, providing responses that are not only accurate but also \ncontextually appropriate."
  },
  {
    "name": "o1-preview",
    "alias": "o1-preview",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "An advanced language model designed for complex reasoning and problem-solving tasks, particularly excelling in science, coding, and mathematics."
  },
  {
    "name": "o1-preview-2024-09-12",
    "alias": "o1-preview",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "An advanced language model designed for complex reasoning and problem-solving tasks, particularly excelling in science, coding, and mathematics."
  },
  {
    "name": "o1-mini",
    "alias": "o1-mini",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "A cost-efficient reasoning model optimized for STEM tasks (science, technology, engineering, and math), particularly excelling in mathematics and coding. It offers advanced reasoning capabilities at a fraction of the cost of its larger counterpart, o1-preview."
  },
  {
    "name": "o1-mini-2024-09-12",
    "alias": "o1-mini",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "A cost-efficient reasoning model optimized for STEM tasks (science, technology, engineering, and math), particularly excelling in mathematics and coding. It offers advanced reasoning capabilities at a fraction of the cost of its larger counterpart, o1-preview."
  },
  {
    "name": "microsoft/WizardLM-2-8x22B",
    "alias": "WizardLM-2-8x22B",
    "category": "text-models-llm",
    "vendor": "Microsoft",
    "description": "A state-of-the-art large language model developed by Microsoft, designed to excel in complex tasks such as multilingual conversations, reasoning, and agent-based interactions. With its advanced architecture and extensive training, it aims to provide high-quality, contextually relevant responses across various applications."
  },
  {
    "name": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
    "alias": "Llama-3.2-90B-Vision-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A large-scale multimodal AI model capable of processing both text and images. It represents Meta's first foray into multimodal AI, offering advanced visual reasoning capabilities alongside powerful language processing."
  },
  {
    "name": "Meta-Llama/Llama-Guard-7b",
    "alias": "Llama-Guard-7b",
    "category": "moderation-safety-models",
    "vendor": "Meta",
    "description": "An LLM-based model, particularly the Llama2-7b version, designed to enhance the safety of Human-AI conversations. It incorporates a comprehensive safety risk taxonomy, aiding in the classification of safety risks associated with LLM prompts and responses. This model has been instruction-tuned on a carefully curated high-quality dataset, exhibiting robust performance in benchmarks like the OpenAI Moderation Evaluation dataset and ToxicChat. Its capabilities are on par with, or exceed, those of existing content moderation tools."
  },
  {
    "name": "google/gemma-2-27b-it",
    "alias": "gemma-2-27b-it",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "A high-performance language model designed to handle a diverse range of text generation tasks, including question answering, summarization, and reasoning. It offers significant improvements in efficiency and \nperformance compared to its predecessors, making it suitable for various applications in natural language processing."
  },
  {
    "name": "meta-llama/Llama-Vision-Free",
    "alias": "Llama-Vision-Free",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "description"
  },
  {
    "name": "Gryphe/MythoMax-L2-13b",
    "alias": "MythoMax-L2-13b",
    "category": "text-models-llm",
    "vendor": "Gryphe",
    "description": "This model represents a pinnacle in the evolution of LLMs, specifically tailored for storytelling and roleplaying. Developed by Gryphe, it's part of the Mytho family, leveraging Llama 2's architecture for enhanced performance. What sets MythoMax-L2 (13B) apart is its innovative tensor merger strategy, which significantly boosts coherence in narrative generation. This model isn't just about creating stories; it's about bringing them to life, offering a deep connection with characters and plotlines that resonate."
  },
  {
    "name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "alias": "Mixtral-8x22B-Instruct",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "A cutting-edge large language model designed for instruction-following tasks. Built on a Mixture of Experts (MoE) architecture, this model is optimized for efficiently processing and generating human-like text based on detailed prompts."
  },
  {
    "name": "Qwen/Qwen2-72B-Instruct",
    "alias": "Qwen2-72B-Instruct",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "This model is stronger than the last generation of Qwen 1.5. The model's linguistic proficiency has been roadened to 27 additional languages, demonstrated state-of-the-art results across a multitude of evaluations, and the context length support was increased up to an impressive 128K tokens. \nThis enhancement allows for more comprehensive and contextually rich interactions, making Qwen2 an even more powerful tool for a variety of applications. Qwen2 builds on the Transformer architecture, adding advanced features like SwiGLU activation, attention QKV bias, group query attention, a mixture of sliding window attention, and more for improved efficiency and focus when processing information."
  },
  {
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "alias": "Mixtral-8x7B-Instruct-v0.1",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "description"
  },
  {
    "name": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
    "alias": "Llama-3.1-Nemotron-70B-Instruct-HF",
    "category": "text-models-llm",
    "vendor": "NVIDIA",
    "description": "A sophisticated large language model developed by NVIDIA, designed to enhance the performance of instruction-following tasks. It utilizes advanced training techniques and a robust architecture to generate human-like responses across a variety of applications."
  },
  {
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "alias": "Nous-Hermes-2-Mixtral-8x7B-DPO",
    "category": "text-models-llm",
    "vendor": "NousResearch",
    "description": "The forefront of AI technology, combining the power of 56 billion parameters with advanced deep policy optimization (DPO) techniques. This model is engineered to provide strategic decision-making capabilities, analyzing complex datasets to generate actionable insights and optimized policy decisions."
  },
  {
    "name": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "alias": "Llama-3.3-70B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "description"
  },
  {
    "name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "alias": "SOLAR-10.7B-Instruct",
    "category": "text-models-llm",
    "vendor": "Upstage AI",
    "description": "Thi model specializes in generating instructional content and facilitating interactive learning experiences. With a 10.7 billion parameter setup, it effectively processes educational material and engages users in a dynamic learning process, supporting a wide range of educational activities from primary to advanced levels."
  },
  {
    "name": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
    "alias": "Llama-3.2-3B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A large language model (LLM) optimized for instruction-following tasks, striking a balance between computational efficiency and high-quality performance. It excels in multilingual tasks, offering a lightweight solution without compromising on quality."
  },
  {
    "name": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
    "alias": "Llama-3.2-11B-Vision-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A powerful multimodal AI model designed for image and text processing tasks. It offers exceptional speed and accuracy, making it ideal for applications such as image captioning, visual question answering, and image-text retrieval."
  },
  {
    "name": "meta-llama/Llama-2-13b-chat-hf",
    "alias": "Llama-2-13b-chat-hf",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A sophisticated conversational AI model with 13 billion parameters, capable of generating highly engaging, contextually aware dialogues. It is designed to provide a seamless conversational experience, capturing the subtleties and complexities of human interaction."
  },
  {
    "name": "meta-llama/Llama-Guard-3-11B-Vision-Turbo",
    "alias": "Llama-Guard-3-11B-Vision-Turbo",
    "category": "moderation-safety-models",
    "vendor": "Meta",
    "description": "11B Llama 3.2 model fine-tuned for content safety, detecting harmful multimodal prompts and text in image reasoning use cases."
  },
  {
    "name": "Qwen/Qwen2.5-7B-Instruct-Turbo",
    "alias": "Qwen2.5-7B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "A cutting-edge large language model designed to understand and generate text based on specific instructions. It excels in various tasks, including coding, mathematical problem-solving, and generating structured outputs."
  },
  {
    "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "alias": "Qwen2.5-Coder-32B-Instruct",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). The one with 32B parameters is the most powerful of them.\nA more comprehensive foundation for real-world applications such as Code Agents. Not only enhancing coding capabilities but also maintaining its strengths in mathematics and general competencies.\nLong-context Support up to 128K tokens."
  },
  {
    "name": "databricks/dbrx-instruct",
    "alias": "dbrx-instruct",
    "category": "text-models-llm",
    "vendor": "Databricks",
    "description": "A powerful, open-source large language model (LLM) developed by Databricks. It utilizes a fine-grained mixture-of-experts (MoE) architecture with 132 billion total parameters, of which 36 billion are active for any given input."
  },
  {
    "name": "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
    "alias": "Meta-Llama-3-8B-Instruct-Lite",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A generative text model optimized for dialogue and instruction-following use cases. It leverages a refined transformer architecture to deliver high performance in text generation tasks."
  },
  {
    "name": "meta-llama/Llama-3-8b-chat-hf",
    "alias": "Llama-3-chat-hf",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "The Llama 3 family consists of pretrained and instruction-tuned generative text models available in 8B and 70B sizes. These models are optimized for dialogue use cases and outperform many existing open-source chat models on common industry benchmarks."
  },
  {
    "name": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-128K",
    "alias": "Meta-Llama-3.1-8B-Instruct-Turbo-128K",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "An auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align with human preferences for safety and helpfulness. "
  },
  {
    "name": "meta-llama/Llama-3-70b-chat-hf",
    "alias": "Llama-3-chat-hf",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "The Llama 3 family consists of pretrained and instruction-tuned generative text models available in 8B and 70B sizes. These models are optimized for dialogue use cases and outperform many existing open-source chat models on common industry benchmarks."
  },
  {
    "name": "Qwen/Qwen2.5-72B-Instruct-Turbo",
    "alias": "Qwen2.5-72B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "A state-of-the-art large language model designed for a variety of natural language processing tasks, including instruction following, coding assistance, and mathematical problem-solving."
  },
  {
    "name": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "alias": "Meta-Llama-3.1-405B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A state-of-the-art large language model developed by Meta AI, designed for advanced text generation tasks. It excels in generating coherent and contextually relevant text across various domains."
  },
  {
    "name": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
    "alias": "Meta-Llama-3.1-8B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "An advanced language model designed for high-quality text generation, optimized for professional and industry applications requiring extensive GPU resources."
  },
  {
    "name": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "alias": "Meta-Llama-3.1-70B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A state-of-the-art instruction-tuned language model designed for multilingual dialogue use cases. It excels in natural language generation and understanding tasks, outperforming many existing models in the industry benchmarks."
  },
  {
    "name": "google/gemma-2b-it",
    "alias": "gemma-2b-it",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone."
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.2",
    "alias": "Mistral-7B-Instruct",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "An improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1. It leverages instruction fine-tuning to generate responses based on specific prompts. The model architecture is based on Mistral-7B-v0.1, which includes features such as Grouped-Query Attention, Sliding-Window Attention, and a Byte-fallback BPE tokenizer."
  },
  {
    "name": "meta-llama/LlamaGuard-2-8b",
    "alias": "LlamaGuard-2-8b",
    "category": "moderation-safety-models",
    "vendor": "Meta",
    "description": "An 8B-parameter Llama 3-based safeguard model, designed for content classification in LLM inputs (prompt classification) and responses (response classification), similar to Llama Guard. Functioning as an LLM, it generates text outputs that indicate whether a given prompt or response is safe or unsafe, and if deemed unsafe, it specifies the violated content categories."
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.1",
    "alias": "Mistral-7B-Instruct",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "A robust AI model equipped with 7 billion parameters, optimized for delivering exceptional performance across various machine learning tasks. This model excels in processing large datasets, understanding complex patterns, and generating insights, making it a powerhouse for AI-driven solutions."
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.3",
    "alias": "Mistral-7B-Instruct",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "An advanced version of the Mistral-7B model, fine-tuned specifically for instruction-based tasks. This model is designed to enhance language generation and understanding capabilities."
  },
  {
    "name": "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
    "alias": "Meta-Llama-3-70B-Instruct-Turbo",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "An auto-regressive LLM featuring optimized transformers, SFT, and RLHF to align with helpfulness and safety preferences."
  },
  {
    "name": "meta-llama/Meta-Llama-3-70B-Instruct-Lite",
    "alias": "Meta-Llama-3-70B-Instruct-Lite",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A large language model developed by Meta, optimized for dialogue and instruction-tuned to improve helpfulness and safety. It is part of the Llama 3 family, which includes models with 8 billion and 70 billion parameters."
  },
  {
    "name": "google/gemma-2-9b-it",
    "alias": "gemma-2-9b-it",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text generation tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone."
  },
  {
    "name": "Gryphe/MythoMax-L2-13b-Lite",
    "alias": "MythoMax-L2-13b-Lite",
    "category": "text-models-llm",
    "vendor": "Gryphe",
    "description": "A lite version of Gryphe/MythoMax-L2-13b model. Both models are tailored for storytelling and roleplaying."
  },
  {
    "name": "meta-llama/Llama-2-7b-chat-hf",
    "alias": "Llama-2-7b-chat-hf",
    "category": "text-models-llm",
    "vendor": "Meta",
    "description": "A conversational AI model designed to provide rich, nuanced, and contextually aware interactions. With 7 billion parameters, it has the capacity to understand and generate conversations that are remarkably human-like, making it ideal for creating engaging and intelligent dialogue systems."
  },
  {
    "name": "meta-llama/Meta-Llama-Guard-3-8B",
    "alias": "Meta-Llama-Guard-3-8B",
    "category": "moderation-safety-models",
    "vendor": "Meta",
    "description": "A language model designed to provide input and output safeguards for human-AI conversations. It focuses on content moderation and safety, ensuring the responses generated by AI systems adhere to predefined safety standards."
  },
  {
    "name": "claude-3-opus-20240229",
    "alias": "claude-3-opus",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "A highly capable AI model designed to process and analyze both text and image data. It excels in tasks requiring complex reasoning, mathematical problem-solving, coding, and multilingual text understanding."
  },
  {
    "name": "claude-3-sonnet-20240229",
    "alias": "claude-3-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Sonnet is engineered to balance performance and speed, positioning it as an excellent option for applications that need both high efficiency and robust capabilities. As a multimodal model like its counterparts, Sonnet can process and analyze both text and image data."
  },
  {
    "name": "claude-3-haiku-20240307",
    "alias": "claude-3-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "The quickest and most streamlined model, offering near-instant responsiveness. It rapidly addresses simple queries and requests with exceptional speed. This allows users to create smooth AI-driven experiences that closely resemble human interactions."
  },
  {
    "name": "claude-3-5-sonnet-20240620",
    "alias": "claude-3-5-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Sonnet sets a new standard in the AI industry, raising the bar for intelligence and performance. Operating at twice the speed of its predecessor, Claude 3 Opus, Claude 3.5 Sonnet outperforms it across a range of evaluations, making it a superior choice for complex AI tasks."
  },
  {
    "name": "claude-3-5-sonnet-20241022",
    "alias": "claude-3-5-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Sonnet sets a new standard in the AI industry, raising the bar for intelligence and performance. Operating at twice the speed of its predecessor, Claude 3 Opus, Claude 3.5 Sonnet outperforms it across a range of evaluations, making it a superior choice for complex AI tasks."
  },
  {
    "name": "claude-3-5-haiku-20241022",
    "alias": "claude-3-5-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Haiku is a cutting-edge AI model designed for rapid data processing and advanced reasoning capabilities. It excels in tasks requiring quick responses, such as coding assistance, customer service interactions, and content moderation."
  },
  {
    "name": "anthropic/claude-3.5-sonnet-20240620",
    "alias": "claude-3.5-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Sonnet sets a new standard in the AI industry, raising the bar for intelligence and performance. Operating at twice the speed of its predecessor, Claude 3 Opus, Claude 3.5 Sonnet outperforms it across a range of evaluations, making it a superior choice for complex AI tasks."
  },
  {
    "name": "anthropic/claude-3.5-sonnet-20241022",
    "alias": "claude-3.5-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Sonnet sets a new standard in the AI industry, raising the bar for intelligence and performance. Operating at twice the speed of its predecessor, Claude 3 Opus, Claude 3.5 Sonnet outperforms it across a range of evaluations, making it a superior choice for complex AI tasks."
  },
  {
    "name": "anthropic/claude-3.5-sonnet",
    "alias": "claude-3.5-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Sonnet sets a new standard in the AI industry, raising the bar for intelligence and performance. Operating at twice the speed of its predecessor, Claude 3 Opus, Claude 3.5 Sonnet outperforms it across a range of evaluations, making it a superior choice for complex AI tasks."
  },
  {
    "name": "claude-3-5-sonnet-latest",
    "alias": "claude-3-5-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Sonnet sets a new standard in the AI industry, raising the bar for intelligence and performance. Operating at twice the speed of its predecessor, Claude 3 Opus, Claude 3.5 Sonnet outperforms it across a range of evaluations, making it a superior choice for complex AI tasks."
  },
  {
    "name": "anthropic/claude-3-haiku-20240307",
    "alias": "claude-3-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "The quickest and most streamlined model, offering near-instant responsiveness. It rapidly addresses simple queries and requests with exceptional speed. This allows users to create smooth AI-driven experiences that closely resemble human interactions."
  },
  {
    "name": "anthropic/claude-3-haiku",
    "alias": "claude-3-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "The quickest and most streamlined model, offering near-instant responsiveness. It rapidly addresses simple queries and requests with exceptional speed. This allows users to create smooth AI-driven experiences that closely resemble human interactions."
  },
  {
    "name": "claude-3-haiku-latest",
    "alias": "claude-3-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "The quickest and most streamlined model, offering near-instant responsiveness. It rapidly addresses simple queries and requests with exceptional speed. This allows users to create smooth AI-driven experiences that closely resemble human interactions."
  },
  {
    "name": "anthropic/claude-3-opus-20240229",
    "alias": "claude-3-opus",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "A highly capable AI model designed to process and analyze both text and image data. It excels in tasks requiring complex reasoning, mathematical problem-solving, coding, and multilingual text understanding."
  },
  {
    "name": "anthropic/claude-3-opus",
    "alias": "claude-3-opus",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "A highly capable AI model designed to process and analyze both text and image data. It excels in tasks requiring complex reasoning, mathematical problem-solving, coding, and multilingual text understanding."
  },
  {
    "name": "claude-3-opus-latest",
    "alias": "claude-3-opus",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "A highly capable AI model designed to process and analyze both text and image data. It excels in tasks requiring complex reasoning, mathematical problem-solving, coding, and multilingual text understanding."
  },
  {
    "name": "anthropic/claude-3-sonnet-20240229",
    "alias": "claude-3-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Sonnet is engineered to balance performance and speed, positioning it as an excellent option for applications that need both high efficiency and robust capabilities. As a multimodal model like its counterparts, Sonnet can process and analyze both text and image data."
  },
  {
    "name": "anthropic/claude-3-sonnet",
    "alias": "claude-3-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Sonnet is engineered to balance performance and speed, positioning it as an excellent option for applications that need both high efficiency and robust capabilities. As a multimodal model like its counterparts, Sonnet can process and analyze both text and image data."
  },
  {
    "name": "claude-3-sonnet-latest",
    "alias": "claude-3-sonnet",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Sonnet is engineered to balance performance and speed, positioning it as an excellent option for applications that need both high efficiency and robust capabilities. As a multimodal model like its counterparts, Sonnet can process and analyze both text and image data."
  },
  {
    "name": "anthropic/claude-3-5-haiku-20241022",
    "alias": "claude-3-5-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Haiku is a cutting-edge AI model designed for rapid data processing and advanced reasoning capabilities. It excels in tasks requiring quick responses, such as coding assistance, customer service interactions, and content moderation."
  },
  {
    "name": "anthropic/claude-3-5-haiku",
    "alias": "claude-3-5-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Haiku is a cutting-edge AI model designed for rapid data processing and advanced reasoning capabilities. It excels in tasks requiring quick responses, such as coding assistance, customer service interactions, and content moderation."
  },
  {
    "name": "claude-3-5-haiku-latest",
    "alias": "claude-3-5-haiku",
    "category": "text-models-llm",
    "vendor": "Anthropic",
    "description": "Claude 3.5 Haiku is a cutting-edge AI model designed for rapid data processing and advanced reasoning capabilities. It excels in tasks requiring quick responses, such as coding assistance, customer service interactions, and content moderation."
  },
  {
    "name": "gemini-1.5-flash",
    "alias": "gemini-1.5-flash",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "A state-of-the-art multimodal AI model designed for high-speed processing and efficient response generation. It excels in real-time applications, making it suitable for tasks that require immediate feedback and high throughput."
  },
  {
    "name": "gemini-1.5-pro",
    "alias": "gemini-1.5-pro",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "A state-of-the-art multimodal AI model designed to process and understand various data types, including text, images, videos, audio, and code. It excels in tasks requiring long-context understanding and interleaving of different modalities."
  },
  {
    "name": "gemini-pro",
    "alias": "gemini-pro",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "A state-of-the-art multimodal AI model designed to process and generate text, images, audio, and video. It leverages advanced machine learning techniques to understand and generate complex data types, making it suitable for a variety of applications in natural language processing, computer vision, and audio analysis."
  },
  {
    "name": "gemini-2.0-flash-exp",
    "alias": "gemini-2.0-flash-exp",
    "category": "text-models-llm",
    "vendor": "Google",
    "description": "A cutting-edge multimodal AI model developed by Google DeepMind, designed to power agentic experiences. This model is capable of processing and generating content in multiple formats, including text, images, audio, and video, making it suitable for a wide range of applications such as real-time conversation systems and interactive tools."
  },
  {
    "name": "mistralai/mistral-tiny",
    "alias": "mistral-tiny",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "A lightweight language model optimized for efficient text generation, summarization, and code completion tasks. It is designed to operate effectively in resource-constrained environments while maintaining high performance."
  },
  {
    "name": "x-ai/grok-beta",
    "alias": "grok-beta",
    "category": "text-models-llm",
    "vendor": "xAI",
    "description": "An advanced language model designed to enhance conversational AI, coding assistance, and complex reasoning tasks. It aims to compete with leading models like OpenAI's GPT-4 and Anthropic's Claude 3.5."
  },
  {
    "name": "mistralai/mistral-nemo",
    "alias": "mistral-nemo",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "A state-of-the-art large language model designed for advanced natural language processing tasks, including text generation, summarization, translation, and sentiment analysis. It features a large context window of up to 128k tokens, making it suitable for handling extensive inputs and complex tasks."
  },
  {
    "name": "neversleep/llama-3.1-lumimaid-70b",
    "alias": "llama-3.1-lumimaid",
    "category": "text-models-llm",
    "vendor": "NeverSleep",
    "description": "A fine-tuned variant of the Llama 3 model, specifically designed for enhanced conversational capabilities and role-playing scenarios. It excels in generating coherent and contextually relevant dialogues while maintaining a broad knowledge base."
  },
  {
    "name": "anthracite-org/magnum-v4-72b",
    "alias": "magnum-v4",
    "category": "text-models-llm",
    "vendor": "Anthracite",
    "description": "A large language model fine-tuned on top of Qwen2.5, specifically designed to replicate the prose quality of the Claude 3 models, particularly Sonnet and Opus. It excels in generating coherent and contextually rich text, making it suitable for various applications requiring high-quality language generation."
  },
  {
    "name": "nvidia/llama-3.1-nemotron-70b-instruct",
    "alias": "llama-3.1-nemotron-70b",
    "category": "text-models-llm",
    "vendor": "NVIDIA",
    "description": "A sophisticated large language model developed by NVIDIA, designed to enhance the performance of instruction-following tasks. It utilizes advanced training techniques and a robust architecture to generate human-like responses across a variety of applications."
  },
  {
    "name": "cohere/command-r-plus",
    "alias": "command-r",
    "category": "text-models-llm",
    "vendor": "Cohere",
    "description": "A cutting-edge large language model designed for enterprise applications, focusing on advanced capabilities such as Retrieval-Augmented Generation (RAG) and multi-step tool use. It is built to enhance efficiency and accuracy in real-world business scenarios."
  },
  {
    "name": "ai21/jamba-1-5-mini",
    "alias": "jamba-1-5-mini",
    "category": "text-models-llm",
    "vendor": "AI21 Labs",
    "description": "A state-of-the-art hybrid SSM-Transformer model designed for high efficiency and performance in instruction-following tasks. It excels in processing long contexts and generating high-quality outputs, making it suitable for a variety of applications in natural language processing."
  },
  {
    "name": "deepseek/deepseek-chat",
    "alias": "deepseek-chat",
    "category": "text-models-llm",
    "vendor": "DeepSeek",
    "description": "An advanced conversational AI designed to deliver highly engaging and context-aware dialogues. This model excels in understanding and generating human-like text, making it an ideal solution for creating responsive and intelligent chatbots. Its sophisticated architecture enables it to grasp subtle nuances in language, providing a seamless conversational experience that mimics human interaction."
  },
  {
    "name": "qwen/qvq-72b-preview",
    "alias": "qvq-72b-preview",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "An experimental research model developed by the Qwen team, focusing on enhancing visual reasoning capabilities. This model integrates advanced multimodal processing to interpret and generate responses based on both text and visual inputs, making it particularly adept at solving complex problems that require understanding visual content."
  },
  {
    "name": "mistralai/codestral-2501",
    "alias": "codestral-2501",
    "category": "text-models-llm",
    "vendor": "Mistral AI",
    "description": "A state-of-the-art AI model specifically designed for code generation tasks. It leverages advanced machine learning techniques to assist developers in writing, debugging, and optimizing code across a wide range of programming languages. With its impressive performance metrics and capabilities, Codestral-2501 aims to streamline the coding process and enhance productivity for software developers."
  },
  {
    "name": "deepseek/deepseek-r1",
    "alias": "deepseek-r1",
    "category": "text-models-llm",
    "vendor": "DeepSeek",
    "description": "A cutting-edge reasoning model developed by DeepSeek AI, designed to excel in complex problem-solving, mathematical reasoning, and programming assistance. Leveraging a Mixture-of-Experts (MoE) architecture, the model activates only a subset of its parameters for each token processed, allowing for efficient computation while maintaining high performance across various tasks."
  },
  {
    "name": "dall-e-3",
    "alias": "dall-e-3",
    "category": "image-models",
    "vendor": "OpenAI",
    "description": "This model represents a significant leap forward in AI-driven image creation, capable of generating 1024x1024 resolution images from text inputs. This model processes prompts with enhanced neural network architectures, resulting in images that are not only relevant but also rich in detail and diversity. DALL·E 3's deep learning techniques analyze and understand complex descriptions, allowing for the generation of visuals across a wide range of styles and subjects."
  },
  {
    "name": "dall-e-2",
    "alias": "dall-e-2",
    "category": "image-models",
    "vendor": "OpenAI",
    "description": "An advanced AI system designed to generate high-quality images and artwork from textual descriptions. It builds upon its predecessor, DALL·E 1, utilizing improved techniques to create images that are more realistic and contextually accurate."
  },
  {
    "name": "stabilityai/stable-diffusion-xl-base-1.0",
    "alias": "stable-diffusion-xl-base",
    "category": "image-models",
    "vendor": "Stability AI",
    "description": "Stable Diffusion XL 1.0 expands upon the capabilities of standard Stable Diffusion models, offering enhanced capacity for generating high-resolution, detailed images. It's designed to cater to demands for larger, more complex visual outputs, maintaining quality and coherence even at increased scales."
  },
  {
    "name": "flux/schnell",
    "alias": "schnell",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "A state-of-the-art text-to-image generation model designed to create high-quality images from textual descriptions. With a robust architecture of 12 billion parameters, it leverages advanced techniques to produce images that rival those generated by leading closed-source models."
  },
  {
    "name": "flux-pro",
    "alias": "flux-pro",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "A state-of-the-art AI model designed for professional-grade image generation from text descriptions. It pushes the boundaries of visual creativity and quality, delivering stunning results that rival human-created artwork."
  },
  {
    "name": "flux-pro/v1.1",
    "alias": "flux-pro",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "A new image generation model with inference speed increased sixfold compared to the previous flux-pro. It also features enhanced generation quality and greater accuracy in following prompts."
  },
  {
    "name": "flux-pro/v1.1-ultra",
    "alias": "flux-pro/v1.1-ultra",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "An advanced AI image generator designed to create high-resolution images rapidly and efficiently. It is optimized for various applications, including content creation, e-commerce, and advertising, providing users with the ability to generate visually appealing images at unprecedented speeds."
  },
  {
    "name": "flux/dev",
    "alias": "flux/dev",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "A state-of-the-art image generation model that utilizes a 12 billion parameter rectified flow transformer architecture. It is designed to generate high-quality images from textual descriptions, making it a powerful tool for developers and creatives."
  },
  {
    "name": "flux/dev/image-to-image",
    "alias": "flux/dev/image-to-image",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "A state-of-the-art image generation model that utilizes a 12 billion parameter rectified flow transformer architecture. It is designed to generate high-quality images from textual descriptions, making it a powerful tool for developers and creatives."
  },
  {
    "name": "stable-diffusion-v3-medium",
    "alias": "stable-diffusion-v3-medium",
    "category": "image-models",
    "vendor": "Stability AI",
    "description": "An advanced text-to-image generation model that utilizes a Multimodal Diffusion Transformer (MMDiT) architecture to produce high-quality images from textual descriptions."
  },
  {
    "name": "stable-diffusion-v35-large",
    "alias": "stable-diffusion-v35-large",
    "category": "image-models",
    "vendor": "Stability AI",
    "description": "A state-of-the-art text-to-image generative model designed to create high-resolution images based on textual prompts. It excels in producing diverse and high-quality outputs, making it suitable for professional applications."
  },
  {
    "name": "flux-realism",
    "alias": "flux-realism",
    "category": "image-models",
    "vendor": "Black Forest Labs",
    "description": "A state-of-the-art model designed to generate photorealistic images from textual descriptions. It enhances the capabilities of the FLUX-1 model, allowing users to create lifelike visuals without the need for extensive realism-related prompts."
  },
  {
    "name": "recraft-v3",
    "alias": "recraft-v3",
    "category": "image-models",
    "vendor": "RecraftAI",
    "description": "A state-of-the-art image generation model specifically designed for professional designers, featuring advanced text generation capabilities, anatomical accuracy, and precise style control. It stands out for its ability to generate images with extended text content and vector art support."
  },
  {
    "name": "triposr",
    "alias": "triposr",
    "category": "3d-generating-models",
    "vendor": "Stability AI",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization. <br/> Nova-2 offers the following model options: <br/> - **atc**: Optimized for audio from air traffic control. <br/> - **automotive**: Optimized for audio with automative oriented vocabulary. <br/> - **conversationalai**: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk. <br/>- **drivethru**: Optimized for audio sources from drivethrus. <br/>- **finance**: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented. <br/> - **general**: Optimized for everyday audio processing. <br/> - **medical**: Optimized for audio with medical oriented vocabulary. <br/> - **meeting**: Optimized for conference room settings, which include multiple speakers with a single microphone. <br/> - **phonecall**: Optimized for low-bandwidth audio phone calls. <br/> - **video**: Optimized for audio sourced from videos. <br/> - **voicemail**: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model."
  },
  {
    "name": "runway-gen3/turbo/image-to-video",
    "alias": "runway-gen3/turbo/image-to-video",
    "category": "video-models",
    "vendor": "Runway",
    "description": "An advanced AI model designed for converting images into high-quality videos. It allows users to generate dynamic video content from still images or text prompts, significantly enhancing creative workflows in multimedia production."
  },
  {
    "name": "kling-video/v1/standard/image-to-video",
    "alias": "kling-video/image-to-video",
    "category": "video-models",
    "vendor": "Kling AI",
    "description": "A sophisticated AI model developed by Kuaishou Technology that transforms static images into dynamic video clips. This model allows users to create engaging videos from images by utilizing advanced AI technologies to simulate motion and narrative, making it suitable for various creative applications."
  },
  {
    "name": "kling-video/v1/pro/image-to-video",
    "alias": "kling-video/image-to-video",
    "category": "video-models",
    "vendor": "Kling AI",
    "description": "This model transforms static images into dynamic video clips. This model allows users to create engaging videos from images by utilizing advanced AI technologies to simulate motion and narrative, making it suitable for various creative applications."
  },
  {
    "name": "kling-video/v1.6/standard/image-to-video",
    "alias": "kling-video/image-to-video",
    "category": "video-models",
    "vendor": "Kling AI",
    "description": "An advanced AI video generation model developed by Kuaishou Technology, designed to create high-quality videos from text prompts and images. This version introduces significant improvements in prompt adherence, visual quality, and dynamic action rendering, enabling users to generate more consistent and visually appealing results compared to its predecessor, Kling 1.5."
  },
  {
    "name": "kling-video/v1.6/pro/image-to-video",
    "alias": "kling-video/image-to-video",
    "category": "video-models",
    "vendor": "Kling AI",
    "description": "An advanced AI video generation model, designed to create high-quality videos from image. This version introduces significant improvements in prompt adherence, visual quality, and dynamic action rendering, enabling users to generate more consistent and visually appealing results compared to its predecessor, Kling 1.5."
  },
  {
    "name": "stable-audio",
    "alias": "stable-audio",
    "category": "music-models",
    "vendor": "Stability AI",
    "description": "An advanced audio generation model designed to create high-quality audio tracks from textual prompts."
  },
  {
    "name": "music-01",
    "alias": "music-01",
    "category": "music-models",
    "vendor": "MiniMax",
    "description": "An advanced AI model that generates diverse high-quality audio compositions by analyzing and reproducing musical patterns, rhythms, and vocal styles from the reference track. Refine the process using a text prompt. "
  },
  {
    "name": "text-embedding-3-small",
    "alias": "text-embedding-3-small",
    "category": "embedding-models",
    "vendor": "OpenAI",
    "description": "An efficient and compact embedding model designed to enhance performance over its predecessor, text-embedding-ada-002. It transforms text into numerical representations that can be easily processed by machine learning models."
  },
  {
    "name": "text-embedding-3-large",
    "alias": "text-embedding-3-large",
    "category": "embedding-models",
    "vendor": "OpenAI",
    "description": "A next-generation embedding model that offers superior performance and flexibility. It converts text into high-dimensional numerical representations that are highly effective for various machine learning tasks."
  },
  {
    "name": "text-embedding-ada-002",
    "alias": "text-embedding-ada-002",
    "category": "embedding-models",
    "vendor": "OpenAI",
    "description": "An efficient and reliable embedding model designed to convert text into numerical representations. It serves as a foundational tool for various natural language processing (NLP) applications, enabling machines to understand and process human language more effectively."
  },
  {
    "name": "togethercomputer/m2-bert-80M-32k-retrieval",
    "alias": "m2-bert-80M-retrieval",
    "category": "embedding-models",
    "vendor": "Together AI",
    "description": "A robust AI model designed to excel in the retrieval of information from extensive databases and knowledge repositories. With a 32k parameter configuration, it offers enhanced capacity for processing complex queries and delivering accurate results, making it ideal for high-demand search environments."
  },
  {
    "name": "BAAI/bge-base-en-v1.5",
    "alias": "bge-base-en",
    "category": "embedding-models",
    "vendor": "BAAI",
    "description": "An embedding model that excels in creating high-precision linguistic representations. It's designed to generate detailed embeddings that capture the subtleties of language, facilitating advanced natural language processing tasks."
  },
  {
    "name": "togethercomputer/m2-bert-80M-2k-retrieval",
    "alias": "m2-bert-80M-retrieval",
    "category": "embedding-models",
    "vendor": "Together AI",
    "description": "An AI-powered model specifically designed for efficient information retrieval. With a compact 2K parameter design, it is tailored for environments where quick, accurate data access is required, particularly in smaller or more focused datasets."
  },
  {
    "name": "BAAI/bge-large-en-v1.5",
    "alias": "bge-large-en",
    "category": "embedding-models",
    "vendor": "BAAI",
    "description": "BGE-Large-EN-v1.5, standing for Bi-directional Global Embedding, is an advanced language model that provides rich, contextual embeddings for English text. It encodes deep linguistic information, allowing for a comprehensive understanding of text nuances, which is crucial for various natural language processing (NLP) tasks."
  },
  {
    "name": "togethercomputer/m2-bert-80M-8k-retrieval",
    "alias": "m2-bert-80M-retrieval",
    "category": "embedding-models",
    "vendor": "Together AI",
    "description": "The model integrates advanced machine learning techniques to excel in searching and retrieving relevant information from vast datasets. With its 8k parameter design, it balances performance and efficiency, making it suitable for applications requiring high-speed data access and analysis."
  },
  {
    "name": "voyage-large-2-instruct",
    "alias": "voyage-large-2-instruct",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "An instruction-tuned, general-purpose text embedding model optimized for tasks such as clustering, classification, and retrieval. It is designed to perform exceptionally well on the Massive Text Embedding Benchmark (MTEB), ranking first in several key areas."
  },
  {
    "name": "voyage-finance-2",
    "alias": "voyage-finance-2",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "A finance domain-specific embedding model that delivers superior retrieval quality, outperforming competing models on financial datasets—achieving an average 7% gain over OpenAI (the next best model) and 12% over Cohere. It supports a 32K context length, significantly larger than other evaluated alternatives. "
  },
  {
    "name": "voyage-multilingual-2",
    "alias": "voyage-multilingual-2",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "Optimized for multilingual retrieval and retrieval-augmented generation (RAG), this model surpasses alternatives like OpenAI v3 large and Cohere multilingual v3 across most languages, including French, German, Japanese, Spanish, and Korean. On average, it outperforms the second-best model by 5.6%, while maintaining strong performance in English. Additionally, it supports a large 32K context length."
  },
  {
    "name": "voyage-law-2",
    "alias": "voyage-law-2",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "This model leads the MTEB leaderboard for legal retrieval by a significant margin, outperforming OpenAI v3 large by an average of 6% across eight legal retrieval datasets and by over 10% on three key benchmarks (LeCaRDv2, LegalQuAD, and GerDaLIR). With a 16K context length and training on extensive long-context legal documents, voyage-law-2 excels in retrieving information across lengthy texts. Notably, it also matches or surpasses performance on general-purpose corpora across domains."
  },
  {
    "name": "voyage-code-2",
    "alias": "voyage-code-2",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "This embedding model is designed for semantic retrieval of code and related text from both natural language and code-based queries. In a comprehensive evaluation across 11 code retrieval tasks—sourced from popular datasets like HumanEval and MBPP—it achieved a significant 14.52% improvement in recall over competitors, including OpenAI and Cohere. Additionally, it demonstrated consistent gains, averaging 3.03%, across various general-purpose text datasets."
  },
  {
    "name": "voyage-large-2",
    "alias": "voyage-large-2",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "Voyage’s most powerful generalist embedding model, outperforming popular competing models."
  },
  {
    "name": "voyage-2",
    "alias": "voyage-2",
    "category": "embedding-models",
    "vendor": "Anthropic",
    "description": "A general-purpose embedding model that delivers state-of-the-art performance across multiple domains while maintaining high efficiency. It's optimized for a balance between cost, latency, and retrieval quality."
  },
  {
    "name": "textembedding-gecko@001",
    "alias": "textembedding-gecko",
    "category": "embedding-models",
    "vendor": "Google",
    "description": "A cutting-edge text embedding model that transforms textual inputs into high-dimensional vector representations. These embeddings are designed to capture the semantic meaning and context of the input text, making them highly useful for various natural language processing tasks."
  },
  {
    "name": "textembedding-gecko@003",
    "alias": "textembedding-gecko",
    "category": "embedding-models",
    "vendor": "Google",
    "description": "A state-of-the-art text embedding model designed to generate high-quality vector representations of text. This model excels in capturing semantic meanings and relationships between textual inputs, making it suitable for various natural language processing tasks."
  },
  {
    "name": "textembedding-gecko-multilingual@001",
    "alias": "textembedding-gecko",
    "category": "embedding-models",
    "vendor": "Google",
    "description": "A state-of-the-art text embedding model designed to convert textual data into numerical vector representations. It captures semantic meanings and relationships within the text, facilitating various natural language processing (NLP) tasks."
  },
  {
    "name": "text-multilingual-embedding-002",
    "alias": "text-multilingual-embedding-002",
    "category": "embedding-models",
    "vendor": "Google",
    "description": "A state-of-the-art model designed to convert textual data into numerical vector representations, capturing the semantic meaning and context of the input text. It is particularly focused on supporting multiple languages, making it suitable for global applications."
  },
  {
    "name": "#g1_nova-2-general",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary."
  },
  {
    "name": "#g1_nova-2-meeting",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary."
  },
  {
    "name": "#g1_nova-2-phonecall",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary."
  },
  {
    "name": "#g1_nova-2-voicemail",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_nova-2-finance",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_nova-2-conversationalai",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_nova-2-video",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_nova-2-medical",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_nova-2-drivethru",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_nova-2-automotive",
    "alias": "#g1_nova-2",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "Nova-2 builds on the advancements of Nova-1 with speech-specific optimizations to its Transformer architecture, refined data curation techniques, and a multi-stage training approach. These improvements result in a lower word error rate (WER) and better entity recognition (including proper nouns and alphanumeric sequences), as well as enhanced punctuation and capitalization.\n\nNova-2 offers the following model options:\ngeneral: Optimized for everyday audio processing.\nmeeting: Optimized for conference room settings, which include multiple speakers with a single microphone.\nphonecall: Optimized for low-bandwidth audio phone calls.\nvoicemail: Optimized for low-bandwidth audio clips with a single speaker. Derived from the phonecall model.\nfinance: Optimized for multiple speakers with varying audio quality, such as might be found on a typical earnings call. Vocabulary is heavily finance oriented.\nconversationalai: Optimized for use cases in which a human is talking to an automated bot, such as IVR, a voice assistant, or an automated kiosk.\nvideo: Optimized for audio sourced from videos.\nmedical: Optimized for audio with medical oriented vocabulary.\ndrivethru: Optimized for audio sources from drivethrus.\nautomotive: Optimized for audio with automative oriented vocabulary.\natc: Optimized for audio from air traffic control."
  },
  {
    "name": "#g1_whisper-large",
    "alias": "#g1_whisper-large",
    "category": "speech-voice-models/stt",
    "vendor": "OpenAI",
    "description": "The Whisper models are primarily for AI research, focusing on model robustness, generalization, and biases, and are also effective for English speech recognition. The use of Whisper models for transcribing non-consensual recordings or in high-risk decision-making contexts is strongly discouraged due to potential inaccuracies and ethical concerns.\nThe models are trained using 680,000 hours of audio and corresponding transcripts from the internet, with 65% being English audio and transcripts, 18% non-English audio with English transcripts, and 17% non-English audio with matching non-English transcripts, covering 98 languages in total."
  },
  {
    "name": "#g1_whisper-medium",
    "alias": "#g1_whisper-medium",
    "category": "speech-voice-models/stt",
    "vendor": "OpenAI",
    "description": "The Whisper models are primarily for AI research, focusing on model robustness, generalization, and biases, and are also effective for English speech recognition. The use of Whisper models for transcribing non-consensual recordings or in high-risk decision-making contexts is strongly discouraged due to potential inaccuracies and ethical concerns.\nThe models are trained using 680,000 hours of audio and corresponding transcripts from the internet, with 65% being English audio and transcripts, 18% non-English audio with English transcripts, and 17% non-English audio with matching non-English transcripts, covering 98 languages in total."
  },
  {
    "name": "#g1_whisper-small",
    "alias": "#g1_whisper-small",
    "category": "speech-voice-models/stt",
    "vendor": "OpenAI",
    "description": "The Whisper models are primarily for AI research, focusing on model robustness, generalization, and biases, and are also effective for English speech recognition. The use of Whisper models for transcribing non-consensual recordings or in high-risk decision-making contexts is strongly discouraged due to potential inaccuracies and ethical concerns.\nThe models are trained using 680,000 hours of audio and corresponding transcripts from the internet, with 65% being English audio and transcripts, 18% non-English audio with English transcripts, and 17% non-English audio with matching non-English transcripts, covering 98 languages in total."
  },
  {
    "name": "#g1_whisper-tiny",
    "alias": "#g1_whisper-tiny",
    "category": "speech-voice-models/stt",
    "vendor": "OpenAI",
    "description": "The Whisper models are primarily for AI research, focusing on model robustness, generalization, and biases, and are also effective for English speech recognition. The use of Whisper models for transcribing non-consensual recordings or in high-risk decision-making contexts is strongly discouraged due to potential inaccuracies and ethical concerns.\nThe models are trained using 680,000 hours of audio and corresponding transcripts from the internet, with 65% being English audio and transcripts, 18% non-English audio with English transcripts, and 17% non-English audio with matching non-English transcripts, covering 98 languages in total."
  },
  {
    "name": "#g1_whisper-base",
    "alias": "#g1_whisper-base",
    "category": "speech-voice-models/stt",
    "vendor": "OpenAI",
    "description": "The Whisper models are primarily for AI research, focusing on model robustness, generalization, and biases, and are also effective for English speech recognition. The use of Whisper models for transcribing non-consensual recordings or in high-risk decision-making contexts is strongly discouraged due to potential inaccuracies and ethical concerns.\nThe models are trained using 680,000 hours of audio and corresponding transcripts from the internet, with 65% being English audio and transcripts, 18% non-English audio with English transcripts, and 17% non-English audio with matching non-English transcripts, covering 98 languages in total."
  },
  {
    "name": "#g1_redaction",
    "alias": "#g1_redaction",
    "category": "speech-voice-models/stt",
    "vendor": "Deepgram",
    "description": "description"
  },
  {
    "name": "#g1_aura-asteria-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-hera-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-luna-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-stella-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "A text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences. It has dozen natural, human-like voices with lower latency than any comparable voice AI alternative and supports seamless integration with Deepgram's industry-leading Nova speech-to-text API."
  },
  {
    "name": "#g1_aura-athena-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-zeus-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-orion-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-arcas-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-perseus-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-angus-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-orpheus-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "#g1_aura-helios-en",
    "alias": "#g1_aura",
    "category": "speech-voice-models/tts",
    "vendor": "Deepgram",
    "description": "Deepgram Aura is the first text-to-speech (TTS) AI model designed for real-time, conversational AI agents and applications. It delivers human-like voice quality with unparalleled speed and efficiency, making it a game-changer for building responsive, high-throughput voice AI experiences."
  },
  {
    "name": "minimax-music",
    "alias": "minimax-music",
    "category": "music-models",
    "vendor": "MiniMax",
    "description": "An advanced AI model that generates diverse high-quality audio compositions by analyzing and reproducing musical patterns, rhythms, and vocal styles from the reference track. Refine the process using a text prompt.\n\nWarning: This model is deprecated (or planned for deprecation) and may no longer receive updates or support. We recommend switching to music-01 MiniMax model, which offers improved performance and ongoing support. The recommended alternative is faster, more cost-efficient, and supports an extended set of parameters compared to this model."
  },
  {
    "name": "video-01",
    "alias": "video-01",
    "category": "video-models",
    "vendor": "MiniMax",
    "description": "An innovative AI model designed for generating high-quality videos from text prompts or image. Developed by Hailou AI, this model can produce visually striking content with cinematic qualities, allowing users to create engaging videos quickly and efficiently."
  },
  {
    "name": "video-01-live2d",
    "alias": "video-01-live2d",
    "category": "video-models",
    "vendor": "MiniMax",
    "description": "An innovative AI model designed for generating high-quality videos from text prompts or image. Developed by Hailou AI, this model can produce visually striking content with cinematic qualities, allowing users to create engaging videos quickly and efficiently."
  },
  {
    "name": "gen3a_turbo",
    "alias": "gen3a_turbo",
    "category": "video-models",
    "vendor": "Runway",
    "description": "A faster text/image to video model in the Gen-3 Alpha family that generates at a lower cost."
  },
  {
    "name": "MiniMax-Text-01",
    "alias": "text-01",
    "category": "text-models-llm",
    "vendor": "MiniMax",
    "description": "A powerful language model developed by MiniMax AI, designed to excel in tasks requiring extensive context processing and reasoning capabilities. With a total of 456 billion parameters, of which 45.9 billion are activated per token, this model utilizes a hybrid architecture that combines various attention mechanisms to optimize performance across a wide array of applications."
  },
  {
    "name": "abab6.5s-chat",
    "alias": "abab6.5s-chat",
    "category": "text-models-llm",
    "vendor": "MiniMax",
    "description": "A powerful language model developed by MiniMax AI, designed to excel in tasks requiring extensive context processing and reasoning capabilities. With a total of 456 billion parameters, of which 45.9 billion are activated per token, this model utilizes a hybrid architecture that combines various attention mechanisms to optimize performance across a wide array of applications.\nAchieves competitive scores on academic benchmarks, including MMLU and various reasoning tests."
  },
  {
    "name": "o1",
    "alias": "o1",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "A state-of-the-art language model designed to excel in complex reasoning tasks, including mathematical problem-solving, programming challenges, and scientific inquiries. The model integrates advanced reasoning capabilities through its innovative architecture, making it suitable for a wide range of applications that require deep understanding and logical deduction."
  },
  {
    "name": "o3-mini",
    "alias": "o3-mini",
    "category": "text-models-llm",
    "vendor": "OpenAI",
    "description": "A state-of-the-art language model designed to excel in complex reasoning tasks, including mathematical problem-solving, programming challenges, and scientific inquiries. The model integrates advanced reasoning capabilities through its innovative architecture, making it suitable for a wide range of applications that require deep understanding and logical deduction."
  },
  {
    "name": "qwen-turbo",
    "alias": "qwen-turbo",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "This model is designed to enhance both the performance and efficiency of AI agents developed on the Alibaba Cloud Model Studio platform.\nOptimized for speed and precision in generative AI application development. Improves AI agent comprehension and adaptation to enterprise data, especially when integrated with Retrieval-Augmented Generation (RAG) architectures. Large context window (1,000,000 tokens)."
  },
  {
    "name": "qwen-plus",
    "alias": "qwen-plus",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "An advanced large language model developed by Alibaba Cloud, designed to support multiple languages such as Chinese and English. Multilingual support, including Chinese and English. Enhanced reasoning capabilities for complex tasks. Improved instruction-following abilities."
  },
  {
    "name": "qwen-max",
    "alias": "qwen-max",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "A large-scale Mixture-of-Experts (MoE) language model developed by Alibaba Cloud. It excels in language understanding, generation, and task performance across a variety of modalities. Mixture-of-Experts (MoE) Architecture: Uses 64 specialized \"expert\" networks, activating only relevant ones per task for efficient processing. Extensive Multilingual Support: Supports 29 languages, including Chinese, English, and Arabic. Long-Context Optimization: Supports 32K context windows with 8K generation. High Stability: Demonstrates high stability in maintaining prompt instructions, with no erroneous replies during extensive testing."
  },
  {
    "name": "qwen-max-2025-01-25",
    "alias": "qwen-max",
    "category": "text-models-llm",
    "vendor": "Alibaba Cloud",
    "description": "A large-scale Mixture-of-Experts (MoE) language model developed by Alibaba Cloud. It excels in language understanding, generation, and task performance across a variety of modalities. Mixture-of-Experts (MoE) Architecture: Uses 64 specialized \"expert\" networks, activating only relevant ones per task for efficient processing. Extensive Multilingual Support: Supports 29 languages, including Chinese, English, and Arabic. Long-Context Optimization: Supports 32K context windows with 8K generation. High Stability: Demonstrates high stability in maintaining prompt instructions, with no erroneous replies during extensive testing."
  }
]